

try:
    import cython
except ImportError:
    class fake_cython:
        compiled = False
        def cfunc(self, func): return func
        def cclass(self, func): return func
        def declare(self, _, value): return value
        def __getattr__(self, type_name): return "object"

    cython = fake_cython()

try:
    from . import _difflib as difflib
    import inspect
    if inspect.isfunction(difflib.get_close_matches):
        raise ImportError(
            "Embedded difflib is not compiled to a fast binary, using the stdlib instead.")
    from cython.cimports.lxml.html._difflib import SequenceMatcher
except ImportError:
    import difflib
    if not cython.compiled:
        from difflib import SequenceMatcher

import itertools
import functools
import operator
import re

from lxml import etree
from lxml.html import fragment_fromstring
from . import defs

__all__ = ['html_annotate', 'htmldiff']

group_by_first_item = functools.partial(itertools.groupby, key=operator.itemgetter(0))






@cython.cfunc
def html_escape(text: str, _escapes: tuple = ('&amp;', '&lt;', '&gt;', '&quot;', '&
    
    
    ch: cython.Py_UCS4
    replace: cython.char[5] = [False] * 5
    for ch in text:
        replace[0] |= ch == '&'
        replace[1] |= ch == '<'
        replace[2] |= ch == '>'
        replace[3] |= ch == '"'
        replace[4] |= ch == "'"

    for i in range(5):
        if replace[i]:
            text = text.replace('&<>"\''[i], _escapes[i])

    return text


if not cython.compiled:
    from html import escape as html_escape


def default_markup(text, version):
    return '<span title="%s">%s</span>' % (
        html_escape(version), text)

def html_annotate(doclist, markup=default_markup):
    
    
    
    
    
    
    tokenlist = [tokenize_annotated(doc, version)
                 for doc, version in doclist]
    cur_tokens = tokenlist[0]
    for tokens in tokenlist[1:]:
        html_annotate_merge_annotations(cur_tokens, tokens)
        cur_tokens = tokens

    
    
    cur_tokens = compress_tokens(cur_tokens)
    
    result = markup_serialize_tokens(cur_tokens, markup)
    return ''.join(result).strip()

def tokenize_annotated(doc, annotation):
    
    tokens = tokenize(doc, include_hrefs=False)
    for tok in tokens:
        tok.annotation = annotation
    return tokens

def html_annotate_merge_annotations(tokens_old, tokens_new):
    
    s = InsensitiveSequenceMatcher(a=tokens_old, b=tokens_new)
    commands = s.get_opcodes()

    for command, i1, i2, j1, j2 in commands:
        if command == 'equal':
            eq_old = tokens_old[i1:i2]
            eq_new = tokens_new[j1:j2]
            copy_annotations(eq_old, eq_new)

def copy_annotations(src, dest):
    
    assert len(src) == len(dest)
    for src_tok, dest_tok in zip(src, dest):
        dest_tok.annotation = src_tok.annotation

def compress_tokens(tokens):
    
    result = [tokens[0]]
    for tok in tokens[1:]:
        if (not tok.pre_tags and
                not result[-1].post_tags and
                result[-1].annotation == tok.annotation):
            compress_merge_back(result, tok)
        else:
            result.append(tok)
    return result

@cython.cfunc
def compress_merge_back(tokens: list, tok):
    
    last = tokens[-1]
    if type(last) is not token or type(tok) is not token:
        tokens.append(tok)
    else:
        text = last + last.trailing_whitespace + tok
        merged = token(text,
                       pre_tags=last.pre_tags,
                       post_tags=tok.post_tags,
                       trailing_whitespace=tok.trailing_whitespace)
        merged.annotation = last.annotation
        tokens[-1] = merged

def markup_serialize_tokens(tokens, markup_func):
    
    for token in tokens:
        yield from token.pre_tags
        html = token.html()
        html = markup_func(html, token.annotation) + token.trailing_whitespace
        yield html
        yield from token.post_tags






def htmldiff(old_html, new_html):
    
    
    
    old_html_tokens = tokenize(old_html)
    new_html_tokens = tokenize(new_html)
    result = htmldiff_tokens(old_html_tokens, new_html_tokens)
    try:
        result = ''.join(result).strip()
    except (ValueError, TypeError) as exc:
        print(exc)
        result = ''
    return fixup_ins_del_tags(result)


def htmldiff_tokens(html1_tokens, html2_tokens):
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    s = InsensitiveSequenceMatcher(a=html1_tokens, b=html2_tokens)
    commands = s.get_opcodes()
    result = []
    for command, i1, i2, j1, j2 in commands:
        if command == 'equal':
            result.extend(expand_tokens(html2_tokens[j1:j2], equal=True))
            continue
        if command == 'insert' or command == 'replace':
            ins_tokens = expand_tokens(html2_tokens[j1:j2])
            merge_insert(ins_tokens, result)
        if command == 'delete' or command == 'replace':
            del_tokens = expand_tokens(html1_tokens[i1:i2])
            merge_delete(del_tokens, result)

    
    
    
    
    cleanup_delete(result)

    return result


def expand_tokens(tokens, equal=False):
    
    for token in tokens:
        yield from token.pre_tags
        if not equal or not token.hide_when_equal:
            yield token.html() + token.trailing_whitespace
        yield from token.post_tags


def merge_insert(ins_chunks, doc: list):
    
    
    
    

    
    
    
    

    item: tuple
    for balanced, marked_chunks in group_by_first_item(mark_unbalanced(ins_chunks)):
        chunks = [item[1] for item in marked_chunks]
        if balanced == 'b':
            if doc and not doc[-1].endswith(' '):
                
                doc[-1] += ' '
            doc.append('<ins>')
            doc.extend(chunks)
            if doc[-1].endswith(' '):
                
                doc[-1] = doc[-1][:-1]
            doc.append('</ins> ')
        else:
            
            doc.extend(chunks)


@cython.cfunc
def tag_name_of_chunk(chunk: str) -> str:
    i: cython.Py_ssize_t
    ch: cython.Py_UCS4

    if chunk[0] != '<':
        return ""

    start_pos = 1
    for i, ch in enumerate(chunk):
        if ch == '/':
            start_pos = 2
        elif ch == '>':
            return chunk[start_pos:i]
        elif ch.isspace():
            return chunk[start_pos:i]

    return chunk[start_pos:]

if not cython.compiled:
    
    def tag_name_of_chunk(chunk: str) -> str:
        return chunk.split(None, 1)[0].strip('<>/')





class DEL_START:
    pass
class DEL_END:
    pass


def merge_delete(del_chunks, doc: list):
    

    doc.append(DEL_START)
    doc.extend(del_chunks)
    doc.append(DEL_END)


def cleanup_delete(chunks: list):
    
    chunk_count = len(chunks)

    i: cython.Py_ssize_t
    del_start: cython.Py_ssize_t
    del_end: cython.Py_ssize_t
    shift_start_right: cython.Py_ssize_t
    shift_end_left: cython.Py_ssize_t
    unbalanced_start: cython.Py_ssize_t
    unbalanced_end: cython.Py_ssize_t
    pos: cython.Py_ssize_t
    start_pos: cython.Py_ssize_t
    chunk: str

    start_pos = 0
    while 1:
        
        
        
        try:
            del_start = chunks.index(DEL_START, start_pos)
        except ValueError:
            
            break
        else:
            del_end = chunks.index(DEL_END, del_start + 1)

        shift_end_left = shift_start_right = 0
        unbalanced_start = unbalanced_end = 0
        deleted_chunks = mark_unbalanced(chunks[del_start+1:del_end])

        
        
        for balanced, del_chunk in deleted_chunks:
            if balanced != 'us':
                break
            unbalanced_start += 1
            unbalanced_start_name = tag_name_of_chunk(del_chunk)
            for i in range(del_end+1, chunk_count):
                if chunks[i] is DEL_START:
                    break
                chunk = chunks[i]
                if chunk[0] != '<' or chunk[1] == '/':
                    
                    break
                name = tag_name_of_chunk(chunk)
                if name == 'ins':
                    
                    break
                assert name != 'del', f"Unexpected delete tag: {chunk!r}"
                if name != unbalanced_start_name:
                    
                    break
                
                shift_start_right += 1

        
        
        for balanced, del_chunk in reversed(deleted_chunks):
            if balanced != 'ue':
                break
            unbalanced_end += 1
            unbalanced_end_name = tag_name_of_chunk(del_chunk)
            for i in range(del_start - 1, -1, -1):
                if chunks[i] is DEL_END:
                    break
                chunk = chunks[i]
                if chunk[0] == '<' and chunk[1] != '/':
                    
                    break
                name = tag_name_of_chunk(chunk)
                if name == 'ins' or name == 'del':
                    
                    break
                if name != unbalanced_end_name:
                    
                    break
                
                shift_end_left += 1

        
        pos = del_start - shift_end_left
        
        for i in range(del_start + 1, del_start + shift_start_right + 1):
            chunks[pos] = chunks[i]
            pos += 1
        if pos and not chunks[pos - 1].endswith(' '):
            
            chunks[pos - 1] += ' '
        chunks[pos] = '<del>'
        pos += 1
        
        for i in range(del_start + unbalanced_start + 1, del_end - unbalanced_end):
            chunks[pos] = chunks[i]
            pos += 1
        if chunks[pos - 1].endswith(' '):
            
            chunks[pos - 1] = chunks[pos - 1][:-1]
        chunks[pos] = '</del> '
        pos += 1
        
        for i in range(del_end - shift_end_left, del_end):
            chunks[pos] = chunks[i]
            pos += 1
        
        del chunks[pos : del_end + shift_start_right + 1]
        start_pos = pos


@cython.cfunc
def mark_unbalanced(chunks) -> list:
    tag_stack = []
    marked = []

    chunk: str
    parents: list

    for chunk in chunks:
        if not chunk.startswith('<'):
            marked.append(('b', chunk))
            continue

        name = tag_name_of_chunk(chunk)
        if name in empty_tags:
            marked.append(('b', chunk))
            continue

        if chunk[1] == '/':
            
            while tag_stack:
                start_name, start_chunk, parents = tag_stack.pop()
                if start_name == name:
                    
                    parents.append(('b', start_chunk))
                    parents.extend(marked)
                    parents.append(('b', chunk))
                    marked = parents
                    chunk = None
                    break
                else:
                    
                    parents.append(('us', start_chunk))
                    parents.extend(marked)
                    marked = parents

            if chunk is not None:
                
                marked.append(('ue', chunk))
        else:
            
            tag_stack.append((name, chunk, marked))
            marked = []

    
    while tag_stack:
        _, start_chunk, parents = tag_stack.pop()
        parents.append(('us', start_chunk))
        parents.extend(marked)
        marked = parents

    return marked


class token(str):
    

    
    
    hide_when_equal = False

    def __new__(cls, text, pre_tags=None, post_tags=None, trailing_whitespace=""):
        obj = str.__new__(cls, text)

        obj.pre_tags = pre_tags if pre_tags is not None else []
        obj.post_tags = post_tags if post_tags is not None else []
        obj.trailing_whitespace = trailing_whitespace

        return obj

    def __repr__(self):
        return 'token(%s, %r, %r, %r)' % (
            str.__repr__(self), self.pre_tags, self.post_tags, self.trailing_whitespace)

    def html(self):
        return str(self)

class tag_token(token):

    

    def __new__(cls, tag, data, html_repr, pre_tags=None,
                post_tags=None, trailing_whitespace=""):
        obj = token.__new__(cls, f"{type}: {data}",
                            pre_tags=pre_tags,
                            post_tags=post_tags,
                            trailing_whitespace=trailing_whitespace)
        obj.tag = tag
        obj.data = data
        obj.html_repr = html_repr
        return obj

    def __repr__(self):
        return 'tag_token(%s, %s, html_repr=%s, post_tags=%r, pre_tags=%r, trailing_whitespace=%r)' % (
            self.tag,
            self.data,
            self.html_repr,
            self.pre_tags,
            self.post_tags,
            self.trailing_whitespace)
    def html(self):
        return self.html_repr

class href_token(token):

    

    hide_when_equal = True

    def html(self):
        return ' Link: %s' % self


def tokenize(html, include_hrefs=True):
    
    if etree.iselement(html):
        body_el = html
    else:
        body_el = parse_html(html, cleanup=True)
    
    chunks = flatten_el(body_el, skip_tag=True, include_hrefs=include_hrefs)
    
    return fixup_chunks(chunks)


def parse_html(html, cleanup=True):
    
    if cleanup:
        
        html = cleanup_html(html)
    return fragment_fromstring(html, create_parent=True)


_search_body = re.compile(r'<body.*?>', re.I|re.S).search
_search_end_body = re.compile(r'</body.*?>', re.I|re.S).search
_replace_ins_del = re.compile(r'</?(ins|del).*?>', re.I|re.S).sub

def cleanup_html(html):
    
    match = _search_body(html)
    if match:
        html = html[match.end():]
    match = _search_end_body(html)
    if match:
        html = html[:match.start()]
    html = _replace_ins_del('', html)
    return html


def split_trailing_whitespace(word):
    
    stripped_length = len(word.rstrip())
    return word[0:stripped_length], word[stripped_length:]


def fixup_chunks(chunks):
    
    tag_accum = []
    cur_word = None
    result = []
    for chunk in chunks:
        if isinstance(chunk, tuple):
            if chunk[0] == 'img':
                src = chunk[1]
                tag, trailing_whitespace = split_trailing_whitespace(chunk[2])
                cur_word = tag_token('img', src, html_repr=tag,
                                     pre_tags=tag_accum,
                                     trailing_whitespace=trailing_whitespace)
                tag_accum = []
                result.append(cur_word)

            elif chunk[0] == 'href':
                href = chunk[1]
                cur_word = href_token(href, pre_tags=tag_accum, trailing_whitespace=" ")
                tag_accum = []
                result.append(cur_word)
            continue

        if is_word(chunk):
            chunk, trailing_whitespace = split_trailing_whitespace(chunk)
            cur_word = token(chunk, pre_tags=tag_accum, trailing_whitespace=trailing_whitespace)
            tag_accum = []
            result.append(cur_word)

        elif is_start_tag(chunk):
            tag_accum.append(chunk)

        elif is_end_tag(chunk):
            if tag_accum:
                tag_accum.append(chunk)
            else:
                assert cur_word, (
                    "Weird state, cur_word=%r, result=%r, chunks=%r of %r"
                    % (cur_word, result, chunk, chunks))
                cur_word.post_tags.append(chunk)
        else:
            assert False

    if not result:
        return [token('', pre_tags=tag_accum)]
    else:
        result[-1].post_tags.extend(tag_accum)

    return result



empty_tags = cython.declare(frozenset, defs.empty_tags)

block_level_tags = cython.declare(frozenset, frozenset([
    'address',
    'blockquote',
    'center',
    'dir',
    'div',
    'dl',
    'fieldset',
    'form',
    'h1',
    'h2',
    'h3',
    'h4',
    'h5',
    'h6',
    'hr',
    'isindex',
    'menu',
    'noframes',
    'noscript',
    'ol',
    'p',
    'pre',
    'table',
    'ul',
]))

block_level_container_tags = cython.declare(frozenset, frozenset([
    'dd',
    'dt',
    'frameset',
    'li',
    'tbody',
    'td',
    'tfoot',
    'th',
    'thead',
    'tr',
]))

any_block_level_tag = cython.declare(tuple, tuple(sorted(
    block_level_tags | block_level_container_tags))
)


def flatten_el(el, include_hrefs, skip_tag=False):
    
    if not skip_tag:
        if el.tag == 'img':
            yield ('img', el.get('src'), start_tag(el))
        else:
            yield start_tag(el)
    if el.tag in empty_tags and not el.text and not len(el) and not el.tail:
        return
    start_words = split_words(el.text)
    for word in start_words:
        yield html_escape(word)
    for child in el:
        yield from flatten_el(child, include_hrefs=include_hrefs)
    if el.tag == 'a' and el.get('href') and include_hrefs:
        yield ('href', el.get('href'))
    if not skip_tag:
        yield end_tag(el)
        end_words = split_words(el.tail)
        for word in end_words:
            yield html_escape(word)

_find_words = re.compile(r'\S+(?:\s+|$)', re.U).findall

def split_words(text):
    
    if not text or not text.strip():
        return []

    words = _find_words(text)
    return words

_has_start_whitespace = re.compile(r'^[ \t\n\r]').match

def start_tag(el):
    
    attributes = ''.join([
        f' {name}="{html_escape(value)}"'
        for name, value in el.attrib.items()
    ])
    return f'<{el.tag}{attributes}>'

def end_tag(el):
    
    tail = el.tail
    extra = ' ' if tail and _has_start_whitespace(tail) else ''
    return f'</{el.tag}>{extra}'

def is_word(tok):
    return not tok.startswith('<')

def is_end_tag(tok):
    return tok.startswith('</')

def is_start_tag(tok):
    return tok.startswith('<') and not tok.startswith('</')

def fixup_ins_del_tags(html):
    
    doc = parse_html(html, cleanup=False)
    _fixup_ins_del_tags(doc)
    html = serialize_html_fragment(doc, skip_outer=True)
    return html

def serialize_html_fragment(el, skip_outer=False):
    
    assert not isinstance(el, str), (
        f"You should pass in an element, not a string like {el!r}")
    html = etree.tostring(el, method="html", encoding='unicode')
    if skip_outer:
        
        html = html[html.find('>')+1:]
        
        html = html[:html.rfind('<')]
        return html.strip()
    else:
        return html


@cython.cfunc
def _fixup_ins_del_tags(doc):
    
    for el in list(doc.iter('ins', 'del')):
        if not _contains_block_level_tag(el):
            continue
        _move_el_inside_block(el, tag=el.tag)
        el.drop_tag()
        


@cython.cfunc
def _contains_block_level_tag(el):
    
    for el in el.iter(*any_block_level_tag):
        return True
    return False


@cython.cfunc
def _move_el_inside_block(el, tag):
    
    makeelement = el.makeelement
    for block_level_el in el.iter(*any_block_level_tag):
        if block_level_el is not el:
            break
    else:
        
        children_tag = makeelement(tag)
        children_tag.text = el.text
        el.text = None
        children_tag.extend(iter(el))
        el[:] = [children_tag]
        return

    for child in list(el):
        if _contains_block_level_tag(child):
            _move_el_inside_block(child, tag)
            if child.tail:
                tail_tag = makeelement(tag)
                tail_tag.text = child.tail
                child.tail = None
                child.addnext(tail_tag)
        else:
            child_tag = makeelement(tag)
            el.replace(child, child_tag)
            child_tag.append(child)
    if el.text:
        text_tag = makeelement(tag)
        text_tag.text = el.text
        el.text = None
        el.insert(0, text_tag)


def _merge_element_contents(el):
    
    parent = el.getparent()
    text = el.text
    tail = el.tail
    if tail:
        if not len(el):
            text = (text or '') + tail
        else:
            el[-1].tail = (el[-1].tail or '') + tail
    index = parent.index(el)
    if text:
        previous = el.getprevious()
        if previous is None:
            parent.text = (parent.text or '') + text
        else:
            previous.tail = (previous.tail or '') + text
    parent[index:index+1] = el.getchildren()


@cython.final
@cython.cclass
class InsensitiveSequenceMatcher(SequenceMatcher):
    

    threshold = 2

    @cython.cfunc
    def get_matching_blocks(self) -> list:
        size: cython.Py_ssize_t = min(len(self.b), len(self.b))
        threshold: cython.Py_ssize_t = self.threshold
        threshold = min(threshold, size // 4)
        actual = SequenceMatcher.get_matching_blocks(self)
        return [item for item in actual
                if item[2] > threshold
                or not item[2]]


if __name__ == '__main__':
    from lxml.html import _diffcommand
    _diffcommand.main()
