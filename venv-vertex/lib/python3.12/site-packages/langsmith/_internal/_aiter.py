

import asyncio
import contextvars
import functools
import inspect
from collections import deque
from collections.abc import (
    AsyncGenerator,
    AsyncIterable,
    AsyncIterator,
    Awaitable,
    Coroutine,
    Iterable,
    Iterator,
)
from contextlib import AbstractAsyncContextManager
from typing import (
    Any,
    Callable,
    Generic,
    Optional,
    TypeVar,
    Union,
    cast,
    overload,
)

T = TypeVar("T")

_no_default = object()




def py_anext(
    iterator: AsyncIterator[T], default: Union[T, Any] = _no_default
) -> Awaitable[Union[T, None, Any]]:
    
    try:
        __anext__ = cast(
            Callable[[AsyncIterator[T]], Awaitable[T]], type(iterator).__anext__
        )
    except AttributeError:
        raise TypeError(f"{iterator!r} is not an async iterator")

    if default is _no_default:
        return __anext__(iterator)

    async def anext_impl() -> Union[T, Any]:
        try:
            
            
            
            
            
            return await __anext__(iterator)
        except StopAsyncIteration:
            return default

    return anext_impl()


class NoLock:
    

    async def __aenter__(self) -> None:
        pass

    async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> bool:
        return False


async def tee_peer(
    iterator: AsyncIterator[T],
    
    buffer: deque[T],
    
    peers: list[deque[T]],
    lock: AbstractAsyncContextManager[Any],
) -> AsyncGenerator[T, None]:
    
    try:
        while True:
            if not buffer:
                async with lock:
                    
                    
                    if buffer:
                        continue
                    try:
                        item = await iterator.__anext__()
                    except StopAsyncIteration:
                        break
                    else:
                        
                        
                        
                        
                        
                        for peer_buffer in peers:
                            peer_buffer.append(item)
            yield buffer.popleft()
    finally:
        async with lock:
            
            for idx, peer_buffer in enumerate(peers):  
                if peer_buffer is buffer:
                    peers.pop(idx)
                    break
            
            if not peers and hasattr(iterator, "aclose"):
                await iterator.aclose()


class Tee(Generic[T]):
    

    def __init__(
        self,
        iterable: AsyncIterator[T],
        n: int = 2,
        *,
        lock: Optional[AbstractAsyncContextManager[Any]] = None,
    ):
        self._iterator = iterable.__aiter__()  
        self._buffers: list[deque[T]] = [deque() for _ in range(n)]
        self._children = tuple(
            tee_peer(
                iterator=self._iterator,
                buffer=buffer,
                peers=self._buffers,
                lock=lock if lock is not None else NoLock(),
            )
            for buffer in self._buffers
        )

    def __len__(self) -> int:
        return len(self._children)

    @overload
    def __getitem__(self, item: int) -> AsyncIterator[T]: ...

    @overload
    def __getitem__(self, item: slice) -> tuple[AsyncIterator[T], ...]: ...

    def __getitem__(
        self, item: Union[int, slice]
    ) -> Union[AsyncIterator[T], tuple[AsyncIterator[T], ...]]:
        return self._children[item]

    def __iter__(self) -> Iterator[AsyncIterator[T]]:
        yield from self._children

    async def __aenter__(self) -> "Tee[T]":
        return self

    async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> bool:
        await self.aclose()
        return False

    async def aclose(self) -> None:
        for child in self._children:
            await child.aclose()


atee = Tee


async def async_zip(*async_iterables):
    
    
    iterators = [iterable.__aiter__() for iterable in async_iterables]
    while True:
        try:
            items = await asyncio.gather(
                *(py_anext(iterator) for iterator in iterators)
            )
            yield tuple(items)
        except StopAsyncIteration:
            break


def ensure_async_iterator(
    iterable: Union[Iterable, AsyncIterable],
) -> AsyncIterator:
    if hasattr(iterable, "__anext__"):
        return cast(AsyncIterator, iterable)
    elif hasattr(iterable, "__aiter__"):
        return cast(AsyncIterator, iterable.__aiter__())
    else:

        class AsyncIteratorWrapper:
            def __init__(self, iterable: Iterable):
                self._iterator = iter(iterable)

            async def __anext__(self):
                try:
                    return next(self._iterator)
                except StopIteration:
                    raise StopAsyncIteration

            def __aiter__(self):
                return self

        return AsyncIteratorWrapper(iterable)


def aiter_with_concurrency(
    n: Optional[int],
    generator: AsyncIterator[Coroutine[None, None, T]],
    *,
    _eager_consumption_timeout: float = 0,
) -> AsyncGenerator[T, None]:
    
    if n == 0:

        async def consume():
            async for item in generator:
                yield await item

        return consume()
    semaphore = cast(
        asyncio.Semaphore, asyncio.Semaphore(n) if n is not None else NoLock()
    )

    async def process_item(ix: int, item):
        async with semaphore:
            res = await item
            return (ix, res)

    async def process_generator():
        tasks = {}
        accepts_context = asyncio_accepts_context()
        ix = 0
        async for item in generator:
            if accepts_context:
                context = contextvars.copy_context()
                task = asyncio.create_task(process_item(ix, item), context=context)
            else:
                task = asyncio.create_task(process_item(ix, item))
            tasks[ix] = task
            ix += 1
            if _eager_consumption_timeout > 0:
                try:
                    for _fut in asyncio.as_completed(
                        tasks.values(),
                        timeout=_eager_consumption_timeout,
                    ):
                        task_idx, res = await _fut
                        yield res
                        del tasks[task_idx]
                except asyncio.TimeoutError:
                    pass
            if n is not None and len(tasks) >= n:
                done, _ = await asyncio.wait(
                    tasks.values(), return_when=asyncio.FIRST_COMPLETED
                )
                for task in done:
                    task_idx, res = task.result()
                    yield res
                    del tasks[task_idx]

        for task in asyncio.as_completed(tasks.values()):
            _, res = await task
            yield res

    return process_generator()


def accepts_context(callable: Callable[..., Any]) -> bool:
    
    try:
        return inspect.signature(callable).parameters.get("context") is not None
    except ValueError:
        return False



async def aio_to_thread(
    func, /, *args, __ctx: Optional[contextvars.Context] = None, **kwargs
):
    
    loop = asyncio.get_running_loop()
    ctx = __ctx or contextvars.copy_context()
    func_call = functools.partial(ctx.run, func, *args, **kwargs)
    return await loop.run_in_executor(None, func_call)


@functools.lru_cache(maxsize=1)
def asyncio_accepts_context():
    
    return accepts_context(asyncio.create_task)
