from __future__ import annotations

import platform
import sys
from collections.abc import Iterable, Mapping, Sequence
from functools import partial
from typing import TYPE_CHECKING, Any

from narwhals._expression_parsing import (
    ExprKind,
    ExprMetadata,
    apply_n_ary_operation,
    combine_metadata,
    extract_compliant,
    is_scalar_like,
)
from narwhals._utils import (
    Implementation,
    Version,
    deprecate_native_namespace,
    flatten,
    is_compliant_expr,
    is_eager_allowed,
    is_sequence_but_not_str,
    supports_arrow_c_stream,
    validate_laziness,
)
from narwhals.dependencies import (
    is_narwhals_series,
    is_numpy_array,
    is_numpy_array_2d,
    is_pyarrow_table,
)
from narwhals.exceptions import InvalidOperationError
from narwhals.expr import Expr
from narwhals.series import Series
from narwhals.translate import from_native, to_native

if TYPE_CHECKING:
    from types import ModuleType

    from typing_extensions import TypeAlias, TypeIs

    from narwhals._compliant import CompliantExpr, CompliantNamespace
    from narwhals._translate import IntoArrowTable
    from narwhals.dataframe import DataFrame, LazyFrame
    from narwhals.dtypes import DType
    from narwhals.schema import Schema
    from narwhals.typing import (
        ConcatMethod,
        FrameT,
        IntoDType,
        IntoExpr,
        NativeFrame,
        NativeLazyFrame,
        NativeSeries,
        NonNestedLiteral,
        _1DArray,
        _2DArray,
    )

    _IntoSchema: TypeAlias = "Mapping[str, DType] | Schema | Sequence[str] | None"


def concat(items: Iterable[FrameT], *, how: ConcatMethod = "vertical") -> FrameT:
    
    from narwhals.dependencies import is_narwhals_lazyframe

    if not items:
        msg = "No items to concatenate."
        raise ValueError(msg)
    items = list(items)
    validate_laziness(items)
    if how not in {"horizontal", "vertical", "diagonal"}:  
        msg = "Only vertical, horizontal and diagonal concatenations are supported."
        raise NotImplementedError(msg)
    first_item = items[0]
    if is_narwhals_lazyframe(first_item) and how == "horizontal":
        msg = (
            "Horizontal concatenation is not supported for LazyFrames.\n\n"
            "Hint: you may want to use `join` instead."
        )
        raise InvalidOperationError(msg)
    plx = first_item.__narwhals_namespace__()
    return first_item._with_compliant(
        plx.concat([df._compliant_frame for df in items], how=how)
    )


def new_series(
    name: str,
    values: Any,
    dtype: IntoDType | None = None,
    *,
    backend: ModuleType | Implementation | str,
) -> Series[Any]:
    
    return _new_series_impl(name, values, dtype, backend=backend)


def _new_series_impl(
    name: str,
    values: Any,
    dtype: IntoDType | None = None,
    *,
    backend: ModuleType | Implementation | str,
) -> Series[Any]:
    implementation = Implementation.from_backend(backend)
    if is_eager_allowed(implementation):
        ns = Version.MAIN.namespace.from_backend(implementation).compliant
        series = ns._series.from_iterable(values, name=name, context=ns, dtype=dtype)
        return series.to_narwhals()
    elif implementation is Implementation.UNKNOWN:  
        _native_namespace = implementation.to_native_namespace()
        try:
            native_series: NativeSeries = _native_namespace.new_series(
                name, values, dtype
            )
            return from_native(native_series, series_only=True).alias(name)
        except AttributeError as e:
            msg = "Unknown namespace is expected to implement `new_series` constructor."
            raise AttributeError(msg) from e
    msg = (
        f"{implementation} support in Narwhals is lazy-only, but `new_series` is an eager-only function.\n\n"
        "Hint: you may want to use an eager backend and then call `.lazy`, e.g.:\n\n"
        f"    nw.new_series('a', [1,2,3], backend='pyarrow').to_frame().lazy('{implementation}')"
    )
    raise ValueError(msg)


@deprecate_native_namespace(warn_version="1.26.0")
def from_dict(
    data: Mapping[str, Any],
    schema: Mapping[str, DType] | Schema | None = None,
    *,
    backend: ModuleType | Implementation | str | None = None,
    native_namespace: ModuleType | None = None,  
) -> DataFrame[Any]:
    
    if backend is None:
        data, backend = _from_dict_no_backend(data)
    implementation = Implementation.from_backend(backend)
    if is_eager_allowed(implementation):
        ns = Version.MAIN.namespace.from_backend(implementation).compliant
        return ns._dataframe.from_dict(data, schema=schema, context=ns).to_narwhals()
    elif implementation is Implementation.UNKNOWN:  
        _native_namespace = implementation.to_native_namespace()
        try:
            
            
            native_frame: NativeFrame = _native_namespace.from_dict(data, schema=schema)
        except AttributeError as e:
            msg = "Unknown namespace is expected to implement `from_dict` function."
            raise AttributeError(msg) from e
        return from_native(native_frame, eager_only=True)
    msg = (
        f"{implementation} support in Narwhals is lazy-only, but `from_dict` is an eager-only function.\n\n"
        "Hint: you may want to use an eager backend and then call `.lazy`, e.g.:\n\n"
        f"    nw.from_dict({{'a': [1, 2]}}, backend='pyarrow').lazy('{implementation}')"
    )
    raise ValueError(msg)


def _from_dict_no_backend(
    data: Mapping[str, Series[Any] | Any], /
) -> tuple[dict[str, Series[Any] | Any], ModuleType]:
    for val in data.values():
        if is_narwhals_series(val):
            native_namespace = val.__native_namespace__()
            break
    else:
        msg = "Calling `from_dict` without `backend` is only supported if all input values are already Narwhals Series"
        raise TypeError(msg)
    data = {key: to_native(value, pass_through=True) for key, value in data.items()}
    return data, native_namespace


def from_numpy(
    data: _2DArray,
    schema: Mapping[str, DType] | Schema | Sequence[str] | None = None,
    *,
    backend: ModuleType | Implementation | str,
) -> DataFrame[Any]:
    
    if not is_numpy_array_2d(data):
        msg = "`from_numpy` only accepts 2D numpy arrays"
        raise ValueError(msg)
    if not _is_into_schema(schema):
        msg = (
            "`schema` is expected to be one of the following types: "
            "Mapping[str, DType] | Schema | Sequence[str]. "
            f"Got {type(schema)}."
        )
        raise TypeError(msg)
    implementation = Implementation.from_backend(backend)
    if is_eager_allowed(implementation):
        ns = Version.MAIN.namespace.from_backend(implementation).compliant
        return ns.from_numpy(data, schema).to_narwhals()
    elif implementation is Implementation.UNKNOWN:  
        _native_namespace = implementation.to_native_namespace()
        try:
            
            
            native_frame: NativeFrame = _native_namespace.from_numpy(data, schema=schema)
        except AttributeError as e:
            msg = "Unknown namespace is expected to implement `from_numpy` function."
            raise AttributeError(msg) from e
        return from_native(native_frame, eager_only=True)
    msg = (
        f"{implementation} support in Narwhals is lazy-only, but `from_numpy` is an eager-only function.\n\n"
        "Hint: you may want to use an eager backend and then call `.lazy`, e.g.:\n\n"
        f"    nw.from_numpy(arr, backend='pyarrow').lazy('{implementation}')"
    )
    raise ValueError(msg)


def _is_into_schema(obj: Any) -> TypeIs[_IntoSchema]:
    from narwhals.schema import Schema

    return (
        obj is None or isinstance(obj, (Mapping, Schema)) or is_sequence_but_not_str(obj)
    )


def from_arrow(
    native_frame: IntoArrowTable, *, backend: ModuleType | Implementation | str
) -> DataFrame[Any]:  
    
    if not (supports_arrow_c_stream(native_frame) or is_pyarrow_table(native_frame)):
        msg = f"Given object of type {type(native_frame)} does not support PyCapsule interface"
        raise TypeError(msg)
    implementation = Implementation.from_backend(backend)
    if is_eager_allowed(implementation):
        ns = Version.MAIN.namespace.from_backend(implementation).compliant
        return ns._dataframe.from_arrow(native_frame, context=ns).to_narwhals()
    elif implementation is Implementation.UNKNOWN:  
        _native_namespace = implementation.to_native_namespace()
        try:
            
            
            native: NativeFrame = _native_namespace.DataFrame(native_frame)
        except AttributeError as e:
            msg = "Unknown namespace is expected to implement `DataFrame` class which accepts object which supports PyCapsule Interface."
            raise AttributeError(msg) from e
        return from_native(native, eager_only=True)
    msg = (
        f"{implementation} support in Narwhals is lazy-only, but `from_arrow` is an eager-only function.\n\n"
        "Hint: you may want to use an eager backend and then call `.lazy`, e.g.:\n\n"
        f"    nw.from_arrow(df, backend='pyarrow').lazy('{implementation}')"
    )
    raise ValueError(msg)


def _get_sys_info() -> dict[str, str]:
    
    python = sys.version.replace("\n", " ")

    blob = (
        ("python", python),
        ("executable", sys.executable),
        ("machine", platform.platform()),
    )

    return dict(blob)


def _get_deps_info() -> dict[str, str]:
    
    from importlib.metadata import distributions

    extra_names = ("narwhals", "numpy")
    member_names = Implementation._member_names_
    exclude = {"PYSPARK_CONNECT", "UNKNOWN"}
    target_names = tuple(
        name.lower() for name in (*extra_names, *member_names) if name not in exclude
    )
    result = dict.fromkeys(target_names, "")  

    for dist in distributions():
        dist_name, dist_version = dist.name.lower(), dist.version

        if dist_name in result:  
            result[dist_name] = dist_version
        else:  
            for target in target_names:
                if not result[target] and dist_name.startswith(target):
                    result[target] = dist_version
                    break

    return result


def show_versions() -> None:
    
    sys_info = _get_sys_info()
    deps_info = _get_deps_info()

    print("\nSystem:")  
    for k, stat in sys_info.items():
        print(f"{k:>10}: {stat}")  

    print("\nPython dependencies:")  
    for k, stat in deps_info.items():
        print(f"{k:>13}: {stat}")  


def read_csv(
    source: str, *, backend: ModuleType | Implementation | str, **kwargs: Any
) -> DataFrame[Any]:
    
    eager_backend = Implementation.from_backend(backend)
    native_namespace = eager_backend.to_native_namespace()
    native_frame: NativeFrame
    if eager_backend in {
        Implementation.POLARS,
        Implementation.PANDAS,
        Implementation.MODIN,
        Implementation.CUDF,
    }:
        native_frame = native_namespace.read_csv(source, **kwargs)
    elif eager_backend is Implementation.PYARROW:
        from pyarrow import csv  

        native_frame = csv.read_csv(source, **kwargs)
    else:  
        try:
            
            
            native_frame = native_namespace.read_csv(source=source, **kwargs)
        except AttributeError as e:
            msg = "Unknown namespace is expected to implement `read_csv` function."
            raise AttributeError(msg) from e
    return from_native(native_frame, eager_only=True)


def scan_csv(
    source: str, *, backend: ModuleType | Implementation | str, **kwargs: Any
) -> LazyFrame[Any]:
    
    implementation = Implementation.from_backend(backend)
    native_namespace = implementation.to_native_namespace()
    native_frame: NativeFrame | NativeLazyFrame
    if implementation is Implementation.POLARS:
        native_frame = native_namespace.scan_csv(source, **kwargs)
    elif implementation in {
        Implementation.PANDAS,
        Implementation.MODIN,
        Implementation.CUDF,
        Implementation.DASK,
        Implementation.DUCKDB,
        Implementation.IBIS,
    }:
        native_frame = native_namespace.read_csv(source, **kwargs)
    elif implementation is Implementation.PYARROW:
        from pyarrow import csv  

        native_frame = csv.read_csv(source, **kwargs)
    elif implementation.is_spark_like():
        if (session := kwargs.pop("session", None)) is None:
            msg = "Spark like backends require a session object to be passed in `kwargs`."
            raise ValueError(msg)

        csv_reader = session.read.format("csv")
        native_frame = (
            csv_reader.load(source)
            if (
                implementation is Implementation.SQLFRAME
                and implementation._backend_version() < (3, 27, 0)
            )
            else csv_reader.options(**kwargs).load(source)
        )
    else:  
        try:
            
            
            native_frame = native_namespace.scan_csv(source=source, **kwargs)
        except AttributeError as e:
            msg = "Unknown namespace is expected to implement `scan_csv` function."
            raise AttributeError(msg) from e
    return from_native(native_frame).lazy()


def read_parquet(
    source: str, *, backend: ModuleType | Implementation | str, **kwargs: Any
) -> DataFrame[Any]:
    
    implementation = Implementation.from_backend(backend)
    native_namespace = implementation.to_native_namespace()
    native_frame: NativeFrame
    if implementation in {
        Implementation.POLARS,
        Implementation.PANDAS,
        Implementation.MODIN,
        Implementation.CUDF,
        Implementation.DUCKDB,
        Implementation.IBIS,
    }:
        native_frame = native_namespace.read_parquet(source, **kwargs)
    elif implementation is Implementation.PYARROW:
        import pyarrow.parquet as pq  

        native_frame = pq.read_table(source, **kwargs)
    else:  
        try:
            
            
            native_frame = native_namespace.read_parquet(source=source, **kwargs)
        except AttributeError as e:
            msg = "Unknown namespace is expected to implement `read_parquet` function."
            raise AttributeError(msg) from e
    return from_native(native_frame, eager_only=True)


def scan_parquet(
    source: str, *, backend: ModuleType | Implementation | str, **kwargs: Any
) -> LazyFrame[Any]:
    
    implementation = Implementation.from_backend(backend)
    native_namespace = implementation.to_native_namespace()
    native_frame: NativeFrame | NativeLazyFrame
    if implementation is Implementation.POLARS:
        native_frame = native_namespace.scan_parquet(source, **kwargs)
    elif implementation in {
        Implementation.PANDAS,
        Implementation.MODIN,
        Implementation.CUDF,
        Implementation.DASK,
        Implementation.DUCKDB,
        Implementation.IBIS,
    }:
        native_frame = native_namespace.read_parquet(source, **kwargs)
    elif implementation is Implementation.PYARROW:
        import pyarrow.parquet as pq  

        native_frame = pq.read_table(source, **kwargs)
    elif implementation.is_spark_like():
        if (session := kwargs.pop("session", None)) is None:
            msg = "Spark like backends require a session object to be passed in `kwargs`."
            raise ValueError(msg)

        pq_reader = session.read.format("parquet")
        native_frame = (
            pq_reader.load(source)
            if (
                implementation is Implementation.SQLFRAME
                and implementation._backend_version() < (3, 27, 0)
            )
            else pq_reader.options(**kwargs).load(source)
        )

    else:  
        try:
            
            
            native_frame = native_namespace.scan_parquet(source=source, **kwargs)
        except AttributeError as e:
            msg = "Unknown namespace is expected to implement `scan_parquet` function."
            raise AttributeError(msg) from e
    return from_native(native_frame).lazy()


def col(*names: str | Iterable[str]) -> Expr:
    
    flat_names = flatten(names)

    def func(plx: Any) -> Any:
        return plx.col(*flat_names)

    return Expr(
        func,
        ExprMetadata.selector_single()
        if len(flat_names) == 1
        else ExprMetadata.selector_multi_named(),
    )


def exclude(*names: str | Iterable[str]) -> Expr:
    
    exclude_names = frozenset(flatten(names))

    def func(plx: Any) -> Any:
        return plx.exclude(exclude_names)

    return Expr(func, ExprMetadata.selector_multi_unnamed())


def nth(*indices: int | Sequence[int]) -> Expr:
    
    flat_indices = flatten(indices)

    def func(plx: Any) -> Any:
        return plx.nth(*flat_indices)

    return Expr(
        func,
        ExprMetadata.selector_single()
        if len(flat_indices) == 1
        else ExprMetadata.selector_multi_unnamed(),
    )



def all_() -> Expr:
    
    return Expr(lambda plx: plx.all(), ExprMetadata.selector_multi_unnamed())



def len_() -> Expr:
    

    def func(plx: Any) -> Any:
        return plx.len()

    return Expr(func, ExprMetadata.aggregation())


def sum(*columns: str) -> Expr:
    
    return col(*columns).sum()


def mean(*columns: str) -> Expr:
    
    return col(*columns).mean()


def median(*columns: str) -> Expr:
    
    return col(*columns).median()


def min(*columns: str) -> Expr:
    
    return col(*columns).min()


def max(*columns: str) -> Expr:
    
    return col(*columns).max()


def sum_horizontal(*exprs: IntoExpr | Iterable[IntoExpr]) -> Expr:
    
    if not exprs:
        msg = "At least one expression must be passed to `sum_horizontal`"
        raise ValueError(msg)
    flat_exprs = flatten(exprs)
    return Expr(
        lambda plx: apply_n_ary_operation(
            plx, plx.sum_horizontal, *flat_exprs, str_as_lit=False
        ),
        ExprMetadata.from_horizontal_op(*flat_exprs),
    )


def min_horizontal(*exprs: IntoExpr | Iterable[IntoExpr]) -> Expr:
    
    if not exprs:
        msg = "At least one expression must be passed to `min_horizontal`"
        raise ValueError(msg)
    flat_exprs = flatten(exprs)
    return Expr(
        lambda plx: apply_n_ary_operation(
            plx, plx.min_horizontal, *flat_exprs, str_as_lit=False
        ),
        ExprMetadata.from_horizontal_op(*flat_exprs),
    )


def max_horizontal(*exprs: IntoExpr | Iterable[IntoExpr]) -> Expr:
    
    if not exprs:
        msg = "At least one expression must be passed to `max_horizontal`"
        raise ValueError(msg)
    flat_exprs = flatten(exprs)
    return Expr(
        lambda plx: apply_n_ary_operation(
            plx, plx.max_horizontal, *flat_exprs, str_as_lit=False
        ),
        ExprMetadata.from_horizontal_op(*flat_exprs),
    )


class When:
    def __init__(self, *predicates: IntoExpr | Iterable[IntoExpr]) -> None:
        self._predicate = all_horizontal(*flatten(predicates), ignore_nulls=False)

    def then(self, value: IntoExpr | NonNestedLiteral | _1DArray) -> Then:
        kind = ExprKind.from_into_expr(value, str_as_lit=False)
        if self._predicate._metadata.is_scalar_like and not kind.is_scalar_like:
            msg = (
                "If you pass a scalar-like predicate to `nw.when`, then "
                "the `then` value must also be scalar-like."
            )
            raise InvalidOperationError(msg)

        return Then(
            lambda plx: apply_n_ary_operation(
                plx,
                lambda *args: plx.when(args[0]).then(args[1]),
                self._predicate,
                value,
                str_as_lit=False,
            ),
            combine_metadata(
                self._predicate,
                value,
                str_as_lit=False,
                allow_multi_output=False,
                to_single_output=False,
            ),
        )


class Then(Expr):
    def otherwise(self, value: IntoExpr | NonNestedLiteral | _1DArray) -> Expr:
        kind = ExprKind.from_into_expr(value, str_as_lit=False)
        if self._metadata.is_scalar_like and not is_scalar_like(kind):
            msg = (
                "If you pass a scalar-like predicate to `nw.when`, then "
                "the `otherwise` value must also be scalar-like."
            )
            raise InvalidOperationError(msg)

        def func(plx: CompliantNamespace[Any, Any]) -> CompliantExpr[Any, Any]:
            compliant_expr = self._to_compliant_expr(plx)
            compliant_value = extract_compliant(plx, value, str_as_lit=False)
            if (
                not self._metadata.is_scalar_like
                and is_scalar_like(kind)
                and is_compliant_expr(compliant_value)
            ):
                compliant_value = compliant_value.broadcast(kind)
            return compliant_expr.otherwise(compliant_value)  

        return Expr(
            func,
            combine_metadata(
                self,
                value,
                str_as_lit=False,
                allow_multi_output=False,
                to_single_output=False,
            ),
        )


def when(*predicates: IntoExpr | Iterable[IntoExpr]) -> When:
    
    return When(*predicates)


def all_horizontal(*exprs: IntoExpr | Iterable[IntoExpr], ignore_nulls: bool) -> Expr:
    r
    if not exprs:
        msg = "At least one expression must be passed to `all_horizontal`"
        raise ValueError(msg)
    flat_exprs = flatten(exprs)
    return Expr(
        lambda plx: apply_n_ary_operation(
            plx,
            partial(plx.all_horizontal, ignore_nulls=ignore_nulls),
            *flat_exprs,
            str_as_lit=False,
        ),
        ExprMetadata.from_horizontal_op(*flat_exprs),
    )


def lit(value: NonNestedLiteral, dtype: IntoDType | None = None) -> Expr:
    
    if is_numpy_array(value):
        msg = (
            "numpy arrays are not supported as literal values. "
            "Consider using `with_columns` to create a new column from the array."
        )
        raise ValueError(msg)

    if isinstance(value, (list, tuple)):
        msg = f"Nested datatypes are not supported yet. Got {value}"
        raise NotImplementedError(msg)

    return Expr(lambda plx: plx.lit(value, dtype), ExprMetadata.literal())


def any_horizontal(*exprs: IntoExpr | Iterable[IntoExpr], ignore_nulls: bool) -> Expr:
    r
    if not exprs:
        msg = "At least one expression must be passed to `any_horizontal`"
        raise ValueError(msg)
    flat_exprs = flatten(exprs)
    return Expr(
        lambda plx: apply_n_ary_operation(
            plx,
            partial(plx.any_horizontal, ignore_nulls=ignore_nulls),
            *flat_exprs,
            str_as_lit=False,
        ),
        ExprMetadata.from_horizontal_op(*flat_exprs),
    )


def mean_horizontal(*exprs: IntoExpr | Iterable[IntoExpr]) -> Expr:
    
    if not exprs:
        msg = "At least one expression must be passed to `mean_horizontal`"
        raise ValueError(msg)
    flat_exprs = flatten(exprs)
    return Expr(
        lambda plx: apply_n_ary_operation(
            plx, plx.mean_horizontal, *flat_exprs, str_as_lit=False
        ),
        ExprMetadata.from_horizontal_op(*flat_exprs),
    )


def concat_str(
    exprs: IntoExpr | Iterable[IntoExpr],
    *more_exprs: IntoExpr,
    separator: str = "",
    ignore_nulls: bool = False,
) -> Expr:
    r
    flat_exprs = flatten([*flatten([exprs]), *more_exprs])
    return Expr(
        lambda plx: apply_n_ary_operation(
            plx,
            lambda *args: plx.concat_str(
                *args, separator=separator, ignore_nulls=ignore_nulls
            ),
            *flat_exprs,
            str_as_lit=False,
        ),
        combine_metadata(
            *flat_exprs, str_as_lit=False, allow_multi_output=True, to_single_output=True
        ),
    )


def coalesce(
    exprs: IntoExpr | Iterable[IntoExpr], *more_exprs: IntoExpr | NonNestedLiteral
) -> Expr:
    
    flat_exprs = flatten([*flatten([exprs]), *more_exprs])

    non_exprs = [expr for expr in flat_exprs if not isinstance(expr, (str, Expr, Series))]
    if non_exprs:
        msg = (
            f"All arguments to `coalesce` must be of type {str!r}, {Expr!r}, or {Series!r}."
            "\nGot the following invalid arguments (type, value):"
            f"\n    {', '.join(repr((type(e), e)) for e in non_exprs)}"
        )
        raise TypeError(msg)

    return Expr(
        lambda plx: apply_n_ary_operation(
            plx, lambda *args: plx.coalesce(*args), *flat_exprs, str_as_lit=False
        ),
        ExprMetadata.from_horizontal_op(*flat_exprs),
    )
