from __future__ import annotations

from abc import abstractmethod
from itertools import chain
from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    ClassVar,
    Generic,
    Literal,
    NoReturn,
    TypeVar,
    overload,
)

from narwhals._exceptions import issue_warning
from narwhals._expression_parsing import (
    ExprKind,
    all_exprs_are_scalar_like,
    check_expressions_preserve_length,
    is_scalar_like,
)
from narwhals._utils import (
    Implementation,
    Version,
    flatten,
    generate_repr,
    is_compliant_dataframe,
    is_compliant_lazyframe,
    is_eager_allowed,
    is_index_selector,
    is_list_of,
    is_sequence_like,
    is_slice_none,
    supports_arrow_c_stream,
)
from narwhals.dependencies import (
    get_polars,
    is_numpy_array,
    is_numpy_array_2d,
    is_pyarrow_table,
)
from narwhals.exceptions import (
    InvalidIntoExprError,
    InvalidOperationError,
    PerformanceWarning,
)
from narwhals.functions import _from_dict_no_backend, _is_into_schema
from narwhals.schema import Schema
from narwhals.series import Series
from narwhals.translate import to_native

if TYPE_CHECKING:
    from collections.abc import Iterable, Iterator, Mapping, Sequence
    from io import BytesIO
    from pathlib import Path
    from types import ModuleType

    import pandas as pd
    import polars as pl
    import pyarrow as pa
    from typing_extensions import Concatenate, ParamSpec, Self, TypeAlias

    from narwhals._compliant import CompliantDataFrame, CompliantLazyFrame
    from narwhals._compliant.typing import CompliantExprAny, EagerNamespaceAny
    from narwhals._translate import IntoArrowTable
    from narwhals.dtypes import DType
    from narwhals.group_by import GroupBy, LazyGroupBy
    from narwhals.typing import (
        AsofJoinStrategy,
        IntoDataFrame,
        IntoExpr,
        IntoFrame,
        JoinStrategy,
        LazyUniqueKeepStrategy,
        MultiColSelector as _MultiColSelector,
        MultiIndexSelector as _MultiIndexSelector,
        PivotAgg,
        SingleColSelector,
        SingleIndexSelector,
        SizeUnit,
        UniqueKeepStrategy,
        _2DArray,
    )

    PS = ParamSpec("PS")

_FrameT = TypeVar("_FrameT", bound="IntoFrame")
FrameT = TypeVar("FrameT", bound="IntoFrame")
DataFrameT = TypeVar("DataFrameT", bound="IntoDataFrame")
R = TypeVar("R")

MultiColSelector: TypeAlias = "_MultiColSelector[Series[Any]]"
MultiIndexSelector: TypeAlias = "_MultiIndexSelector[Series[Any]]"


class BaseFrame(Generic[_FrameT]):
    _compliant_frame: Any
    _level: Literal["full", "lazy", "interchange"]

    def __native_namespace__(self) -> ModuleType:
        return self._compliant_frame.__native_namespace__()  

    def __narwhals_namespace__(self) -> Any:
        return self._compliant_frame.__narwhals_namespace__()

    def _with_compliant(self, df: Any) -> Self:
        
        return self.__class__(df, level=self._level)  

    def _flatten_and_extract(
        self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr
    ) -> tuple[list[CompliantExprAny], list[ExprKind]]:
        
        out_exprs = []
        out_kinds = []
        for expr in flatten(exprs):
            compliant_expr = self._extract_compliant(expr)
            out_exprs.append(compliant_expr)
            out_kinds.append(ExprKind.from_into_expr(expr, str_as_lit=False))
        for alias, expr in named_exprs.items():
            compliant_expr = self._extract_compliant(expr).alias(alias)
            out_exprs.append(compliant_expr)
            out_kinds.append(ExprKind.from_into_expr(expr, str_as_lit=False))
        return out_exprs, out_kinds

    @abstractmethod
    def _extract_compliant(self, arg: Any) -> Any:
        raise NotImplementedError

    @property
    def schema(self) -> Schema:
        return Schema(self._compliant_frame.schema.items())

    def collect_schema(self) -> Schema:
        native_schema = dict(self._compliant_frame.collect_schema())

        return Schema(native_schema)

    def pipe(
        self,
        function: Callable[Concatenate[Self, PS], R],
        *args: PS.args,
        **kwargs: PS.kwargs,
    ) -> R:
        return function(self, *args, **kwargs)

    def drop_nulls(self, subset: str | list[str] | None) -> Self:
        subset = [subset] if isinstance(subset, str) else subset
        return self._with_compliant(self._compliant_frame.drop_nulls(subset=subset))

    @property
    def columns(self) -> list[str]:
        return self._compliant_frame.columns  

    def with_columns(
        self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr
    ) -> Self:
        compliant_exprs, kinds = self._flatten_and_extract(*exprs, **named_exprs)
        compliant_exprs = [
            compliant_expr.broadcast(kind) if is_scalar_like(kind) else compliant_expr
            for compliant_expr, kind in zip(compliant_exprs, kinds)
        ]
        return self._with_compliant(self._compliant_frame.with_columns(*compliant_exprs))

    def select(
        self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr
    ) -> Self:
        flat_exprs = tuple(flatten(exprs))
        if flat_exprs and all(isinstance(x, str) for x in flat_exprs) and not named_exprs:
            
            try:
                return self._with_compliant(
                    self._compliant_frame.simple_select(*flat_exprs)
                )
            except Exception as e:
                
                if error := self._compliant_frame._check_columns_exist(flat_exprs):
                    raise error from e
                raise
        compliant_exprs, kinds = self._flatten_and_extract(*flat_exprs, **named_exprs)
        if compliant_exprs and all_exprs_are_scalar_like(*flat_exprs, **named_exprs):
            return self._with_compliant(self._compliant_frame.aggregate(*compliant_exprs))
        compliant_exprs = [
            compliant_expr.broadcast(kind) if is_scalar_like(kind) else compliant_expr
            for compliant_expr, kind in zip(compliant_exprs, kinds)
        ]
        return self._with_compliant(self._compliant_frame.select(*compliant_exprs))

    def rename(self, mapping: dict[str, str]) -> Self:
        return self._with_compliant(self._compliant_frame.rename(mapping))

    def head(self, n: int) -> Self:
        return self._with_compliant(self._compliant_frame.head(n))

    def tail(self, n: int) -> Self:
        return self._with_compliant(self._compliant_frame.tail(n))

    def drop(self, *columns: Iterable[str], strict: bool) -> Self:
        return self._with_compliant(self._compliant_frame.drop(columns, strict=strict))

    def filter(
        self, *predicates: IntoExpr | Iterable[IntoExpr] | list[bool], **constraints: Any
    ) -> Self:
        if len(predicates) == 1 and is_list_of(predicates[0], bool):
            predicate = predicates[0]
        else:
            from narwhals.functions import col

            flat_predicates = flatten(predicates)
            check_expressions_preserve_length(*flat_predicates, function_name="filter")
            plx = self.__narwhals_namespace__()
            compliant_predicates, _kinds = self._flatten_and_extract(*flat_predicates)
            compliant_constraints = (
                (col(name) == v)._to_compliant_expr(plx)
                for name, v in constraints.items()
            )
            predicate = plx.all_horizontal(
                *chain(compliant_predicates, compliant_constraints), ignore_nulls=False
            )
        return self._with_compliant(self._compliant_frame.filter(predicate))

    def sort(
        self,
        by: str | Iterable[str],
        *more_by: str,
        descending: bool | Sequence[bool] = False,
        nulls_last: bool = False,
    ) -> Self:
        by = flatten([*flatten([by]), *more_by])
        return self._with_compliant(
            self._compliant_frame.sort(*by, descending=descending, nulls_last=nulls_last)
        )

    def join(
        self,
        other: Self,
        on: str | list[str] | None,
        how: JoinStrategy,
        *,
        left_on: str | list[str] | None,
        right_on: str | list[str] | None,
        suffix: str,
    ) -> Self:
        _supported_joins = ("inner", "left", "full", "cross", "anti", "semi")
        on = [on] if isinstance(on, str) else on
        left_on = [left_on] if isinstance(left_on, str) else left_on
        right_on = [right_on] if isinstance(right_on, str) else right_on
        compliant = self._compliant_frame
        other = self._extract_compliant(other)

        if how not in _supported_joins:
            msg = f"Only the following join strategies are supported: {_supported_joins}; found '{how}'."
            raise NotImplementedError(msg)
        if how == "cross":
            if left_on is not None or right_on is not None or on is not None:
                msg = "Can not pass `left_on`, `right_on` or `on` keys for cross join"
                raise ValueError(msg)
            result = compliant.join(
                other, how=how, left_on=None, right_on=None, suffix=suffix
            )
        elif on is None:
            if left_on is None or right_on is None:
                msg = f"Either (`left_on` and `right_on`) or `on` keys should be specified for {how}."
                raise ValueError(msg)
            if len(left_on) != len(right_on):
                msg = "`left_on` and `right_on` must have the same length."
                raise ValueError(msg)
            result = compliant.join(
                other, how=how, left_on=left_on, right_on=right_on, suffix=suffix
            )
        else:
            if left_on is not None or right_on is not None:
                msg = f"If `on` is specified, `left_on` and `right_on` should be None for {how}."
                raise ValueError(msg)
            result = compliant.join(
                other, how=how, left_on=on, right_on=on, suffix=suffix
            )
        return self._with_compliant(result)

    def gather_every(self, n: int, offset: int = 0) -> Self:
        return self._with_compliant(
            self._compliant_frame.gather_every(n=n, offset=offset)
        )

    def join_asof(
        self,
        other: Self,
        *,
        left_on: str | None,
        right_on: str | None,
        on: str | None,
        by_left: str | list[str] | None,
        by_right: str | list[str] | None,
        by: str | list[str] | None,
        strategy: AsofJoinStrategy,
        suffix: str,
    ) -> Self:
        _supported_strategies = ("backward", "forward", "nearest")

        if strategy not in _supported_strategies:
            msg = f"Only the following strategies are supported: {_supported_strategies}; found '{strategy}'."
            raise NotImplementedError(msg)

        if (on is None) and (left_on is None or right_on is None):
            msg = "Either (`left_on` and `right_on`) or `on` keys should be specified."
            raise ValueError(msg)
        if (on is not None) and (left_on is not None or right_on is not None):
            msg = "If `on` is specified, `left_on` and `right_on` should be None."
            raise ValueError(msg)
        if (by is None) and (
            (by_left is None and by_right is not None)
            or (by_left is not None and by_right is None)
        ):
            msg = (
                "Can not specify only `by_left` or `by_right`, you need to specify both."
            )
            raise ValueError(msg)
        if (by is not None) and (by_left is not None or by_right is not None):
            msg = "If `by` is specified, `by_left` and `by_right` should be None."
            raise ValueError(msg)
        if on is not None:
            left_on = right_on = on
        if by is not None:
            by_left = by_right = by

        by_left = [by_left] if isinstance(by_left, str) else by_left
        by_right = [by_right] if isinstance(by_right, str) else by_right

        if (isinstance(by_left, list) and isinstance(by_right, list)) and (
            len(by_left) != len(by_right)
        ):
            msg = "`by_left` and `by_right` must have the same length."
            raise ValueError(msg)

        return self._with_compliant(
            self._compliant_frame.join_asof(
                self._extract_compliant(other),
                left_on=left_on,
                right_on=right_on,
                by_left=by_left,
                by_right=by_right,
                strategy=strategy,
                suffix=suffix,
            )
        )

    def unpivot(
        self,
        on: str | list[str] | None,
        *,
        index: str | list[str] | None,
        variable_name: str,
        value_name: str,
    ) -> Self:
        on = [on] if isinstance(on, str) else on
        index = [index] if isinstance(index, str) else index

        return self._with_compliant(
            self._compliant_frame.unpivot(
                on=on, index=index, variable_name=variable_name, value_name=value_name
            )
        )

    def __neq__(self, other: object) -> NoReturn:
        msg = (
            "DataFrame.__neq__ and LazyFrame.__neq__ are not implemented, please "
            "use expressions instead.\n\n"
            "Hint: instead of\n"
            "    df != 0\n"
            "you may want to use\n"
            "    df.select(nw.all() != 0)"
        )
        raise NotImplementedError(msg)

    def __eq__(self, other: object) -> NoReturn:
        msg = (
            "DataFrame.__eq__ and LazyFrame.__eq__ are not implemented, please "
            "use expressions instead.\n\n"
            "Hint: instead of\n"
            "    df == 0\n"
            "you may want to use\n"
            "    df.select(nw.all() == 0)"
        )
        raise NotImplementedError(msg)

    def explode(self, columns: str | Sequence[str], *more_columns: str) -> Self:
        to_explode = (
            [columns, *more_columns]
            if isinstance(columns, str)
            else [*columns, *more_columns]
        )

        return self._with_compliant(self._compliant_frame.explode(columns=to_explode))


class DataFrame(BaseFrame[DataFrameT]):
    

    _version: ClassVar[Version] = Version.MAIN

    def _extract_compliant(self, arg: Any) -> Any:
        from narwhals.expr import Expr
        from narwhals.series import Series

        plx: EagerNamespaceAny = self.__narwhals_namespace__()
        if isinstance(arg, BaseFrame):
            return arg._compliant_frame
        if isinstance(arg, Series):
            return arg._compliant_series._to_expr()
        if isinstance(arg, Expr):
            return arg._to_compliant_expr(self.__narwhals_namespace__())
        if isinstance(arg, str):
            return plx.col(arg)
        if get_polars() is not None and "polars" in str(type(arg)):  
            msg = (
                f"Expected Narwhals object, got: {type(arg)}.\n\n"
                "Perhaps you:\n"
                "- Forgot a `nw.from_native` somewhere?\n"
                "- Used `pl.col` instead of `nw.col`?"
            )
            raise TypeError(msg)
        if is_numpy_array(arg):
            return plx._series.from_numpy(arg, context=plx)._to_expr()
        raise InvalidIntoExprError.from_invalid_type(type(arg))

    @property
    def _series(self) -> type[Series[Any]]:
        return Series

    @property
    def _lazyframe(self) -> type[LazyFrame[Any]]:
        return LazyFrame

    def __init__(self, df: Any, *, level: Literal["full", "lazy", "interchange"]) -> None:
        self._level: Literal["full", "lazy", "interchange"] = level
        
        self._compliant_frame: CompliantDataFrame[Any, Any, DataFrameT, Self]  
        if is_compliant_dataframe(df):
            self._compliant_frame = df.__narwhals_dataframe__()
        else:  
            msg = f"Expected an object which implements `__narwhals_dataframe__`, got: {type(df)}"
            raise AssertionError(msg)

    @classmethod
    def from_arrow(
        cls, native_frame: IntoArrowTable, *, backend: ModuleType | Implementation | str
    ) -> DataFrame[Any]:
        
        if not (supports_arrow_c_stream(native_frame) or is_pyarrow_table(native_frame)):
            msg = f"Given object of type {type(native_frame)} does not support PyCapsule interface"
            raise TypeError(msg)
        implementation = Implementation.from_backend(backend)
        if is_eager_allowed(implementation):
            ns = cls._version.namespace.from_backend(implementation).compliant
            compliant = ns._dataframe.from_arrow(native_frame, context=ns)
            return cls(compliant, level="full")
        msg = (
            f"{implementation} support in Narwhals is lazy-only, but `DataFrame.from_arrow` is an eager-only function.\n\n"
            "Hint: you may want to use an eager backend and then call `.lazy`, e.g.:\n\n"
            f"    nw.DataFrame.from_arrow(df, backend='pyarrow').lazy('{implementation}')"
        )
        raise ValueError(msg)

    @classmethod
    def from_dict(
        cls,
        data: Mapping[str, Any],
        schema: Mapping[str, DType] | Schema | None = None,
        *,
        backend: ModuleType | Implementation | str | None = None,
    ) -> DataFrame[Any]:
        
        if backend is None:
            data, backend = _from_dict_no_backend(data)
        implementation = Implementation.from_backend(backend)
        if is_eager_allowed(implementation):
            ns = cls._version.namespace.from_backend(implementation).compliant
            compliant = ns._dataframe.from_dict(data, schema=schema, context=ns)
            return cls(compliant, level="full")
        
        msg = (
            f"{implementation} support in Narwhals is lazy-only, but `DataFrame.from_dict` is an eager-only function.\n\n"
            "Hint: you may want to use an eager backend and then call `.lazy`, e.g.:\n\n"
            f"    nw.DataFrame.from_dict({{'a': [1, 2]}}, backend='pyarrow').lazy('{implementation}')"
        )
        raise ValueError(msg)

    @classmethod
    def from_numpy(
        cls,
        data: _2DArray,
        schema: Mapping[str, DType] | Schema | Sequence[str] | None = None,
        *,
        backend: ModuleType | Implementation | str,
    ) -> DataFrame[Any]:
        
        if not is_numpy_array_2d(data):
            msg = "`from_numpy` only accepts 2D numpy arrays"
            raise ValueError(msg)
        if not _is_into_schema(schema):
            msg = (
                "`schema` is expected to be one of the following types: "
                "Mapping[str, DType] | Schema | Sequence[str]. "
                f"Got {type(schema)}."
            )
            raise TypeError(msg)
        implementation = Implementation.from_backend(backend)
        if is_eager_allowed(implementation):
            ns = cls._version.namespace.from_backend(implementation).compliant
            return cls(ns.from_numpy(data, schema), level="full")
        msg = (
            f"{implementation} support in Narwhals is lazy-only, but `DataFrame.from_numpy` is an eager-only function.\n\n"
            "Hint: you may want to use an eager backend and then call `.lazy`, e.g.:\n\n"
            f"    nw.DataFrame.from_numpy(arr, backend='pyarrow').lazy('{implementation}')"
        )
        raise ValueError(msg)

    @property
    def implementation(self) -> Implementation:
        
        return self._compliant_frame._implementation

    def __len__(self) -> int:
        return self._compliant_frame.__len__()

    def __array__(self, dtype: Any = None, copy: bool | None = None) -> _2DArray:  
        return self._compliant_frame.__array__(dtype, copy=copy)

    def __repr__(self) -> str:  
        return generate_repr("Narwhals DataFrame", self.to_native().__repr__())

    def __arrow_c_stream__(self, requested_schema: object | None = None) -> object:
        
        native_frame = self._compliant_frame._native_frame
        if supports_arrow_c_stream(native_frame):
            return native_frame.__arrow_c_stream__(requested_schema=requested_schema)
        try:
            pa_version = Implementation.PYARROW._backend_version()
        except ModuleNotFoundError as exc:  
            msg = f"'pyarrow>=14.0.0' is required for `DataFrame.__arrow_c_stream__` for object of type {type(native_frame)}"
            raise ModuleNotFoundError(msg) from exc
        if pa_version < (14, 0):  
            msg = f"'pyarrow>=14.0.0' is required for `DataFrame.__arrow_c_stream__` for object of type {type(native_frame)}"
            raise ModuleNotFoundError(msg) from None
        pa_table = self.to_arrow()
        return pa_table.__arrow_c_stream__(requested_schema=requested_schema)  

    def lazy(
        self, backend: ModuleType | Implementation | str | None = None
    ) -> LazyFrame[Any]:
        
        lazy_backend = None if backend is None else Implementation.from_backend(backend)
        supported_lazy_backends = (
            Implementation.DASK,
            Implementation.DUCKDB,
            Implementation.POLARS,
            Implementation.IBIS,
        )
        if lazy_backend is not None and lazy_backend not in supported_lazy_backends:
            msg = (
                "Not-supported backend."
                f"\n\nExpected one of {supported_lazy_backends} or `None`, got {lazy_backend}"
            )
            raise ValueError(msg)
        return self._lazyframe(
            self._compliant_frame.lazy(backend=lazy_backend), level="lazy"
        )

    def to_native(self) -> DataFrameT:
        
        return self._compliant_frame._native_frame

    def to_pandas(self) -> pd.DataFrame:
        
        return self._compliant_frame.to_pandas()

    def to_polars(self) -> pl.DataFrame:
        
        return self._compliant_frame.to_polars()

    @overload
    def write_csv(self, file: None = None) -> str: ...

    @overload
    def write_csv(self, file: str | Path | BytesIO) -> None: ...

    def write_csv(self, file: str | Path | BytesIO | None = None) -> str | None:
        r
        return self._compliant_frame.write_csv(file)

    def write_parquet(self, file: str | Path | BytesIO) -> None:
        
        self._compliant_frame.write_parquet(file)

    def to_numpy(self) -> _2DArray:
        
        return self._compliant_frame.to_numpy(None, copy=None)

    @property
    def shape(self) -> tuple[int, int]:
        
        return self._compliant_frame.shape

    def get_column(self, name: str) -> Series[Any]:
        
        return self._series(self._compliant_frame.get_column(name), level=self._level)

    def estimated_size(self, unit: SizeUnit = "b") -> int | float:
        
        return self._compliant_frame.estimated_size(unit=unit)

    
    
    @overload
    def __getitem__(self, item: tuple[SingleIndexSelector, SingleColSelector]) -> Any: ...

    @overload
    def __getitem__(  
        self, item: str | tuple[MultiIndexSelector, SingleColSelector]
    ) -> Series[Any]: ...

    @overload
    def __getitem__(
        self,
        item: (
            SingleIndexSelector
            | MultiIndexSelector
            | MultiColSelector
            | tuple[SingleIndexSelector, MultiColSelector]
            | tuple[MultiIndexSelector, MultiColSelector]
        ),
    ) -> Self: ...
    def __getitem__(  
        self,
        item: (
            SingleIndexSelector
            | SingleColSelector
            | MultiColSelector
            | MultiIndexSelector
            | tuple[SingleIndexSelector, SingleColSelector]
            | tuple[SingleIndexSelector, MultiColSelector]
            | tuple[MultiIndexSelector, SingleColSelector]
            | tuple[MultiIndexSelector, MultiColSelector]
        ),
    ) -> Series[Any] | Self | Any:
        
        from narwhals.series import Series

        msg = (
            f"Unexpected type for `DataFrame.__getitem__`, got: {type(item)}.\n\n"
            "Hints:\n"
            "- use `df.item` to select a single item.\n"
            "- Use `df[indices, :]` to select rows positionally.\n"
            "- Use `df.filter(mask)` to filter rows based on a boolean mask."
        )

        if isinstance(item, tuple):
            if len(item) > 2:
                tuple_msg = (
                    "Tuples cannot be passed to DataFrame.__getitem__ directly.\n\n"
                    "Hint: instead of `df[indices]`, did you mean `df[indices, :]`?"
                )
                raise TypeError(tuple_msg)
            rows = None if not item or is_slice_none(item[0]) else item[0]
            columns = None if len(item) < 2 or is_slice_none(item[1]) else item[1]
            if rows is None and columns is None:
                return self
        elif is_index_selector(item):
            rows = item
            columns = None
        elif is_sequence_like(item) or isinstance(item, (slice, str)):
            rows = None
            columns = item
        else:
            raise TypeError(msg)

        if isinstance(rows, str):
            raise TypeError(msg)

        compliant = self._compliant_frame

        if isinstance(columns, (int, str)):
            if isinstance(rows, int):
                return self.item(rows, columns)
            col_name = columns if isinstance(columns, str) else self.columns[columns]
            series = self.get_column(col_name)
            return series[rows] if rows is not None else series
        if isinstance(rows, Series):
            rows = rows._compliant_series
        if isinstance(columns, Series):
            columns = columns._compliant_series
        if rows is None:
            return self._with_compliant(compliant[:, columns])
        if columns is None:
            return self._with_compliant(compliant[rows, :])
        return self._with_compliant(compliant[rows, columns])

    def __contains__(self, key: str) -> bool:
        return key in self.columns

    @overload
    def to_dict(self, *, as_series: Literal[True] = ...) -> dict[str, Series[Any]]: ...
    @overload
    def to_dict(self, *, as_series: Literal[False]) -> dict[str, list[Any]]: ...
    @overload
    def to_dict(
        self, *, as_series: bool
    ) -> dict[str, Series[Any]] | dict[str, list[Any]]: ...
    def to_dict(
        self, *, as_series: bool = True
    ) -> dict[str, Series[Any]] | dict[str, list[Any]]:
        
        if as_series:
            return {
                key: self._series(value, level=self._level)
                for key, value in self._compliant_frame.to_dict(
                    as_series=as_series
                ).items()
            }
        return self._compliant_frame.to_dict(as_series=as_series)

    def row(self, index: int) -> tuple[Any, ...]:
        
        return self._compliant_frame.row(index)

    
    def pipe(
        self,
        function: Callable[Concatenate[Self, PS], R],
        *args: PS.args,
        **kwargs: PS.kwargs,
    ) -> R:
        
        return super().pipe(function, *args, **kwargs)

    def drop_nulls(self, subset: str | list[str] | None = None) -> Self:
        
        return super().drop_nulls(subset=subset)

    def with_row_index(
        self, name: str = "index", *, order_by: str | Sequence[str] | None = None
    ) -> Self:
        
        order_by_ = [order_by] if isinstance(order_by, str) else order_by
        return self._with_compliant(
            self._compliant_frame.with_row_index(name, order_by=order_by_)
        )

    @property
    def schema(self) -> Schema:
        r
        return super().schema

    def collect_schema(self) -> Schema:
        r
        return super().collect_schema()

    @property
    def columns(self) -> list[str]:
        
        return super().columns

    @overload
    def rows(self, *, named: Literal[False] = False) -> list[tuple[Any, ...]]: ...

    @overload
    def rows(self, *, named: Literal[True]) -> list[dict[str, Any]]: ...

    @overload
    def rows(self, *, named: bool) -> list[tuple[Any, ...]] | list[dict[str, Any]]: ...

    def rows(
        self, *, named: bool = False
    ) -> list[tuple[Any, ...]] | list[dict[str, Any]]:
        
        return self._compliant_frame.rows(named=named)  

    def iter_columns(self) -> Iterator[Series[Any]]:
        
        for series in self._compliant_frame.iter_columns():
            yield self._series(series, level=self._level)

    @overload
    def iter_rows(
        self, *, named: Literal[False] = ..., buffer_size: int = ...
    ) -> Iterator[tuple[Any, ...]]: ...

    @overload
    def iter_rows(
        self, *, named: Literal[True], buffer_size: int = ...
    ) -> Iterator[dict[str, Any]]: ...

    @overload
    def iter_rows(
        self, *, named: bool, buffer_size: int = ...
    ) -> Iterator[tuple[Any, ...]] | Iterator[dict[str, Any]]: ...

    def iter_rows(
        self, *, named: bool = False, buffer_size: int = 512
    ) -> Iterator[tuple[Any, ...]] | Iterator[dict[str, Any]]:
        
        return self._compliant_frame.iter_rows(named=named, buffer_size=buffer_size)  

    def with_columns(
        self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr
    ) -> Self:
        r
        return super().with_columns(*exprs, **named_exprs)

    def select(
        self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr
    ) -> Self:
        r
        return super().select(*exprs, **named_exprs)

    def rename(self, mapping: dict[str, str]) -> Self:
        
        return super().rename(mapping)

    def head(self, n: int = 5) -> Self:
        
        return super().head(n)

    def tail(self, n: int = 5) -> Self:
        
        return super().tail(n)

    def drop(self, *columns: str | Iterable[str], strict: bool = True) -> Self:
        
        return super().drop(*flatten(columns), strict=strict)

    def unique(
        self,
        subset: str | list[str] | None = None,
        *,
        keep: UniqueKeepStrategy = "any",
        maintain_order: bool = False,
    ) -> Self:
        
        if keep not in {"any", "none", "first", "last"}:
            msg = f"Expected {'any', 'none', 'first', 'last'}, got: {keep}"
            raise ValueError(msg)
        if isinstance(subset, str):
            subset = [subset]
        return self._with_compliant(
            self._compliant_frame.unique(subset, keep=keep, maintain_order=maintain_order)
        )

    def filter(
        self, *predicates: IntoExpr | Iterable[IntoExpr] | list[bool], **constraints: Any
    ) -> Self:
        r
        return super().filter(*predicates, **constraints)

    @overload
    def group_by(
        self, *keys: IntoExpr | Iterable[IntoExpr], drop_null_keys: Literal[False] = ...
    ) -> GroupBy[Self]: ...

    @overload
    def group_by(
        self, *keys: str | Iterable[str], drop_null_keys: Literal[True]
    ) -> GroupBy[Self]: ...

    def group_by(
        self, *keys: IntoExpr | Iterable[IntoExpr], drop_null_keys: bool = False
    ) -> GroupBy[Self]:
        r
        from narwhals.group_by import GroupBy

        flat_keys = flatten(keys)

        if all(isinstance(key, str) for key in flat_keys):
            return GroupBy(self, flat_keys, drop_null_keys=drop_null_keys)

        from narwhals import col
        from narwhals.expr import Expr
        from narwhals.series import Series

        key_is_expr_or_series = tuple(isinstance(k, (Expr, Series)) for k in flat_keys)

        if drop_null_keys and any(key_is_expr_or_series):
            msg = "drop_null_keys cannot be True when keys contains Expr or Series"
            raise NotImplementedError(msg)

        _keys = [
            k if is_expr else col(k)
            for k, is_expr in zip(flat_keys, key_is_expr_or_series)
        ]
        expr_flat_keys, kinds = self._flatten_and_extract(*_keys)

        if not all(kind is ExprKind.ELEMENTWISE for kind in kinds):
            from narwhals.exceptions import ComputeError

            msg = (
                "Group by is not supported with keys that are not elementwise expressions"
            )
            raise ComputeError(msg)

        return GroupBy(self, expr_flat_keys, drop_null_keys=drop_null_keys)

    def sort(
        self,
        by: str | Iterable[str],
        *more_by: str,
        descending: bool | Sequence[bool] = False,
        nulls_last: bool = False,
    ) -> Self:
        r
        return super().sort(by, *more_by, descending=descending, nulls_last=nulls_last)

    def join(
        self,
        other: Self,
        on: str | list[str] | None = None,
        how: JoinStrategy = "inner",
        *,
        left_on: str | list[str] | None = None,
        right_on: str | list[str] | None = None,
        suffix: str = "_right",
    ) -> Self:
        r
        return super().join(
            other, how=how, left_on=left_on, right_on=right_on, on=on, suffix=suffix
        )

    def join_asof(
        self,
        other: Self,
        *,
        left_on: str | None = None,
        right_on: str | None = None,
        on: str | None = None,
        by_left: str | list[str] | None = None,
        by_right: str | list[str] | None = None,
        by: str | list[str] | None = None,
        strategy: AsofJoinStrategy = "backward",
        suffix: str = "_right",
    ) -> Self:
        
        return super().join_asof(
            other,
            left_on=left_on,
            right_on=right_on,
            on=on,
            by_left=by_left,
            by_right=by_right,
            by=by,
            strategy=strategy,
            suffix=suffix,
        )

    
    def is_duplicated(self) -> Series[Any]:
        r
        return ~self.is_unique()

    def is_empty(self) -> bool:
        r
        return len(self) == 0

    def is_unique(self) -> Series[Any]:
        r
        return self._series(self._compliant_frame.is_unique(), level=self._level)

    def null_count(self) -> Self:
        r
        plx = self._compliant_frame.__narwhals_namespace__()
        result = self._compliant_frame.select(plx.all().null_count())
        return self._with_compliant(result)

    def item(self, row: int | None = None, column: int | str | None = None) -> Any:
        r
        return self._compliant_frame.item(row=row, column=column)

    def clone(self) -> Self:
        r
        return self._with_compliant(self._compliant_frame.clone())

    def gather_every(self, n: int, offset: int = 0) -> Self:
        r
        return super().gather_every(n=n, offset=offset)

    def pivot(
        self,
        on: str | list[str],
        *,
        index: str | list[str] | None = None,
        values: str | list[str] | None = None,
        aggregate_function: PivotAgg | None = None,
        maintain_order: bool | None = None,
        sort_columns: bool = False,
        separator: str = "_",
    ) -> Self:
        r
        if values is None and index is None:
            msg = "At least one of `values` and `index` must be passed"
            raise ValueError(msg)
        if maintain_order is not None:
            msg = (
                "`maintain_order` has no effect and is only kept around for backwards-compatibility. "
                "You can safely remove this argument."
            )
            issue_warning(msg, UserWarning)
        on = [on] if isinstance(on, str) else on
        values = [values] if isinstance(values, str) else values
        index = [index] if isinstance(index, str) else index

        return self._with_compliant(
            self._compliant_frame.pivot(
                on=on,
                index=index,
                values=values,
                aggregate_function=aggregate_function,
                sort_columns=sort_columns,
                separator=separator,
            )
        )

    def to_arrow(self) -> pa.Table:
        r
        return self._compliant_frame.to_arrow()

    def sample(
        self,
        n: int | None = None,
        *,
        fraction: float | None = None,
        with_replacement: bool = False,
        seed: int | None = None,
    ) -> Self:
        r
        return self._with_compliant(
            self._compliant_frame.sample(
                n=n, fraction=fraction, with_replacement=with_replacement, seed=seed
            )
        )

    def unpivot(
        self,
        on: str | list[str] | None = None,
        *,
        index: str | list[str] | None = None,
        variable_name: str = "variable",
        value_name: str = "value",
    ) -> Self:
        r
        return super().unpivot(
            on=on, index=index, variable_name=variable_name, value_name=value_name
        )

    def explode(self, columns: str | Sequence[str], *more_columns: str) -> Self:
        
        return super().explode(columns, *more_columns)


class LazyFrame(BaseFrame[FrameT]):
    

    def _extract_compliant(self, arg: Any) -> Any:
        from narwhals.expr import Expr
        from narwhals.series import Series

        if isinstance(arg, BaseFrame):
            return arg._compliant_frame
        if isinstance(arg, Series):  
            msg = "Binary operations between Series and LazyFrame are not supported."
            raise TypeError(msg)
        if isinstance(arg, str):  
            plx = self.__narwhals_namespace__()
            return plx.col(arg)
        if isinstance(arg, Expr):
            if arg._metadata.n_orderable_ops:
                msg = (
                    "Order-dependent expressions are not supported for use in LazyFrame.\n\n"
                    "Hint: To make the expression valid, use `.over` with `order_by` specified.\n\n"
                    "For example, if you wrote `nw.col('price').cum_sum()` and you have a column\n"
                    "`'date'` which orders your data, then replace:\n\n"
                    "   nw.col('price').cum_sum()\n\n"
                    " with:\n\n"
                    "   nw.col('price').cum_sum().over(order_by='date')\n"
                    "                            ^^^^^^^^^^^^^^^^^^^^^^\n\n"
                    "See https://narwhals-dev.github.io/narwhals/concepts/order_dependence/."
                )
                raise InvalidOperationError(msg)
            if arg._metadata.is_filtration:
                msg = (
                    "Length-changing expressions are not supported for use in LazyFrame, unless\n"
                    "followed by an aggregation.\n\n"
                    "Hints:\n"
                    "- Instead of `lf.select(nw.col('a').head())`, use `lf.select('a').head()\n"
                    "- Instead of `lf.select(nw.col('a').drop_nulls()).select(nw.sum('a'))`,\n"
                    "  use `lf.select(nw.col('a').drop_nulls().sum())\n"
                )
                raise InvalidOperationError(msg)
            return arg._to_compliant_expr(self.__narwhals_namespace__())
        if get_polars() is not None and "polars" in str(type(arg)):  
            msg = (
                f"Expected Narwhals object, got: {type(arg)}.\n\n"
                "Perhaps you:\n"
                "- Forgot a `nw.from_native` somewhere?\n"
                "- Used `pl.col` instead of `nw.col`?"
            )
            raise TypeError(msg)
        raise InvalidIntoExprError.from_invalid_type(type(arg))  

    @property
    def _dataframe(self) -> type[DataFrame[Any]]:
        return DataFrame

    def __init__(self, df: Any, *, level: Literal["full", "lazy", "interchange"]) -> None:
        self._level = level
        self._compliant_frame: CompliantLazyFrame[Any, FrameT, Self]  
        if is_compliant_lazyframe(df):
            self._compliant_frame = df.__narwhals_lazyframe__()
        else:  
            msg = f"Expected Polars LazyFrame or an object that implements `__narwhals_lazyframe__`, got: {type(df)}"
            raise AssertionError(msg)

    def __repr__(self) -> str:  
        return generate_repr("Narwhals LazyFrame", self.to_native().__repr__())

    @property
    def implementation(self) -> Implementation:
        
        return self._compliant_frame._implementation

    def __getitem__(self, item: str | slice) -> NoReturn:
        msg = "Slicing is not supported on LazyFrame"
        raise TypeError(msg)

    def collect(
        self, backend: ModuleType | Implementation | str | None = None, **kwargs: Any
    ) -> DataFrame[Any]:
        r
        eager_backend = None if backend is None else Implementation.from_backend(backend)
        supported_eager_backends = (
            Implementation.POLARS,
            Implementation.PANDAS,
            Implementation.PYARROW,
        )
        if eager_backend is not None and eager_backend not in supported_eager_backends:
            msg = f"Unsupported `backend` value.\nExpected one of {supported_eager_backends} or None, got: {eager_backend}."
            raise ValueError(msg)
        return self._dataframe(
            self._compliant_frame.collect(backend=eager_backend, **kwargs), level="full"
        )

    def to_native(self) -> FrameT:
        
        return to_native(narwhals_object=self, pass_through=False)

    
    def pipe(
        self,
        function: Callable[Concatenate[Self, PS], R],
        *args: PS.args,
        **kwargs: PS.kwargs,
    ) -> R:
        
        return super().pipe(function, *args, **kwargs)

    def drop_nulls(self, subset: str | list[str] | None = None) -> Self:
        
        return super().drop_nulls(subset=subset)

    def with_row_index(
        self, name: str = "index", *, order_by: str | Sequence[str]
    ) -> Self:
        
        order_by_ = [order_by] if isinstance(order_by, str) else order_by
        return self._with_compliant(
            self._compliant_frame.with_row_index(name, order_by=order_by_)
        )

    @property
    def schema(self) -> Schema:
        r
        if self._compliant_frame._version is not Version.V1:
            msg = (
                "Resolving the schema of a LazyFrame is a potentially expensive operation. "
                "Use `LazyFrame.collect_schema()` to get the schema without this warning."
            )
            issue_warning(msg, PerformanceWarning)
        return super().schema

    def collect_schema(self) -> Schema:
        r
        return super().collect_schema()

    @property
    def columns(self) -> list[str]:
        r
        return super().columns

    def with_columns(
        self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr
    ) -> Self:
        r
        if not exprs and not named_exprs:
            msg = "At least one expression must be passed to LazyFrame.with_columns"
            raise ValueError(msg)
        return super().with_columns(*exprs, **named_exprs)

    def select(
        self, *exprs: IntoExpr | Iterable[IntoExpr], **named_exprs: IntoExpr
    ) -> Self:
        r
        if not exprs and not named_exprs:
            msg = "At least one expression must be passed to LazyFrame.select"
            raise ValueError(msg)
        return super().select(*exprs, **named_exprs)

    def rename(self, mapping: dict[str, str]) -> Self:
        r
        return super().rename(mapping)

    def head(self, n: int = 5) -> Self:
        r
        return super().head(n)

    def drop(self, *columns: str | Iterable[str], strict: bool = True) -> Self:
        r
        return super().drop(*flatten(columns), strict=strict)

    def unique(
        self,
        subset: str | list[str] | None = None,
        *,
        keep: LazyUniqueKeepStrategy = "any",
    ) -> Self:
        
        if keep not in {"any", "none"}:
            msg = (
                "narwhals.LazyFrame makes no assumptions about row order, so only "
                f"'any' and 'none' are supported for `keep` in `unique`. Got: {keep}."
            )
            raise ValueError(msg)
        if isinstance(subset, str):
            subset = [subset]
        return self._with_compliant(
            self._compliant_frame.unique(subset=subset, keep=keep)
        )

    def filter(
        self, *predicates: IntoExpr | Iterable[IntoExpr] | list[bool], **constraints: Any
    ) -> Self:
        r
        if (
            len(predicates) == 1 and is_list_of(predicates[0], bool) and not constraints
        ):  
            msg = "`LazyFrame.filter` is not supported with Python boolean masks - use expressions instead."
            raise TypeError(msg)

        return super().filter(*predicates, **constraints)

    def sink_parquet(self, file: str | Path | BytesIO) -> None:
        
        self._compliant_frame.sink_parquet(file)

    @overload
    def group_by(
        self, *keys: IntoExpr | Iterable[IntoExpr], drop_null_keys: Literal[False] = ...
    ) -> LazyGroupBy[Self]: ...

    @overload
    def group_by(
        self, *keys: str | Iterable[str], drop_null_keys: Literal[True]
    ) -> LazyGroupBy[Self]: ...

    def group_by(
        self, *keys: IntoExpr | Iterable[IntoExpr], drop_null_keys: bool = False
    ) -> LazyGroupBy[Self]:
        r
        from narwhals.group_by import LazyGroupBy

        flat_keys = flatten(keys)

        if all(isinstance(key, str) for key in flat_keys):
            return LazyGroupBy(self, flat_keys, drop_null_keys=drop_null_keys)

        from narwhals import col
        from narwhals.expr import Expr

        key_is_expr = tuple(isinstance(k, Expr) for k in flat_keys)

        if drop_null_keys and any(key_is_expr):
            msg = "drop_null_keys cannot be True when keys contains Expr"
            raise NotImplementedError(msg)

        _keys = [k if is_expr else col(k) for k, is_expr in zip(flat_keys, key_is_expr)]
        expr_flat_keys, kinds = self._flatten_and_extract(*_keys)

        if not all(kind is ExprKind.ELEMENTWISE for kind in kinds):
            from narwhals.exceptions import ComputeError

            msg = (
                "Group by is not supported with keys that are not elementwise expressions"
            )
            raise ComputeError(msg)

        return LazyGroupBy(self, expr_flat_keys, drop_null_keys=drop_null_keys)

    def sort(
        self,
        by: str | Iterable[str],
        *more_by: str,
        descending: bool | Sequence[bool] = False,
        nulls_last: bool = False,
    ) -> Self:
        r
        return super().sort(by, *more_by, descending=descending, nulls_last=nulls_last)

    def join(
        self,
        other: Self,
        on: str | list[str] | None = None,
        how: JoinStrategy = "inner",
        *,
        left_on: str | list[str] | None = None,
        right_on: str | list[str] | None = None,
        suffix: str = "_right",
    ) -> Self:
        r
        return super().join(
            other, how=how, left_on=left_on, right_on=right_on, on=on, suffix=suffix
        )

    def join_asof(
        self,
        other: Self,
        *,
        left_on: str | None = None,
        right_on: str | None = None,
        on: str | None = None,
        by_left: str | list[str] | None = None,
        by_right: str | list[str] | None = None,
        by: str | list[str] | None = None,
        strategy: AsofJoinStrategy = "backward",
        suffix: str = "_right",
    ) -> Self:
        
        return super().join_asof(
            other,
            left_on=left_on,
            right_on=right_on,
            on=on,
            by_left=by_left,
            by_right=by_right,
            by=by,
            strategy=strategy,
            suffix=suffix,
        )

    def lazy(self) -> Self:
        
        return self

    def unpivot(
        self,
        on: str | list[str] | None = None,
        *,
        index: str | list[str] | None = None,
        variable_name: str = "variable",
        value_name: str = "value",
    ) -> Self:
        r
        return super().unpivot(
            on=on, index=index, variable_name=variable_name, value_name=value_name
        )

    def explode(self, columns: str | Sequence[str], *more_columns: str) -> Self:
        
        return super().explode(columns, *more_columns)
