















import copy
from typing import Any, Dict, List, Optional, Sequence, Union

from google.auth import credentials as auth_credentials
from google.cloud.aiplatform import explain
from google.cloud.aiplatform.compat.types import artifact as gca_artifact
from google.cloud.aiplatform.metadata import _models
from google.cloud.aiplatform.metadata.schema import base_artifact
from google.cloud.aiplatform.metadata.schema import utils
from google.cloud.aiplatform.models import Model


_ARTIFACT_PROPERTY_KEY_RESOURCE_NAME = "resourceName"

_CLASSIFICATION_METRICS_AGGREGATION_TYPE = [
    "AGGREGATION_TYPE_UNSPECIFIED",
    "MACRO_AVERAGE",
    "MICRO_AVERAGE",
]


class VertexDataset(base_artifact.BaseArtifactSchema):
    

    schema_title = "google.VertexDataset"

    def __init__(
        self,
        *,
        vertex_dataset_name: str,
        artifact_id: Optional[str] = None,
        display_name: Optional[str] = None,
        schema_version: Optional[str] = None,
        description: Optional[str] = None,
        metadata: Optional[Dict] = None,
        state: Optional[gca_artifact.Artifact.State] = gca_artifact.Artifact.State.LIVE,
    ):
        
        extended_metadata = copy.deepcopy(metadata) if metadata else {}
        extended_metadata[_ARTIFACT_PROPERTY_KEY_RESOURCE_NAME] = vertex_dataset_name

        super(VertexDataset, self).__init__(
            uri=utils.create_uri_from_resource_name(resource_name=vertex_dataset_name),
            artifact_id=artifact_id,
            display_name=display_name,
            schema_version=schema_version,
            description=description,
            metadata=extended_metadata,
            state=state,
        )


class VertexModel(base_artifact.BaseArtifactSchema):
    

    schema_title = "google.VertexModel"

    def __init__(
        self,
        *,
        vertex_model_name: str,
        artifact_id: Optional[str] = None,
        display_name: Optional[str] = None,
        schema_version: Optional[str] = None,
        description: Optional[str] = None,
        metadata: Optional[Dict] = None,
        state: Optional[gca_artifact.Artifact.State] = gca_artifact.Artifact.State.LIVE,
    ):
        
        extended_metadata = copy.deepcopy(metadata) if metadata else {}
        extended_metadata[_ARTIFACT_PROPERTY_KEY_RESOURCE_NAME] = vertex_model_name

        super(VertexModel, self).__init__(
            uri=utils.create_uri_from_resource_name(resource_name=vertex_model_name),
            artifact_id=artifact_id,
            display_name=display_name,
            schema_version=schema_version,
            description=description,
            metadata=extended_metadata,
            state=state,
        )


class VertexEndpoint(base_artifact.BaseArtifactSchema):
    

    schema_title = "google.VertexEndpoint"

    def __init__(
        self,
        *,
        vertex_endpoint_name: str,
        artifact_id: Optional[str] = None,
        display_name: Optional[str] = None,
        schema_version: Optional[str] = None,
        description: Optional[str] = None,
        metadata: Optional[Dict] = None,
        state: Optional[gca_artifact.Artifact.State] = gca_artifact.Artifact.State.LIVE,
    ):
        
        extended_metadata = copy.deepcopy(metadata) if metadata else {}
        extended_metadata[_ARTIFACT_PROPERTY_KEY_RESOURCE_NAME] = vertex_endpoint_name

        super(VertexEndpoint, self).__init__(
            uri=utils.create_uri_from_resource_name(resource_name=vertex_endpoint_name),
            artifact_id=artifact_id,
            display_name=display_name,
            schema_version=schema_version,
            description=description,
            metadata=extended_metadata,
            state=state,
        )


class UnmanagedContainerModel(base_artifact.BaseArtifactSchema):
    

    schema_title = "google.UnmanagedContainerModel"

    def __init__(
        self,
        *,
        predict_schemata: utils.PredictSchemata,
        container_spec: utils.ContainerSpec,
        artifact_id: Optional[str] = None,
        uri: Optional[str] = None,
        display_name: Optional[str] = None,
        schema_version: Optional[str] = None,
        description: Optional[str] = None,
        metadata: Optional[Dict] = None,
        state: Optional[gca_artifact.Artifact.State] = gca_artifact.Artifact.State.LIVE,
    ):
        
        extended_metadata = copy.deepcopy(metadata) if metadata else {}
        extended_metadata["predictSchemata"] = predict_schemata.to_dict()
        extended_metadata["containerSpec"] = container_spec.to_dict()

        super(UnmanagedContainerModel, self).__init__(
            uri=uri,
            artifact_id=artifact_id,
            display_name=display_name,
            schema_version=schema_version,
            description=description,
            metadata=extended_metadata,
            state=state,
        )


class ClassificationMetrics(base_artifact.BaseArtifactSchema):
    

    schema_title = "google.ClassificationMetrics"

    def __init__(
        self,
        *,
        aggregation_type: Optional[str] = None,
        aggregation_threshold: Optional[float] = None,
        recall: Optional[float] = None,
        precision: Optional[float] = None,
        f1_score: Optional[float] = None,
        accuracy: Optional[float] = None,
        au_prc: Optional[float] = None,
        au_roc: Optional[float] = None,
        log_loss: Optional[float] = None,
        confusion_matrix: Optional[utils.ConfusionMatrix] = None,
        confidence_metrics: Optional[List[utils.ConfidenceMetric]] = None,
        artifact_id: Optional[str] = None,
        uri: Optional[str] = None,
        display_name: Optional[str] = None,
        schema_version: Optional[str] = None,
        description: Optional[str] = None,
        metadata: Optional[Dict] = None,
        state: Optional[gca_artifact.Artifact.State] = gca_artifact.Artifact.State.LIVE,
    ):
        
        extended_metadata = copy.deepcopy(metadata) if metadata else {}
        if aggregation_type:
            if aggregation_type not in _CLASSIFICATION_METRICS_AGGREGATION_TYPE:
                raise ValueError(
                    "aggregation_type can only be 'AGGREGATION_TYPE_UNSPECIFIED', 'MACRO_AVERAGE', or 'MICRO_AVERAGE'."
                )
            extended_metadata["aggregationType"] = aggregation_type
        if aggregation_threshold is not None:
            extended_metadata["aggregationThreshold"] = aggregation_threshold
        if recall is not None:
            extended_metadata["recall"] = recall
        if precision is not None:
            extended_metadata["precision"] = precision
        if f1_score is not None:
            extended_metadata["f1Score"] = f1_score
        if accuracy is not None:
            extended_metadata["accuracy"] = accuracy
        if au_prc is not None:
            extended_metadata["auPrc"] = au_prc
        if au_roc is not None:
            extended_metadata["auRoc"] = au_roc
        if log_loss is not None:
            extended_metadata["logLoss"] = log_loss
        if confusion_matrix:
            extended_metadata["confusionMatrix"] = confusion_matrix.to_dict()
        if confidence_metrics:
            extended_metadata["confidenceMetrics"] = [
                confidence_metric.to_dict() for confidence_metric in confidence_metrics
            ]

        super(ClassificationMetrics, self).__init__(
            uri=uri,
            artifact_id=artifact_id,
            display_name=display_name,
            schema_version=schema_version,
            description=description,
            metadata=extended_metadata,
            state=state,
        )


class RegressionMetrics(base_artifact.BaseArtifactSchema):
    

    schema_title = "google.RegressionMetrics"

    def __init__(
        self,
        *,
        root_mean_squared_error: Optional[float] = None,
        mean_absolute_error: Optional[float] = None,
        mean_absolute_percentage_error: Optional[float] = None,
        r_squared: Optional[float] = None,
        root_mean_squared_log_error: Optional[float] = None,
        artifact_id: Optional[str] = None,
        uri: Optional[str] = None,
        display_name: Optional[str] = None,
        schema_version: Optional[str] = None,
        description: Optional[str] = None,
        metadata: Optional[Dict] = None,
        state: Optional[gca_artifact.Artifact.State] = gca_artifact.Artifact.State.LIVE,
    ):
        
        extended_metadata = copy.deepcopy(metadata) if metadata else {}
        if root_mean_squared_error:
            extended_metadata["rootMeanSquaredError"] = root_mean_squared_error
        if mean_absolute_error:
            extended_metadata["meanAbsoluteError"] = mean_absolute_error
        if mean_absolute_percentage_error:
            extended_metadata[
                "meanAbsolutePercentageError"
            ] = mean_absolute_percentage_error
        if r_squared:
            extended_metadata["rSquared"] = r_squared
        if root_mean_squared_log_error:
            extended_metadata["rootMeanSquaredLogError"] = root_mean_squared_log_error

        super(RegressionMetrics, self).__init__(
            uri=uri,
            artifact_id=artifact_id,
            display_name=display_name,
            schema_version=schema_version,
            description=description,
            metadata=extended_metadata,
            state=state,
        )


class ForecastingMetrics(base_artifact.BaseArtifactSchema):
    

    schema_title = "google.ForecastingMetrics"

    def __init__(
        self,
        *,
        root_mean_squared_error: Optional[float] = None,
        mean_absolute_error: Optional[float] = None,
        mean_absolute_percentage_error: Optional[float] = None,
        r_squared: Optional[float] = None,
        root_mean_squared_log_error: Optional[float] = None,
        weighted_absolute_percentage_error: Optional[float] = None,
        root_mean_squared_percentage_error: Optional[float] = None,
        symmetric_mean_absolute_percentage_error: Optional[float] = None,
        artifact_id: Optional[str] = None,
        uri: Optional[str] = None,
        display_name: Optional[str] = None,
        schema_version: Optional[str] = None,
        description: Optional[str] = None,
        metadata: Optional[Dict] = None,
        state: Optional[gca_artifact.Artifact.State] = gca_artifact.Artifact.State.LIVE,
    ):
        
        extended_metadata = copy.deepcopy(metadata) if metadata else {}
        if root_mean_squared_error:
            extended_metadata["rootMeanSquaredError"] = root_mean_squared_error
        if mean_absolute_error:
            extended_metadata["meanAbsoluteError"] = mean_absolute_error
        if mean_absolute_percentage_error:
            extended_metadata[
                "meanAbsolutePercentageError"
            ] = mean_absolute_percentage_error
        if r_squared:
            extended_metadata["rSquared"] = r_squared
        if root_mean_squared_log_error:
            extended_metadata["rootMeanSquaredLogError"] = root_mean_squared_log_error
        if weighted_absolute_percentage_error:
            extended_metadata[
                "weightedAbsolutePercentageError"
            ] = weighted_absolute_percentage_error
        if root_mean_squared_percentage_error:
            extended_metadata[
                "rootMeanSquaredPercentageError"
            ] = root_mean_squared_percentage_error
        if symmetric_mean_absolute_percentage_error:
            extended_metadata[
                "symmetricMeanAbsolutePercentageError"
            ] = symmetric_mean_absolute_percentage_error

        super(ForecastingMetrics, self).__init__(
            uri=uri,
            artifact_id=artifact_id,
            display_name=display_name,
            schema_version=schema_version,
            description=description,
            metadata=extended_metadata,
            state=state,
        )


class ExperimentModel(base_artifact.BaseArtifactSchema):
    

    schema_title = "google.ExperimentModel"

    RESERVED_METADATA_KEYS = [
        "frameworkName",
        "frameworkVersion",
        "modelFile",
        "modelClass",
        "predictSchemata",
    ]

    def __init__(
        self,
        *,
        framework_name: str,
        framework_version: str,
        model_file: str,
        uri: str,
        model_class: Optional[str] = None,
        predict_schemata: Optional[utils.PredictSchemata] = None,
        artifact_id: Optional[str] = None,
        display_name: Optional[str] = None,
        schema_version: Optional[str] = None,
        description: Optional[str] = None,
        metadata: Optional[Dict] = None,
        state: Optional[gca_artifact.Artifact.State] = gca_artifact.Artifact.State.LIVE,
    ):
        
        if metadata:
            for k in metadata:
                if k in self.RESERVED_METADATA_KEYS:
                    raise ValueError(f"'{k}' is a system reserved key in metadata.")
            extended_metadata = copy.deepcopy(metadata)
        else:
            extended_metadata = {}
        extended_metadata["frameworkName"] = framework_name
        extended_metadata["frameworkVersion"] = framework_version
        extended_metadata["modelFile"] = model_file
        if model_class is not None:
            extended_metadata["modelClass"] = model_class
        if predict_schemata is not None:
            extended_metadata["predictSchemata"] = predict_schemata.to_dict()

        super().__init__(
            uri=uri,
            artifact_id=artifact_id,
            display_name=display_name,
            schema_version=schema_version,
            description=description,
            metadata=extended_metadata,
            state=state,
        )

    @classmethod
    def get(
        cls,
        artifact_id: str,
        *,
        metadata_store_id: str = "default",
        project: Optional[str] = None,
        location: Optional[str] = None,
        credentials: Optional[auth_credentials.Credentials] = None,
    ) -> "ExperimentModel":
        
        experiment_model = ExperimentModel(
            framework_name="",
            framework_version="",
            model_file="",
            uri="",
        )
        experiment_model._init_with_resource_name(
            artifact_name=artifact_id,
            metadata_store_id=metadata_store_id,
            project=project,
            location=location,
            credentials=credentials,
        )
        if experiment_model.schema_title != cls.schema_title:
            raise ValueError(
                f"The schema title of the artifact must be {cls.schema_title}."
                f"Got {experiment_model.schema_title}."
            )
        return experiment_model

    @property
    def framework_name(self) -> Optional[str]:
        
        return self.metadata.get("frameworkName")

    @property
    def framework_version(self) -> Optional[str]:
        
        return self.metadata.get("frameworkVersion")

    @property
    def model_class(self) -> Optional[str]:
        "The class name of the saved ML model."
        return self.metadata.get("modelClass")

    def get_model_info(self) -> Dict[str, Any]:
        
        return _models.get_experiment_model_info(self)

    def load_model(
        self,
    ) -> Union["sklearn.base.BaseEstimator", "xgb.Booster", "tf.Module"]:  
        
        return _models.load_model(self)

    def register_model(
        self,
        *,
        model_id: Optional[str] = None,
        parent_model: Optional[str] = None,
        use_gpu: bool = False,
        is_default_version: bool = True,
        version_aliases: Optional[Sequence[str]] = None,
        version_description: Optional[str] = None,
        display_name: Optional[str] = None,
        description: Optional[str] = None,
        labels: Optional[Dict[str, str]] = None,
        serving_container_image_uri: Optional[str] = None,
        serving_container_predict_route: Optional[str] = None,
        serving_container_health_route: Optional[str] = None,
        serving_container_command: Optional[Sequence[str]] = None,
        serving_container_args: Optional[Sequence[str]] = None,
        serving_container_environment_variables: Optional[Dict[str, str]] = None,
        serving_container_ports: Optional[Sequence[int]] = None,
        instance_schema_uri: Optional[str] = None,
        parameters_schema_uri: Optional[str] = None,
        prediction_schema_uri: Optional[str] = None,
        explanation_metadata: Optional[explain.ExplanationMetadata] = None,
        explanation_parameters: Optional[explain.ExplanationParameters] = None,
        project: Optional[str] = None,
        location: Optional[str] = None,
        credentials: Optional[auth_credentials.Credentials] = None,
        encryption_spec_key_name: Optional[str] = None,
        staging_bucket: Optional[str] = None,
        sync: Optional[bool] = True,
        upload_request_timeout: Optional[float] = None,
    ) -> Model:
        
        return _models.register_model(
            model=self,
            model_id=model_id,
            parent_model=parent_model,
            use_gpu=use_gpu,
            is_default_version=is_default_version,
            version_aliases=version_aliases,
            version_description=version_description,
            display_name=display_name,
            description=description,
            labels=labels,
            serving_container_image_uri=serving_container_image_uri,
            serving_container_predict_route=serving_container_predict_route,
            serving_container_health_route=serving_container_health_route,
            serving_container_command=serving_container_command,
            serving_container_args=serving_container_args,
            serving_container_environment_variables=serving_container_environment_variables,
            serving_container_ports=serving_container_ports,
            instance_schema_uri=instance_schema_uri,
            parameters_schema_uri=parameters_schema_uri,
            prediction_schema_uri=prediction_schema_uri,
            explanation_metadata=explanation_metadata,
            explanation_parameters=explanation_parameters,
            project=project,
            location=location,
            credentials=credentials,
            encryption_spec_key_name=encryption_spec_key_name,
            staging_bucket=staging_bucket,
            sync=sync,
            upload_request_timeout=upload_request_timeout,
        )
