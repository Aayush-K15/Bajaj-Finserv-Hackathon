


















from google.cloud.aiplatform.training_utils.cloud_profiler import (
    cloud_profiler_utils,
)

try:
    import tensorflow as tf
    from tensorboard_plugin_profile.profile_plugin import (
        ProfilePlugin,
    )
except ImportError as err:
    raise ImportError(cloud_profiler_utils.import_error_msg) from err

import argparse
from collections import namedtuple
import importlib.util
import json
import logging
from typing import Callable, Dict, Optional
from urllib import parse

import tensorboard.plugins.base_plugin as tensorboard_base_plugin
from werkzeug import Response

from google.cloud.aiplatform.tensorboard.plugins.tf_profiler import (
    profile_uploader,
)
from google.cloud.aiplatform.training_utils import environment_variables
from google.cloud.aiplatform.training_utils.cloud_profiler import wsgi_types
from google.cloud.aiplatform.training_utils.cloud_profiler.plugins import (
    base_plugin,
)
from google.cloud.aiplatform.training_utils.cloud_profiler.plugins.tensorflow import (
    tensorboard_api,
)



Version = namedtuple("Version", ["major", "minor", "patch"])

logger = logging.Logger("tf-profiler")

_BASE_TB_ENV_WARNING = (
    "To set this environment variable, run your training with the 'tensorboard' "
    "option. For more information on how to run with training with tensorboard, visit "
    "https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-training"
)


def _get_tf_versioning() -> Optional[Version]:
    
    version = tf.__version__

    versioning = version.split(".")
    if len(versioning) != 3:
        return
    return Version(int(versioning[0]), int(versioning[1]), versioning[2])


def _is_compatible_version(version: Version) -> bool:
    
    return version.major >= 2 and version.minor >= 4


def _check_tf() -> bool:
    
    
    if importlib.util.find_spec("tensorflow") is None:
        logger.warning("Tensorflow not installed, cannot initialize profiling plugin")
        return False

    
    version = _get_tf_versioning()
    if version is None:
        logger.warning(
            "Could not find major, minor, and patch versions of tensorflow. Version found: %s",
            version,
        )
        return False

    
    if not _is_compatible_version(version):
        logger.warning(
            "Version %s is incompatible with tf profiler."
            "To use the profiler, choose a version >= 2.2.0",
            "%s.%s.%s" % (version.major, version.minor, version.patch),
        )
        return False

    
    if importlib.util.find_spec("tensorboard_plugin_profile") is None:
        logger.warning(
            "Could not import tensorboard_plugin_profile, will not run tf profiling service"
        )
        return False

    return True


def _create_profiling_context() -> tensorboard_base_plugin.TBContext:
    

    context_flags = argparse.Namespace(master_tpu_unsecure_channel=None)

    context = tensorboard_base_plugin.TBContext(
        logdir=environment_variables.tensorboard_log_dir,
        multiplexer=None,
        flags=context_flags,
    )

    return context


def _host_to_grpc(hostname: str) -> str:
    
    return (
        "grpc://"
        + "".join(hostname.split(":")[:-1])
        + ":"
        + environment_variables.tf_profiler_port
    )


def _get_hostnames() -> Optional[str]:
    
    cluster_spec = environment_variables.cluster_spec
    if cluster_spec is None:
        return

    cluster = cluster_spec.get("cluster", "")
    if not cluster:
        return

    hostnames = []
    for value in cluster.values():
        hostnames.extend(value)

    return ",".join([_host_to_grpc(x) for x in hostnames])


def _update_environ(environ: wsgi_types.Environment) -> bool:
    
    hosts = _get_hostnames()

    if hosts is None:
        return False

    query_dict = {}
    query_dict["service_addr"] = hosts

    
    
    
    prev_query_string = dict(parse.parse_qsl(environ["QUERY_STRING"]))
    prev_query_string.update(query_dict)

    environ["QUERY_STRING"] = parse.urlencode(prev_query_string)

    return True


def warn_tensorboard_env_var(var_name: str):
    
    logging.warning(
        "Environment variable `%s` must be set. %s", var_name, _BASE_TB_ENV_WARNING
    )


def _check_env_vars() -> bool:
    
    
    if environment_variables.tf_profiler_port is None:
        warn_tensorboard_env_var("AIP_TF_PROFILER_PORT")
        return False

    if environment_variables.tensorboard_log_dir is None:
        warn_tensorboard_env_var("AIP_TENSORBOARD_LOG_DIR")
        return False

    if environment_variables.tensorboard_api_uri is None:
        warn_tensorboard_env_var("AIP_TENSORBOARD_API_URI")
        return False

    if environment_variables.tensorboard_resource_name is None:
        warn_tensorboard_env_var("AIP_TENSORBOARD_RESOURCE_NAME")
        return False

    
    
    cluster_spec = environment_variables.cluster_spec
    if cluster_spec is None:
        logger.warning("Environment variable `CLUSTER_SPEC` is not set.")
        return False

    if environment_variables.cloud_ml_job_id is None:
        logger.warning("Environment variable `CLOUD_ML_JOB_ID` is not set")
        return False

    return True


class TFProfiler(base_plugin.BasePlugin):
    

    PLUGIN_NAME = "profile"

    def __init__(self):
        
        context = _create_profiling_context()
        self._profile_request_sender: profile_uploader.ProfileRequestSender = (
            tensorboard_api.create_profile_request_sender()
        )
        self._profile_plugin: ProfilePlugin = ProfilePlugin(context)

    def get_routes(
        self,
    ) -> Dict[str, Callable[[Dict[str, str], Callable[..., None]], Response]]:
        
        return {"/capture_profile": self.capture_profile_wrapper}

    
    def capture_profile_wrapper(
        self, environ: wsgi_types.Environment, start_response: wsgi_types.StartResponse
    ) -> Response:
        
        
        if not _update_environ(environ):
            err = {"error": "Could not parse the environ: %s"}
            return Response(
                json.dumps(err), content_type="application/json", status=500
            )

        response = self._profile_plugin.capture_route(environ, start_response)

        self._profile_request_sender.send_request("")

        return response

    

    @staticmethod
    def setup() -> None:
        
        tf.profiler.experimental.server.start(
            int(environment_variables.tf_profiler_port)
        )

    @staticmethod
    def post_setup_check() -> bool:
        
        cluster_spec = environment_variables.cluster_spec
        task_type = cluster_spec.get("task", {}).get("type", "")
        task_index = cluster_spec.get("task", {}).get("index", -1)

        return task_type in {"workerpool0", "chief"} and task_index == 0

    @staticmethod
    def can_initialize() -> bool:
        

        return _check_env_vars() and _check_tf()
