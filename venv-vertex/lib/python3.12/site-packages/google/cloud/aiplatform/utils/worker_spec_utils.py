















from typing import NamedTuple, Optional, Dict, Union, List, Literal

from google.cloud.aiplatform import utils
from google.cloud.aiplatform.compat.types import (
    accelerator_type as gca_accelerator_type_compat,
)





_SPEC_ORDERS = {
    "chief_spec": 0,
    "worker_spec": 1,
    "server_spec": 2,
    "evaluator_spec": 3,
}


class _WorkerPoolSpec(NamedTuple):
    

    replica_count: int = 0
    machine_type: str = "n1-standard-4"
    accelerator_count: int = 0
    accelerator_type: str = "ACCELERATOR_TYPE_UNSPECIFIED"
    boot_disk_type: str = "pd-ssd"
    boot_disk_size_gb: int = 100
    tpu_topology: Optional[str] = None
    reservation_affinity_type: Optional[
        Literal["NO_RESERVATION", "ANY_RESERVATION", "SPECIFIC_RESERVATION"]
    ] = None
    reservation_affinity_key: Optional[str] = None
    reservation_affinity_values: Optional[List[str]] = None

    def _get_accelerator_type(self) -> Optional[str]:
        

        
        utils.validate_accelerator_type(self.accelerator_type)

        accelerator_enum = getattr(
            gca_accelerator_type_compat.AcceleratorType, self.accelerator_type
        )

        if (
            accelerator_enum
            != gca_accelerator_type_compat.AcceleratorType.ACCELERATOR_TYPE_UNSPECIFIED
        ):
            return self.accelerator_type

    @property
    def spec_dict(self) -> Dict[str, Union[int, str, Dict[str, Union[int, str]]]]:
        
        spec = {
            "machine_spec": {"machine_type": self.machine_type},
            "replica_count": self.replica_count,
            "disk_spec": {
                "boot_disk_type": self.boot_disk_type,
                "boot_disk_size_gb": self.boot_disk_size_gb,
            },
        }

        accelerator_type = self._get_accelerator_type()
        if accelerator_type and self.accelerator_count:
            spec["machine_spec"]["accelerator_type"] = accelerator_type
            spec["machine_spec"]["accelerator_count"] = self.accelerator_count

        if self.tpu_topology:
            spec["machine_spec"]["tpu_topology"] = self.tpu_topology

        if self.reservation_affinity_type:
            spec["machine_spec"]["reservation_affinity"] = {
                "reservation_affinity_type": self.reservation_affinity_type,
            }
            if self.reservation_affinity_type == "SPECIFIC_RESERVATION":
                spec["machine_spec"]["reservation_affinity"][
                    "key"
                ] = self.reservation_affinity_key
                spec["machine_spec"]["reservation_affinity"][
                    "values"
                ] = self.reservation_affinity_values

        return spec

    @property
    def is_empty(self) -> bool:
        
        return self.replica_count <= 0


class _DistributedTrainingSpec(NamedTuple):
    

    chief_spec: _WorkerPoolSpec = _WorkerPoolSpec()
    worker_spec: _WorkerPoolSpec = _WorkerPoolSpec()
    server_spec: _WorkerPoolSpec = _WorkerPoolSpec()
    evaluator_spec: _WorkerPoolSpec = _WorkerPoolSpec()

    @property
    def pool_specs(
        self,
    ) -> List[Dict[str, Union[int, str, Dict[str, Union[int, str]]]]]:
        
        if self.chief_spec.replica_count > 1:
            raise ValueError("Chief spec replica count cannot be greater than 1.")

        spec_order = [
            self.chief_spec,
            self.worker_spec,
            self.server_spec,
            self.evaluator_spec,
        ]
        specs = [{} if s.is_empty else s.spec_dict for s in spec_order]
        for i in reversed(range(len(spec_order))):
            if spec_order[i].is_empty:
                specs.pop()
            else:
                break
        return specs

    @classmethod
    def chief_worker_pool(
        cls,
        replica_count: int = 0,
        machine_type: str = "n1-standard-4",
        accelerator_count: int = 0,
        accelerator_type: str = "ACCELERATOR_TYPE_UNSPECIFIED",
        boot_disk_type: str = "pd-ssd",
        boot_disk_size_gb: int = 100,
        reduction_server_replica_count: int = 0,
        reduction_server_machine_type: str = None,
        tpu_topology: str = None,
        reservation_affinity_type: Optional[
            Literal["NO_RESERVATION", "ANY_RESERVATION", "SPECIFIC_RESERVATION"]
        ] = None,
        reservation_affinity_key: Optional[str] = None,
        reservation_affinity_values: Optional[List[str]] = None,
    ) -> "_DistributedTrainingSpec":
        
        if replica_count <= 0:
            return cls()

        chief_spec = _WorkerPoolSpec(
            replica_count=1,
            machine_type=machine_type,
            accelerator_count=accelerator_count,
            accelerator_type=accelerator_type,
            boot_disk_type=boot_disk_type,
            boot_disk_size_gb=boot_disk_size_gb,
            tpu_topology=tpu_topology,
            reservation_affinity_type=reservation_affinity_type,
            reservation_affinity_key=reservation_affinity_key,
            reservation_affinity_values=reservation_affinity_values,
        )

        worker_spec = _WorkerPoolSpec(
            replica_count=replica_count - 1,
            machine_type=machine_type,
            accelerator_count=accelerator_count,
            accelerator_type=accelerator_type,
            boot_disk_type=boot_disk_type,
            boot_disk_size_gb=boot_disk_size_gb,
            reservation_affinity_type=reservation_affinity_type,
            reservation_affinity_key=reservation_affinity_key,
            reservation_affinity_values=reservation_affinity_values,
        )

        reduction_server_spec = _WorkerPoolSpec(
            replica_count=reduction_server_replica_count,
            machine_type=reduction_server_machine_type,
            reservation_affinity_type=reservation_affinity_type,
            reservation_affinity_key=reservation_affinity_key,
            reservation_affinity_values=reservation_affinity_values,
        )

        return cls(
            chief_spec=chief_spec,
            worker_spec=worker_spec,
            server_spec=reduction_server_spec,
        )
