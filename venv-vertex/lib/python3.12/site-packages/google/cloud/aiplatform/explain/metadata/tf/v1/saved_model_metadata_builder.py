















from google.protobuf import json_format
from typing import Any, Dict, List, Optional

from google.cloud.aiplatform.compat.types import explanation_metadata
from google.cloud.aiplatform.explain.metadata import metadata_builder


class SavedModelMetadataBuilder(metadata_builder.MetadataBuilder):
    

    def __init__(
        self,
        model_path: str,
        tags: Optional[List[str]] = None,
        signature_name: Optional[str] = None,
        outputs_to_explain: Optional[List[str]] = None,
    ) -> None:
        
        if outputs_to_explain:
            if len(outputs_to_explain) > 1:
                raise ValueError(
                    "Only one output is supported at the moment. "
                    f"Received: {outputs_to_explain}."
                )
            self._output_to_explain = next(iter(outputs_to_explain))

        try:
            import tensorflow.compat.v1 as tf
        except ImportError:
            raise ImportError(
                "Tensorflow is not installed and is required to load saved model. "
                'Please install the SDK using "pip install "tensorflow>=1.15,<2.0""'
            )

        if not signature_name:
            signature_name = tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY
        self._tags = tags or [tf.saved_model.tag_constants.SERVING]
        self._graph = tf.Graph()

        with self.graph.as_default():
            self._session = tf.Session(graph=self.graph)
            self._metagraph_def = tf.saved_model.loader.load(
                sess=self.session, tags=self._tags, export_dir=model_path
            )
            if signature_name not in self._metagraph_def.signature_def:
                raise ValueError(
                    f"Serving sigdef key {signature_name} not in the signature def."
                )
            serving_sigdef = self._metagraph_def.signature_def[signature_name]
        if not outputs_to_explain:
            if len(serving_sigdef.outputs) > 1:
                raise ValueError(
                    "The signature contains multiple outputs. Specify "
                    'an output via "outputs_to_explain" parameter.'
                )
            self._output_to_explain = next(iter(serving_sigdef.outputs.keys()))

        self._inputs = _create_input_metadata_from_signature(serving_sigdef.inputs)
        self._outputs = _create_output_metadata_from_signature(
            serving_sigdef.outputs, self._output_to_explain
        )

    @property
    def graph(self) -> "tf.Graph":  
        return self._graph

    @property
    def session(self) -> "tf.Session":  
        return self._session

    def get_metadata(self) -> Dict[str, Any]:
        
        return json_format.MessageToDict(self.get_metadata_protobuf()._pb)

    def get_metadata_protobuf(self) -> explanation_metadata.ExplanationMetadata:
        
        return explanation_metadata.ExplanationMetadata(
            inputs=self._inputs,
            outputs=self._outputs,
        )


def _create_input_metadata_from_signature(
    signature_inputs: Dict[str, "tf.Tensor"]  
) -> Dict[str, explanation_metadata.ExplanationMetadata.InputMetadata]:
    
    input_mds = {}
    for key, tensor in signature_inputs.items():
        input_mds[key] = explanation_metadata.ExplanationMetadata.InputMetadata(
            input_tensor_name=tensor.name
        )
    return input_mds


def _create_output_metadata_from_signature(
    signature_outputs: Dict[str, "tf.Tensor"],  
    output_to_explain: Optional[str] = None,
) -> Dict[str, explanation_metadata.ExplanationMetadata.OutputMetadata]:
    
    output_mds = {}
    for key, tensor in signature_outputs.items():
        if not output_to_explain or output_to_explain == key:
            output_mds[key] = explanation_metadata.ExplanationMetadata.OutputMetadata(
                output_tensor_name=tensor.name
            )
    return output_mds
