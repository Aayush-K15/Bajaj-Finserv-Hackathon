
















from dataclasses import dataclass, field
from typing import Dict, List, Optional, Sequence, Tuple, Union

from google.auth import credentials as auth_credentials
from google.cloud.aiplatform import base
from google.cloud.aiplatform import initializer
from google.cloud.aiplatform import matching_engine
from google.cloud.aiplatform import utils
from google.cloud.aiplatform.compat.types import (
    machine_resources as gca_machine_resources_compat,
    matching_engine_index_endpoint as gca_matching_engine_index_endpoint,
    match_service_v1beta1 as gca_match_service_v1beta1,
    index_v1beta1 as gca_index_v1beta1,
    service_networking as gca_service_networking,
    encryption_spec as gca_encryption_spec,
)
from google.cloud.aiplatform.matching_engine._protos import match_service_pb2
from google.cloud.aiplatform.matching_engine._protos import (
    match_service_pb2_grpc,
)
from google.protobuf import field_mask_pb2

import grpc

_LOGGER = base.Logger(__name__)


@dataclass
class Namespace:
    

    name: str
    allow_tokens: list = field(default_factory=list)
    deny_tokens: list = field(default_factory=list)


@dataclass
class NumericNamespace:
    

    name: str
    value_int: Optional[int] = None
    value_float: Optional[float] = None
    value_double: Optional[float] = None
    op: Optional[str] = None

    def __post_init__(self):
        
        
        if (
            self.value_int is None
            and self.value_float is None
            and self.value_double is None
        ):
            raise ValueError(
                "Must choose one among `value_int`,"
                "`value_float` and `value_double` for "
                "intended precision."
            )

        
        if self.value_int is not None and not isinstance(self.value_int, int):
            raise ValueError(
                "value_int must be of type int, got" f" { type(self.value_int)}."
            )
        if self.value_float is not None and not isinstance(self.value_float, float):
            raise ValueError(
                "value_float must be of type float, got " f"{ type(self.value_float)}."
            )
        if self.value_double is not None and not isinstance(self.value_double, float):
            raise ValueError(
                "value_double must be of type float, got "
                f"{ type(self.value_double)}."
            )
        
        if (
            self.op is not None
            and self.op
            not in gca_index_v1beta1.IndexDatapoint.NumericRestriction.Operator._member_names_
        ):
            raise ValueError(
                f"Invalid operator '{self.op}'," " must be one of the valid operators."
            )


@dataclass
class HybridQuery:
    

    dense_embedding: List[float] = None
    sparse_embedding_values: List[float] = None
    sparse_embedding_dimensions: List[int] = None
    rrf_ranking_alpha: float = None


@dataclass
class MatchNeighbor:
    

    id: str
    distance: Optional[float] = None
    sparse_distance: Optional[float] = None
    feature_vector: Optional[List[float]] = None
    crowding_tag: Optional[str] = None
    restricts: Optional[List[Namespace]] = None
    numeric_restricts: Optional[List[NumericNamespace]] = None
    sparse_embedding_values: Optional[List[float]] = None
    sparse_embedding_dimensions: Optional[List[int]] = None

    def from_index_datapoint(
        self, index_datapoint: gca_index_v1beta1.IndexDatapoint
    ) -> "MatchNeighbor":
        
        if not index_datapoint:
            return self
        self.feature_vector = index_datapoint.feature_vector
        if (
            index_datapoint.crowding_tag is not None
            and index_datapoint.crowding_tag.crowding_attribute is not None
        ):
            self.crowding_tag = index_datapoint.crowding_tag.crowding_attribute
        self.restricts = [
            Namespace(
                name=restrict.namespace,
                allow_tokens=restrict.allow_list,
                deny_tokens=restrict.deny_list,
            )
            for restrict in index_datapoint.restricts
        ]
        if index_datapoint.numeric_restricts is not None:
            self.numeric_restricts = []
            for restrict in index_datapoint.numeric_restricts:
                numeric_namespace = None
                restrict_value_type = restrict._pb.WhichOneof("Value")
                if restrict_value_type == "value_int":
                    numeric_namespace = NumericNamespace(
                        name=restrict.namespace, value_int=restrict.value_int
                    )
                elif restrict_value_type == "value_float":
                    numeric_namespace = NumericNamespace(
                        name=restrict.namespace, value_float=restrict.value_float
                    )
                elif restrict_value_type == "value_double":
                    numeric_namespace = NumericNamespace(
                        name=restrict.namespace, value_double=restrict.value_double
                    )
                self.numeric_restricts.append(numeric_namespace)
        
        if (
            index_datapoint.sparse_embedding is not None
            and index_datapoint.sparse_embedding.values is not None
        ):
            self.sparse_embedding_values = index_datapoint.sparse_embedding.values
            self.sparse_embedding_dimensions = (
                index_datapoint.sparse_embedding.dimensions
            )
        return self

    def from_embedding(self, embedding: match_service_pb2.Embedding) -> "MatchNeighbor":
        
        if not embedding:
            return self
        self.feature_vector = embedding.float_val
        if not self.crowding_tag and embedding.crowding_attribute is not None:
            self.crowding_tag = str(embedding.crowding_attribute)
        self.restricts = [
            Namespace(
                name=restrict.name,
                allow_tokens=restrict.allow_tokens,
                deny_tokens=restrict.deny_tokens,
            )
            for restrict in embedding.restricts
        ]
        if embedding.numeric_restricts:
            self.numeric_restricts = []
            for restrict in embedding.numeric_restricts:
                numeric_namespace = None
                restrict_value_type = restrict.WhichOneof("Value")
                if restrict_value_type == "value_int":
                    numeric_namespace = NumericNamespace(
                        name=restrict.name, value_int=restrict.value_int
                    )
                elif restrict_value_type == "value_float":
                    numeric_namespace = NumericNamespace(
                        name=restrict.name, value_float=restrict.value_float
                    )
                elif restrict_value_type == "value_double":
                    numeric_namespace = NumericNamespace(
                        name=restrict.name, value_double=restrict.value_double
                    )
                self.numeric_restricts.append(numeric_namespace)
        if embedding.sparse_embedding:
            self.sparse_embedding_values = embedding.sparse_embedding.float_val
            self.sparse_embedding_dimensions = embedding.sparse_embedding.dimension
        return self


class MatchingEngineIndexEndpoint(base.VertexAiResourceNounWithFutureManager):
    

    client_class = utils.IndexEndpointClientWithOverride

    _resource_noun = "indexEndpoints"
    _getter_method = "get_index_endpoint"
    _list_method = "list_index_endpoints"
    _delete_method = "delete_index_endpoint"
    _parse_resource_name_method = "parse_index_endpoint_path"
    _format_resource_name_method = "index_endpoint_path"

    def __init__(
        self,
        index_endpoint_name: str,
        project: Optional[str] = None,
        location: Optional[str] = None,
        credentials: Optional[auth_credentials.Credentials] = None,
    ):
        

        super().__init__(
            project=project,
            location=location,
            credentials=credentials,
            resource_name=index_endpoint_name,
        )
        self._gca_resource = self._get_gca_resource(resource_name=index_endpoint_name)

        self._public_match_client = None
        if self.public_endpoint_domain_name:
            self._public_match_client = self._instantiate_public_match_client()

        self._match_grpc_stub_cache = {}
        self._private_service_connect_ip_address = None

    @classmethod
    def create(
        cls,
        display_name: str,
        network: Optional[str] = None,
        public_endpoint_enabled: bool = False,
        description: Optional[str] = None,
        labels: Optional[Dict[str, str]] = None,
        project: Optional[str] = None,
        location: Optional[str] = None,
        credentials: Optional[auth_credentials.Credentials] = None,
        request_metadata: Optional[Sequence[Tuple[str, str]]] = (),
        sync: bool = True,
        enable_private_service_connect: bool = False,
        project_allowlist: Optional[Sequence[str]] = None,
        encryption_spec_key_name: Optional[str] = None,
        create_request_timeout: Optional[float] = None,
    ) -> "MatchingEngineIndexEndpoint":
        
        network = network or initializer.global_config.network

        if not (network or public_endpoint_enabled or enable_private_service_connect):
            raise ValueError(
                "Please provide `network` argument for Private Service Access endpoint,"
                "or provide `enable_private_service_connect` for Private Service"
                "Connect endpoint, or provide `public_endpoint_enabled` to"
                "deploy to a public endpoint"
            )

        if (
            sum(
                bool(network_setting)
                for network_setting in [
                    network,
                    public_endpoint_enabled,
                    enable_private_service_connect,
                ]
            )
            > 1
        ):
            raise ValueError(
                "One and only one among network, public_endpoint_enabled and enable_private_service_connect should be set."
            )

        return cls._create(
            display_name=display_name,
            network=network,
            public_endpoint_enabled=public_endpoint_enabled,
            description=description,
            labels=labels,
            project=project,
            location=location,
            credentials=credentials,
            request_metadata=request_metadata,
            sync=sync,
            enable_private_service_connect=enable_private_service_connect,
            project_allowlist=project_allowlist,
            encryption_spec_key_name=encryption_spec_key_name,
            create_request_timeout=create_request_timeout,
        )

    @classmethod
    @base.optional_sync()
    def _create(
        cls,
        display_name: str,
        network: Optional[str] = None,
        public_endpoint_enabled: bool = False,
        description: Optional[str] = None,
        labels: Optional[Dict[str, str]] = None,
        project: Optional[str] = None,
        location: Optional[str] = None,
        credentials: Optional[auth_credentials.Credentials] = None,
        request_metadata: Optional[Sequence[Tuple[str, str]]] = (),
        sync: bool = True,
        enable_private_service_connect: bool = False,
        project_allowlist: Optional[Sequence[str]] = None,
        encryption_spec_key_name: Optional[str] = None,
        create_request_timeout: Optional[float] = None,
    ) -> "MatchingEngineIndexEndpoint":
        
        
        if public_endpoint_enabled:
            gapic_index_endpoint = gca_matching_engine_index_endpoint.IndexEndpoint(
                display_name=display_name,
                description=description,
                public_endpoint_enabled=public_endpoint_enabled,
            )
        
        elif network:
            gapic_index_endpoint = gca_matching_engine_index_endpoint.IndexEndpoint(
                display_name=display_name, description=description, network=network
            )
        
        else:
            gapic_index_endpoint = gca_matching_engine_index_endpoint.IndexEndpoint(
                display_name=display_name,
                description=description,
                private_service_connect_config=gca_service_networking.PrivateServiceConnectConfig(
                    project_allowlist=project_allowlist,
                    enable_private_service_connect=enable_private_service_connect,
                ),
            )

        if encryption_spec_key_name:
            gapic_index_endpoint.encryption_spec = gca_encryption_spec.EncryptionSpec(
                kms_key_name=encryption_spec_key_name
            )

        if labels:
            utils.validate_labels(labels)
            gapic_index_endpoint.labels = labels

        api_client = cls._instantiate_client(location=location, credentials=credentials)

        create_lro = api_client.create_index_endpoint(
            parent=initializer.global_config.common_location_path(
                project=project, location=location
            ),
            index_endpoint=gapic_index_endpoint,
            metadata=request_metadata,
            timeout=create_request_timeout,
        )

        _LOGGER.log_create_with_lro(cls, create_lro)

        created_index = create_lro.result()

        _LOGGER.log_create_complete(cls, created_index, "index_endpoint")

        index_obj = cls(
            index_endpoint_name=created_index.name,
            project=project,
            location=location,
            credentials=credentials,
        )

        return index_obj

    def _instantiate_public_match_client(
        self,
    ) -> utils.MatchClientWithOverride:
        
        return initializer.global_config.create_client(
            client_class=utils.MatchClientWithOverride,
            credentials=self.credentials,
            location_override=self.location,
            api_path_override=self.public_endpoint_domain_name,
        )

    def _get_psc_automated_deployed_index_ip_address(
        self,
        deployed_index_id: Optional[str] = None,
        deployed_index: Optional[
            gca_matching_engine_index_endpoint.DeployedIndex
        ] = None,
        psc_network: Optional[str] = None,
    ) -> str:
        
        if deployed_index_id:
            deployed_indexes = [
                deployed_index
                for deployed_index in self.deployed_indexes
                if deployed_index.id == deployed_index_id
            ]
            deployed_index = deployed_indexes[0]
        else:
            deployed_index_id = deployed_index.id

        ip_address = None
        
        
        psc_network_list = [
            endpoint.network
            for endpoint in deployed_index.private_endpoints.psc_automated_endpoints
        ]
        for endpoint in deployed_index.private_endpoints.psc_automated_endpoints:
            if psc_network == endpoint.network:
                ip_address = endpoint.match_address
                break
        if not ip_address:
            raise RuntimeError(
                f"No valid ip found for deployed index with id "
                f"'{deployed_index_id}' within network '{psc_network}', "
                "invalid PSC network provided. A list of valid PSC networks"
                f"are: '{psc_network_list}'."
            )
        return ip_address

    def _instantiate_private_match_service_stub(
        self,
        deployed_index_id: Optional[str] = None,
        ip_address: Optional[str] = None,
        psc_network: Optional[str] = None,
    ) -> match_service_pb2_grpc.MatchServiceStub:
        

        if ip_address:
            
            if self.public_endpoint_domain_name:
                raise ValueError(
                    "MatchingEngineIndexEndpoint is set to use ",
                    "public network. Could not establish connection using "
                    "provided ip address",
                )
            elif self.private_service_access_network:
                raise ValueError(
                    "MatchingEngineIndexEndpoint is set to use ",
                    "private service access network. Could not establish "
                    "connection using provided ip address",
                )
        else:
            deployed_indexes = [
                deployed_index
                for deployed_index in self.deployed_indexes
                if deployed_index.id == deployed_index_id
            ]

            if not deployed_indexes:
                raise RuntimeError(
                    f"No deployed index with id '{deployed_index_id}' found"
                )

            if deployed_indexes[0].private_endpoints.psc_automated_endpoints:
                ip_address = self._get_psc_automated_deployed_index_ip_address(
                    deployed_index_id=deployed_index_id,
                    psc_network=psc_network,
                )
            else:
                
                ip_address = deployed_indexes[0].private_endpoints.match_grpc_address

        if ip_address not in self._match_grpc_stub_cache:
            
            channel = grpc.insecure_channel("{}:10000".format(ip_address))
            self._match_grpc_stub_cache[
                ip_address
            ] = match_service_pb2_grpc.MatchServiceStub(channel)
        return self._match_grpc_stub_cache[ip_address]

    @property
    def public_endpoint_domain_name(self) -> Optional[str]:
        
        self._assert_gca_resource_is_available()
        return self._gca_resource.public_endpoint_domain_name

    @property
    def private_service_access_network(self) -> Optional[str]:
        
        self._assert_gca_resource_is_available()
        return self._gca_resource.network

    @property
    def private_service_connect_ip_address(self) -> Optional[str]:
        
        return self._private_service_connect_ip_address

    @private_service_connect_ip_address.setter
    def private_service_connect_ip_address(self, ip_address: str) -> Optional[str]:
        
        self._private_service_connect_ip_address = ip_address

    def update(
        self,
        display_name: str,
        description: Optional[str] = None,
        labels: Optional[Dict[str, str]] = None,
        request_metadata: Optional[Sequence[Tuple[str, str]]] = (),
        update_request_timeout: Optional[float] = None,
    ) -> "MatchingEngineIndexEndpoint":
        

        self.wait()

        update_mask = list()

        if labels:
            utils.validate_labels(labels)
            update_mask.append("labels")

        if display_name is not None:
            update_mask.append("display_name")

        if description is not None:
            update_mask.append("description")

        update_mask = field_mask_pb2.FieldMask(paths=update_mask)

        gapic_index_endpoint = gca_matching_engine_index_endpoint.IndexEndpoint(
            name=self.resource_name,
            display_name=display_name,
            description=description,
            labels=labels,
        )

        self._gca_resource = self.api_client.update_index_endpoint(
            index_endpoint=gapic_index_endpoint,
            update_mask=update_mask,
            metadata=request_metadata,
            timeout=update_request_timeout,
        )

        return self

    @staticmethod
    def _build_deployed_index(
        deployed_index_id: str,
        index_resource_name: Optional[str] = None,
        display_name: Optional[str] = None,
        machine_type: Optional[str] = None,
        min_replica_count: Optional[int] = None,
        max_replica_count: Optional[int] = None,
        enable_access_logging: Optional[bool] = None,
        reserved_ip_ranges: Optional[Sequence[str]] = None,
        deployment_group: Optional[str] = None,
        auth_config_audiences: Optional[Sequence[str]] = None,
        auth_config_allowed_issuers: Optional[Sequence[str]] = None,
        psc_automation_configs: Optional[Sequence[Tuple[str, str]]] = None,
    ) -> gca_matching_engine_index_endpoint.DeployedIndex:
        

        deployed_index = gca_matching_engine_index_endpoint.DeployedIndex(
            id=deployed_index_id,
            index=index_resource_name,
            display_name=display_name,
            enable_access_logging=enable_access_logging,
            reserved_ip_ranges=reserved_ip_ranges,
            deployment_group=deployment_group,
        )

        if auth_config_audiences and auth_config_allowed_issuers:
            deployed_index.deployed_index_auth_config = gca_matching_engine_index_endpoint.DeployedIndexAuthConfig(
                auth_provider=gca_matching_engine_index_endpoint.DeployedIndexAuthConfig.AuthProvider(
                    audiences=auth_config_audiences,
                    allowed_issuers=auth_config_allowed_issuers,
                )
            )

        if machine_type:
            machine_spec = gca_machine_resources_compat.MachineSpec(
                machine_type=machine_type
            )

            deployed_index.dedicated_resources = (
                gca_machine_resources_compat.DedicatedResources(
                    machine_spec=machine_spec,
                    min_replica_count=min_replica_count,
                    max_replica_count=max_replica_count,
                )
            )

        else:
            deployed_index.automatic_resources = (
                gca_machine_resources_compat.AutomaticResources(
                    min_replica_count=min_replica_count,
                    max_replica_count=max_replica_count,
                )
            )

        if psc_automation_configs:
            deployed_index.psc_automation_configs = [
                gca_service_networking.PSCAutomationConfig(
                    project_id=psc_automation_config[0],
                    network=psc_automation_config[1],
                )
                for psc_automation_config in psc_automation_configs
            ]

        return deployed_index

    def deploy_index(
        self,
        index: matching_engine.MatchingEngineIndex,
        deployed_index_id: str,
        display_name: Optional[str] = None,
        machine_type: Optional[str] = None,
        min_replica_count: Optional[int] = None,
        max_replica_count: Optional[int] = None,
        enable_access_logging: Optional[bool] = None,
        reserved_ip_ranges: Optional[Sequence[str]] = None,
        deployment_group: Optional[str] = None,
        auth_config_audiences: Optional[Sequence[str]] = None,
        auth_config_allowed_issuers: Optional[Sequence[str]] = None,
        request_metadata: Optional[Sequence[Tuple[str, str]]] = (),
        sync: bool = True,
        deploy_request_timeout: Optional[float] = None,
        psc_automation_configs: Optional[Sequence[Tuple[str, str]]] = None,
    ) -> "MatchingEngineIndexEndpoint":
        
        return self._deploy_index(
            index=index,
            deployed_index_id=deployed_index_id,
            display_name=display_name,
            machine_type=machine_type,
            min_replica_count=min_replica_count,
            max_replica_count=max_replica_count,
            enable_access_logging=enable_access_logging,
            reserved_ip_ranges=reserved_ip_ranges,
            deployment_group=deployment_group,
            auth_config_audiences=auth_config_audiences,
            auth_config_allowed_issuers=auth_config_allowed_issuers,
            request_metadata=request_metadata,
            sync=sync,
            deploy_request_timeout=deploy_request_timeout,
            psc_automation_configs=psc_automation_configs,
        )

    @base.optional_sync(return_input_arg="self")
    def _deploy_index(
        self,
        index: matching_engine.MatchingEngineIndex,
        deployed_index_id: str,
        display_name: Optional[str] = None,
        machine_type: Optional[str] = None,
        min_replica_count: Optional[int] = None,
        max_replica_count: Optional[int] = None,
        enable_access_logging: Optional[bool] = None,
        reserved_ip_ranges: Optional[Sequence[str]] = None,
        deployment_group: Optional[str] = None,
        auth_config_audiences: Optional[Sequence[str]] = None,
        auth_config_allowed_issuers: Optional[Sequence[str]] = None,
        request_metadata: Optional[Sequence[Tuple[str, str]]] = (),
        sync: bool = True,
        deploy_request_timeout: Optional[float] = None,
        psc_automation_configs: Optional[Sequence[Tuple[str, str]]] = None,
    ) -> "MatchingEngineIndexEndpoint":
        

        self.wait()

        _LOGGER.log_action_start_against_resource(
            "Deploying index",
            "index_endpoint",
            self,
        )

        deployed_index = self._build_deployed_index(
            deployed_index_id=deployed_index_id,
            index_resource_name=index.resource_name,
            display_name=display_name,
            machine_type=machine_type,
            min_replica_count=min_replica_count,
            max_replica_count=max_replica_count,
            enable_access_logging=enable_access_logging,
            reserved_ip_ranges=reserved_ip_ranges,
            deployment_group=deployment_group,
            auth_config_audiences=auth_config_audiences,
            auth_config_allowed_issuers=auth_config_allowed_issuers,
            psc_automation_configs=psc_automation_configs,
        )

        deploy_lro = self.api_client.deploy_index(
            index_endpoint=self.resource_name,
            deployed_index=deployed_index,
            metadata=request_metadata,
            timeout=deploy_request_timeout,
        )

        _LOGGER.log_action_started_against_resource_with_lro(
            "Deploy index", "index_endpoint", self.__class__, deploy_lro
        )

        deploy_lro.result(timeout=None)

        _LOGGER.log_action_completed_against_resource(
            "index_endpoint", "Deployed index", self
        )

        
        self._sync_gca_resource()

        return self

    def undeploy_index(
        self,
        deployed_index_id: str,
        request_metadata: Optional[Sequence[Tuple[str, str]]] = (),
        undeploy_request_timeout: Optional[float] = None,
    ) -> "MatchingEngineIndexEndpoint":
        

        self.wait()

        _LOGGER.log_action_start_against_resource(
            "Undeploying index",
            "index_endpoint",
            self,
        )

        undeploy_lro = self.api_client.undeploy_index(
            index_endpoint=self.resource_name,
            deployed_index_id=deployed_index_id,
            metadata=request_metadata,
            timeout=undeploy_request_timeout,
        )

        _LOGGER.log_action_started_against_resource_with_lro(
            "Undeploy index", "index_endpoint", self.__class__, undeploy_lro
        )

        undeploy_lro.result()

        _LOGGER.log_action_completed_against_resource(
            "index_endpoint", "Undeployed index", self
        )

        return self

    def mutate_deployed_index(
        self,
        deployed_index_id: str,
        min_replica_count: int = 1,
        max_replica_count: int = 1,
        request_metadata: Optional[Sequence[Tuple[str, str]]] = (),
        mutate_request_timeout: Optional[float] = None,
    ):
        

        self.wait()

        _LOGGER.log_action_start_against_resource(
            "Mutating index",
            "index_endpoint",
            self,
        )

        deployed_index = self._build_deployed_index(
            index_resource_name=None,
            deployed_index_id=deployed_index_id,
            min_replica_count=min_replica_count,
            max_replica_count=max_replica_count,
        )

        deploy_lro = self.api_client.mutate_deployed_index(
            index_endpoint=self.resource_name,
            deployed_index=deployed_index,
            metadata=request_metadata,
            timeout=mutate_request_timeout,
        )

        _LOGGER.log_action_started_against_resource_with_lro(
            "Mutate index", "index_endpoint", self.__class__, deploy_lro
        )

        deploy_lro.result()

        
        self._sync_gca_resource()

        _LOGGER.log_action_completed_against_resource("index_endpoint", "Mutated", self)

        return self

    @property
    def deployed_indexes(
        self,
    ) -> List[gca_matching_engine_index_endpoint.DeployedIndex]:
        
        self._assert_gca_resource_is_available()
        return self._gca_resource.deployed_indexes

    @base.optional_sync()
    def _undeploy(
        self,
        deployed_index_id: str,
        metadata: Optional[Sequence[Tuple[str, str]]] = (),
        sync=True,
        undeploy_request_timeout: Optional[float] = None,
    ) -> None:
        
        self._sync_gca_resource()

        _LOGGER.log_action_start_against_resource("Undeploying", "index_endpoint", self)

        operation_future = self.api_client.undeploy_index(
            index_endpoint=self.resource_name,
            deployed_index_id=deployed_index_id,
            metadata=metadata,
            timeout=undeploy_request_timeout,
        )

        _LOGGER.log_action_started_against_resource_with_lro(
            "Undeploy", "index_endpoint", self.__class__, operation_future
        )

        
        operation_future.result()

        
        self._sync_gca_resource()

        _LOGGER.log_action_completed_against_resource(
            "index_endpoint", "undeployed", self
        )

    def undeploy_all(self, sync: bool = True) -> "MatchingEngineIndexEndpoint":
        
        self._sync_gca_resource()

        for deployed_index in self.deployed_indexes:
            self._undeploy(deployed_index_id=deployed_index.id, sync=sync)

        return self

    def delete(self, force: bool = False, sync: bool = True) -> None:
        
        if force:
            self.undeploy_all(sync=sync)

        super().delete(sync=sync)

    @property
    def description(self) -> str:
        
        self._assert_gca_resource_is_available()
        return self._gca_resource.description

    def find_neighbors(
        self,
        *,
        deployed_index_id: str,
        queries: Optional[Union[List[List[float]], List[HybridQuery]]] = None,
        num_neighbors: int = 10,
        filter: Optional[List[Namespace]] = None,
        per_crowding_attribute_neighbor_count: Optional[int] = None,
        approx_num_neighbors: Optional[int] = None,
        fraction_leaf_nodes_to_search_override: Optional[float] = None,
        return_full_datapoint: bool = False,
        numeric_filter: Optional[List[NumericNamespace]] = None,
        embedding_ids: Optional[List[str]] = None,
        signed_jwt: Optional[str] = None,
        psc_network: Optional[str] = None,
    ) -> List[List[MatchNeighbor]]:
        

        if not self._public_match_client:
            
            return self.match(
                deployed_index_id=deployed_index_id,
                queries=queries,
                num_neighbors=num_neighbors,
                filter=filter,
                per_crowding_attribute_num_neighbors=per_crowding_attribute_neighbor_count,
                approx_num_neighbors=approx_num_neighbors,
                fraction_leaf_nodes_to_search_override=fraction_leaf_nodes_to_search_override,
                numeric_filter=numeric_filter,
                signed_jwt=signed_jwt,
                psc_network=psc_network,
            )

        
        find_neighbors_request = gca_match_service_v1beta1.FindNeighborsRequest()
        find_neighbors_request.index_endpoint = self.resource_name
        find_neighbors_request.deployed_index_id = deployed_index_id
        find_neighbors_request.return_full_datapoint = return_full_datapoint

        
        restricts = []
        if filter:
            for namespace in filter:
                restrict = gca_index_v1beta1.IndexDatapoint.Restriction()
                restrict.namespace = namespace.name
                restrict.allow_list.extend(namespace.allow_tokens)
                restrict.deny_list.extend(namespace.deny_tokens)
                restricts.append(restrict)
        
        numeric_restricts = []
        if numeric_filter:
            for numeric_namespace in numeric_filter:
                numeric_restrict = gca_index_v1beta1.IndexDatapoint.NumericRestriction()
                numeric_restrict.namespace = numeric_namespace.name
                numeric_restrict.op = numeric_namespace.op
                numeric_restrict.value_int = numeric_namespace.value_int
                numeric_restrict.value_float = numeric_namespace.value_float
                numeric_restrict.value_double = numeric_namespace.value_double
                numeric_restricts.append(numeric_restrict)
        
        query_by_id = False
        query_is_hybrid = False
        if embedding_ids:
            query_by_id = True
            query_iterators: list[str] = embedding_ids
        elif queries:
            query_is_hybrid = isinstance(queries[0], HybridQuery)
            query_iterators = queries
        else:
            raise ValueError(
                "To find neighbors using matching engine,"
                "please specify `queries` or `embedding_ids` or `hybrid_queries`"
            )

        for query in query_iterators:
            find_neighbors_query = gca_match_service_v1beta1.FindNeighborsRequest.Query(
                neighbor_count=num_neighbors,
                per_crowding_attribute_neighbor_count=per_crowding_attribute_neighbor_count,
                approximate_neighbor_count=approx_num_neighbors,
                fraction_leaf_nodes_to_search_override=fraction_leaf_nodes_to_search_override,
            )
            if query_by_id:
                datapoint = gca_index_v1beta1.IndexDatapoint(
                    datapoint_id=query,
                )
            elif query_is_hybrid:
                datapoint = gca_index_v1beta1.IndexDatapoint(
                    feature_vector=query.dense_embedding,
                    sparse_embedding=gca_index_v1beta1.IndexDatapoint.SparseEmbedding(
                        values=query.sparse_embedding_values,
                        dimensions=query.sparse_embedding_dimensions,
                    ),
                )
                if query.rrf_ranking_alpha:
                    find_neighbors_query.rrf = (
                        gca_match_service_v1beta1.FindNeighborsRequest.Query.RRF(
                            alpha=query.rrf_ranking_alpha,
                        )
                    )
            else:
                datapoint = gca_index_v1beta1.IndexDatapoint(
                    feature_vector=query,
                )
            datapoint.restricts.extend(restricts)
            datapoint.numeric_restricts.extend(numeric_restricts)
            find_neighbors_query.datapoint = datapoint
            find_neighbors_request.queries.append(find_neighbors_query)

        response = self._public_match_client.find_neighbors(find_neighbors_request)

        
        return [
            [
                MatchNeighbor(
                    id=neighbor.datapoint.datapoint_id,
                    distance=neighbor.distance,
                    sparse_distance=neighbor.sparse_distance
                    if neighbor.sparse_distance
                    else None,
                ).from_index_datapoint(index_datapoint=neighbor.datapoint)
                for neighbor in embedding_neighbors.neighbors
            ]
            for embedding_neighbors in response.nearest_neighbors
        ]

    def read_index_datapoints(
        self,
        *,
        deployed_index_id: str,
        ids: List[str] = [],
        signed_jwt: Optional[str] = None,
        psc_network: Optional[str] = None,
    ) -> List[gca_index_v1beta1.IndexDatapoint]:
        
        if not self._public_match_client:
            
            embeddings = self._batch_get_embeddings(
                deployed_index_id=deployed_index_id,
                ids=ids,
                signed_jwt=signed_jwt,
                psc_network=psc_network,
            )

            response = []
            for embedding in embeddings:
                index_datapoint = gca_index_v1beta1.IndexDatapoint(
                    datapoint_id=embedding.id,
                    feature_vector=embedding.float_val,
                    restricts=[
                        gca_index_v1beta1.IndexDatapoint.Restriction(
                            namespace=restrict.name,
                            allow_list=restrict.allow_tokens,
                            deny_list=restrict.deny_tokens,
                        )
                        for restrict in embedding.restricts
                    ],
                )
                if embedding.crowding_attribute:
                    index_datapoint.crowding_tag = (
                        gca_index_v1beta1.IndexDatapoint.CrowdingTag(
                            crowding_attribute=str(embedding.crowding_attribute)
                        )
                    )
                response.append(index_datapoint)
            return response

        
        read_index_datapoints_request = (
            gca_match_service_v1beta1.ReadIndexDatapointsRequest()
        )
        read_index_datapoints_request.index_endpoint = self.resource_name
        read_index_datapoints_request.deployed_index_id = deployed_index_id

        for id in ids:
            read_index_datapoints_request.ids.append(id)

        response = self._public_match_client.read_index_datapoints(
            read_index_datapoints_request
        )

        return response.datapoints

    def _batch_get_embeddings(
        self,
        *,
        deployed_index_id: str,
        ids: List[str] = [],
        signed_jwt: Optional[str] = None,
        psc_network: Optional[str] = None,
    ) -> List[match_service_pb2.Embedding]:
        
        if psc_network:
            stub = self._instantiate_private_match_service_stub(
                deployed_index_id=deployed_index_id, psc_network=psc_network
            )
        else:
            stub = self._instantiate_private_match_service_stub(
                deployed_index_id=deployed_index_id,
                ip_address=self._private_service_connect_ip_address,
            )

        
        batch_request = match_service_pb2.BatchGetEmbeddingsRequest()
        batch_request.deployed_index_id = deployed_index_id

        for id in ids:
            batch_request.id.append(id)
        metadata = None
        if signed_jwt:
            metadata = (("authorization", f"Bearer: {signed_jwt}"),)
        response = stub.BatchGetEmbeddings(batch_request, metadata=metadata)

        return response.embeddings

    def match(
        self,
        deployed_index_id: str,
        queries: Union[List[List[float]], List[HybridQuery]] = None,
        num_neighbors: int = 1,
        filter: Optional[List[Namespace]] = None,
        per_crowding_attribute_num_neighbors: Optional[int] = None,
        approx_num_neighbors: Optional[int] = None,
        fraction_leaf_nodes_to_search_override: Optional[float] = None,
        low_level_batch_size: int = 0,
        numeric_filter: Optional[List[NumericNamespace]] = None,
        signed_jwt: Optional[str] = None,
        psc_network: Optional[str] = None,
    ) -> List[List[MatchNeighbor]]:
        
        if psc_network:
            stub = self._instantiate_private_match_service_stub(
                deployed_index_id=deployed_index_id,
                psc_network=psc_network,
            )
        else:
            stub = self._instantiate_private_match_service_stub(
                deployed_index_id=deployed_index_id,
                ip_address=self._private_service_connect_ip_address,
            )

        
        batch_request = match_service_pb2.BatchMatchRequest()
        batch_request_for_index = (
            match_service_pb2.BatchMatchRequest.BatchMatchRequestPerIndex()
        )
        batch_request_for_index.deployed_index_id = deployed_index_id
        batch_request_for_index.low_level_batch_size = low_level_batch_size

        
        restricts = []
        
        if filter:
            for namespace in filter:
                restrict = match_service_pb2.Namespace()
                restrict.name = namespace.name
                restrict.allow_tokens.extend(namespace.allow_tokens)
                restrict.deny_tokens.extend(namespace.deny_tokens)
                restricts.append(restrict)
        numeric_restricts = []
        
        if numeric_filter:
            for numeric_namespace in numeric_filter:
                numeric_restrict = match_service_pb2.NumericNamespace()
                numeric_restrict.name = numeric_namespace.name
                numeric_restrict.op = match_service_pb2.NumericNamespace.Operator.Value(
                    numeric_namespace.op
                )
                if numeric_namespace.value_int is not None:
                    numeric_restrict.value_int = numeric_namespace.value_int
                if numeric_namespace.value_float is not None:
                    numeric_restrict.value_float = numeric_namespace.value_float
                if numeric_namespace.value_double is not None:
                    numeric_restrict.value_double = numeric_namespace.value_double
                numeric_restricts.append(numeric_restrict)

        requests = []
        if queries:
            query_is_hybrid = isinstance(queries[0], HybridQuery)
            for query in queries:
                request = match_service_pb2.MatchRequest(
                    deployed_index_id=deployed_index_id,
                    float_val=query.dense_embedding if query_is_hybrid else query,
                    num_neighbors=num_neighbors,
                    restricts=restricts,
                    per_crowding_attribute_num_neighbors=per_crowding_attribute_num_neighbors,
                    approx_num_neighbors=approx_num_neighbors,
                    fraction_leaf_nodes_to_search_override=fraction_leaf_nodes_to_search_override,
                    numeric_restricts=numeric_restricts,
                    sparse_embedding=match_service_pb2.SparseEmbedding(
                        float_val=query.sparse_embedding_values,
                        dimension=query.sparse_embedding_dimensions,
                    )
                    if query_is_hybrid
                    else None,
                    rrf=match_service_pb2.MatchRequest.RRF(
                        alpha=query.rrf_ranking_alpha,
                    )
                    if query_is_hybrid and query.rrf_ranking_alpha
                    else None,
                )
                requests.append(request)
        else:
            raise ValueError(
                "To find neighbors using matching engine,"
                "please specify `queries` or `embedding_ids`"
            )

        batch_request_for_index.requests.extend(requests)
        batch_request.requests.append(batch_request_for_index)

        
        metadata = None
        if signed_jwt:
            metadata = (("authorization", f"Bearer: {signed_jwt}"),)
        response = stub.BatchMatch(batch_request, metadata=metadata)

        
        match_neighbors_response = []
        for resp in response.responses[0].responses:
            match_neighbors_id_map = {}
            for neighbor in resp.neighbor:
                match_neighbors_id_map[neighbor.id] = MatchNeighbor(
                    id=neighbor.id,
                    distance=neighbor.distance,
                    sparse_distance=neighbor.sparse_distance
                    if neighbor.sparse_distance
                    else None,
                )
            for embedding in resp.embeddings:
                if embedding.id in match_neighbors_id_map:
                    match_neighbors_id_map[embedding.id] = match_neighbors_id_map[
                        embedding.id
                    ].from_embedding(embedding=embedding)
            match_neighbors_response.append(list(match_neighbors_id_map.values()))
        return match_neighbors_response
