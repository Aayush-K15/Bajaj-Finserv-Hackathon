















from __future__ import absolute_import

import base64
import hashlib
import logging
import random
import warnings

from urllib.parse import parse_qs
from urllib.parse import urlencode
from urllib.parse import urlsplit
from urllib.parse import urlunsplit

from google.resumable_media import common


RANGE_HEADER = "range"
CONTENT_RANGE_HEADER = "content-range"
CONTENT_ENCODING_HEADER = "content-encoding"

_SLOW_CRC32C_WARNING = (
    "Currently using crcmod in pure python form. This is a slow "
    "implementation. Python 3 has a faster implementation, `google-crc32c`, "
    "which will be used if it is installed."
)
_GENERATION_HEADER = "x-goog-generation"
_HASH_HEADER = "x-goog-hash"
_STORED_CONTENT_ENCODING_HEADER = "x-goog-stored-content-encoding"

_MISSING_CHECKSUM = 
_LOGGER = logging.getLogger(__name__)


def do_nothing():
    


def header_required(response, name, get_headers, callback=do_nothing):
    
    headers = get_headers(response)
    if name not in headers:
        callback()
        raise common.InvalidResponse(
            response, "Response headers must contain header", name
        )

    return headers[name]


def require_status_code(response, status_codes, get_status_code, callback=do_nothing):
    
    status_code = get_status_code(response)
    if status_code not in status_codes:
        if status_code not in common.RETRYABLE:
            callback()
        raise common.InvalidResponse(
            response,
            "Request failed with status code",
            status_code,
            "Expected one of",
            *status_codes
        )
    return status_code


def calculate_retry_wait(base_wait, max_sleep, multiplier=2.0):
    
    new_base_wait = multiplier * base_wait
    if new_base_wait > max_sleep:
        new_base_wait = max_sleep

    jitter_ms = random.randint(0, 1000)
    return new_base_wait, new_base_wait + 0.001 * jitter_ms


def _get_crc32c_object():
    
    try:
        import google_crc32c  

        crc_obj = google_crc32c.Checksum()
    except ImportError:
        try:
            import crcmod  

            crc_obj = crcmod.predefined.Crc("crc-32c")
            _is_fast_crcmod()

        except ImportError:
            raise ImportError("Failed to import either `google-crc32c` or `crcmod`")

    return crc_obj


def _is_fast_crcmod():
    
    nested_crcmod = __import__(
        "crcmod.crcmod",
        globals(),
        locals(),
        ["_usingExtension"],
        0,
    )
    fast_crc = getattr(nested_crcmod, "_usingExtension", False)
    if not fast_crc:
        warnings.warn(_SLOW_CRC32C_WARNING, RuntimeWarning, stacklevel=2)
    return fast_crc


def _get_metadata_key(checksum_type):
    if checksum_type == "md5":
        return "md5Hash"
    else:
        return checksum_type


def prepare_checksum_digest(digest_bytestring):
    
    encoded_digest = base64.b64encode(digest_bytestring)
    
    return encoded_digest.decode("utf-8")


def _get_expected_checksum(response, get_headers, media_url, checksum_type):
    
    if checksum_type not in ["md5", "crc32c", None]:
        raise ValueError("checksum must be ``'md5'``, ``'crc32c'`` or ``None``")
    elif checksum_type in ["md5", "crc32c"]:
        headers = get_headers(response)
        expected_checksum = _parse_checksum_header(
            headers.get(_HASH_HEADER), response, checksum_label=checksum_type
        )

        if expected_checksum is None:
            msg = _MISSING_CHECKSUM.format(
                media_url, checksum_type=checksum_type.upper()
            )
            _LOGGER.info(msg)
            checksum_object = _DoNothingHash()
        else:
            if checksum_type == "md5":
                checksum_object = hashlib.md5()
            else:
                checksum_object = _get_crc32c_object()
    else:
        expected_checksum = None
        checksum_object = _DoNothingHash()

    return (expected_checksum, checksum_object)


def _get_uploaded_checksum_from_headers(response, get_headers, checksum_type):
    
    if checksum_type not in ["md5", "crc32c", None]:
        raise ValueError("checksum must be ``'md5'``, ``'crc32c'`` or ``None``")
    elif checksum_type in ["md5", "crc32c"]:
        headers = get_headers(response)
        remote_checksum = _parse_checksum_header(
            headers.get(_HASH_HEADER), response, checksum_label=checksum_type
        )
    else:
        remote_checksum = None

    return remote_checksum


def _parse_checksum_header(header_value, response, checksum_label):
    
    if header_value is None:
        return None

    matches = []
    for checksum in header_value.split(","):
        name, value = checksum.split("=", 1)
        
        if name.lstrip() == checksum_label:
            matches.append(value)

    if len(matches) == 0:
        return None
    elif len(matches) == 1:
        return matches[0]
    else:
        raise common.InvalidResponse(
            response,
            "X-Goog-Hash header had multiple ``{}`` values.".format(checksum_label),
            header_value,
            matches,
        )


def _get_checksum_object(checksum_type):
    
    if checksum_type == "md5":
        return hashlib.md5()
    elif checksum_type == "crc32c":
        return _get_crc32c_object()
    elif checksum_type is None:
        return None
    else:
        raise ValueError("checksum must be ``'md5'``, ``'crc32c'`` or ``None``")


def _parse_generation_header(response, get_headers):
    
    headers = get_headers(response)
    object_generation = headers.get(_GENERATION_HEADER, None)

    if object_generation is None:
        return None
    else:
        return int(object_generation)


def _get_generation_from_url(media_url):
    

    _, _, _, query, _ = urlsplit(media_url)
    query_params = parse_qs(query)
    object_generation = query_params.get("generation", None)

    if object_generation is None:
        return None
    else:
        return int(object_generation[0])


def add_query_parameters(media_url, query_params):
    

    if len(query_params) == 0:
        return media_url

    scheme, netloc, path, query, frag = urlsplit(media_url)
    params = parse_qs(query)
    new_params = {**params, **query_params}
    query = urlencode(new_params, doseq=True)
    return urlunsplit((scheme, netloc, path, query, frag))


def _is_decompressive_transcoding(response, get_headers):
    
    headers = get_headers(response)
    return (
        headers.get(_STORED_CONTENT_ENCODING_HEADER) == "gzip"
        and headers.get(CONTENT_ENCODING_HEADER) != "gzip"
    )


class _DoNothingHash(object):
    

    def update(self, unused_chunk):
        
