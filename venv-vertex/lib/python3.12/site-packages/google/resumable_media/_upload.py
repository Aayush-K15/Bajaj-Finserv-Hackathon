















import http.client
import json
import os
import random
import re
import sys
import urllib.parse

from google import resumable_media
from google.resumable_media import _helpers
from google.resumable_media import common

from xml.etree import ElementTree


_CONTENT_TYPE_HEADER = "content-type"
_CONTENT_RANGE_TEMPLATE = "bytes {:d}-{:d}/{:d}"
_RANGE_UNKNOWN_TEMPLATE = "bytes {:d}-{:d}/*"
_EMPTY_RANGE_TEMPLATE = "bytes */{:d}"
_BOUNDARY_WIDTH = len(str(sys.maxsize - 1))
_BOUNDARY_FORMAT = "==============={{:0{:d}d}}==".format(_BOUNDARY_WIDTH)
_MULTIPART_SEP = b"--"
_CRLF = b"\r\n"
_MULTIPART_BEGIN = b"\r\ncontent-type: application/json; charset=UTF-8\r\n\r\n"
_RELATED_HEADER = b'multipart/related; boundary="'
_BYTES_RANGE_RE = re.compile(r"bytes=0-(?P<end_byte>\d+)", flags=re.IGNORECASE)
_STREAM_ERROR_TEMPLATE = (
    "Bytes stream is in unexpected state. "
    "The local stream has had {:d} bytes read from it while "
    "{:d} bytes have already been updated (they should match)."
)
_STREAM_READ_PAST_TEMPLATE = (
    "{:d} bytes have been read from the stream, which exceeds "
    "the expected total {:d}."
)
_DELETE = "DELETE"
_POST = "POST"
_PUT = "PUT"
_UPLOAD_CHECKSUM_MISMATCH_MESSAGE = (
    "The computed ``{}`` checksum, ``{}``, and the checksum reported by the "
    "remote host, ``{}``, did not match."
)
_UPLOAD_METADATA_NO_APPROPRIATE_CHECKSUM_MESSAGE = (
    "Response metadata had no ``{}`` value; checksum could not be validated."
)
_UPLOAD_HEADER_NO_APPROPRIATE_CHECKSUM_MESSAGE = (
    "Response headers had no ``{}`` value; checksum could not be validated."
)
_MPU_INITIATE_QUERY = "?uploads"
_MPU_PART_QUERY_TEMPLATE = "?partNumber={part}&uploadId={upload_id}"
_S3_COMPAT_XML_NAMESPACE = "{http://s3.amazonaws.com/doc/2006-03-01/}"
_UPLOAD_ID_NODE = "UploadId"
_MPU_FINAL_QUERY_TEMPLATE = "?uploadId={upload_id}"


class UploadBase(object):
    

    def __init__(self, upload_url, headers=None):
        self.upload_url = upload_url
        if headers is None:
            headers = {}
        self._headers = headers
        self._finished = False
        self._retry_strategy = common.RetryStrategy()

    @property
    def finished(self):
        
        return self._finished

    def _process_response(self, response):
        
        
        
        self._finished = True
        _helpers.require_status_code(response, (http.client.OK,), self._get_status_code)

    @staticmethod
    def _get_status_code(response):
        
        raise NotImplementedError("This implementation is virtual.")

    @staticmethod
    def _get_headers(response):
        
        raise NotImplementedError("This implementation is virtual.")

    @staticmethod
    def _get_body(response):
        
        raise NotImplementedError("This implementation is virtual.")


class SimpleUpload(UploadBase):
    

    def _prepare_request(self, data, content_type):
        
        if self.finished:
            raise ValueError("An upload can only be used once.")

        if not isinstance(data, bytes):
            raise TypeError("`data` must be bytes, received", type(data))
        self._headers[_CONTENT_TYPE_HEADER] = content_type
        return _POST, self.upload_url, data, self._headers

    def transmit(self, transport, data, content_type, timeout=None):
        
        raise NotImplementedError("This implementation is virtual.")


class MultipartUpload(UploadBase):
    

    def __init__(self, upload_url, headers=None, checksum=None):
        super(MultipartUpload, self).__init__(upload_url, headers=headers)
        self._checksum_type = checksum

    def _prepare_request(self, data, metadata, content_type):
        
        if self.finished:
            raise ValueError("An upload can only be used once.")

        if not isinstance(data, bytes):
            raise TypeError("`data` must be bytes, received", type(data))

        checksum_object = _helpers._get_checksum_object(self._checksum_type)
        if checksum_object is not None:
            checksum_object.update(data)
            actual_checksum = _helpers.prepare_checksum_digest(checksum_object.digest())
            metadata_key = _helpers._get_metadata_key(self._checksum_type)
            metadata[metadata_key] = actual_checksum

        content, multipart_boundary = construct_multipart_request(
            data, metadata, content_type
        )
        multipart_content_type = _RELATED_HEADER + multipart_boundary + b'"'
        self._headers[_CONTENT_TYPE_HEADER] = multipart_content_type

        return _POST, self.upload_url, content, self._headers

    def transmit(self, transport, data, metadata, content_type, timeout=None):
        
        raise NotImplementedError("This implementation is virtual.")


class ResumableUpload(UploadBase):
    

    def __init__(self, upload_url, chunk_size, checksum=None, headers=None):
        super(ResumableUpload, self).__init__(upload_url, headers=headers)
        if chunk_size % resumable_media.UPLOAD_CHUNK_SIZE != 0:
            raise ValueError(
                "{} KB must divide chunk size".format(
                    resumable_media.UPLOAD_CHUNK_SIZE / 1024
                )
            )
        self._chunk_size = chunk_size
        self._stream = None
        self._content_type = None
        self._bytes_uploaded = 0
        self._bytes_checksummed = 0
        self._checksum_type = checksum
        self._checksum_object = None
        self._total_bytes = None
        self._resumable_url = None
        self._invalid = False

    @property
    def invalid(self):
        
        return self._invalid

    @property
    def chunk_size(self):
        
        return self._chunk_size

    @property
    def resumable_url(self):
        
        return self._resumable_url

    @property
    def bytes_uploaded(self):
        
        return self._bytes_uploaded

    @property
    def total_bytes(self):
        
        return self._total_bytes

    def _prepare_initiate_request(
        self, stream, metadata, content_type, total_bytes=None, stream_final=True
    ):
        
        if self.resumable_url is not None:
            raise ValueError("This upload has already been initiated.")
        if stream.tell() != 0:
            raise ValueError("Stream must be at beginning.")

        self._stream = stream
        self._content_type = content_type

        
        parse_result = urllib.parse.urlparse(self.upload_url)
        parsed_query = urllib.parse.parse_qs(parse_result.query)
        if "x-goog-signature" in parsed_query or "X-Goog-Signature" in parsed_query:
            
            headers = {**self._headers, _CONTENT_TYPE_HEADER: content_type}
        else:
            
            headers = {
                **self._headers,
                _CONTENT_TYPE_HEADER: "application/json; charset=UTF-8",
                "x-upload-content-type": content_type,
            }
        
        if total_bytes is not None:
            self._total_bytes = total_bytes
        elif stream_final:
            self._total_bytes = get_total_bytes(stream)
        
        if self._total_bytes is not None:
            content_length = "{:d}".format(self._total_bytes)
            headers["x-upload-content-length"] = content_length

        payload = json.dumps(metadata).encode("utf-8")
        return _POST, self.upload_url, payload, headers

    def _process_initiate_response(self, response):
        
        _helpers.require_status_code(
            response,
            (http.client.OK, http.client.CREATED),
            self._get_status_code,
            callback=self._make_invalid,
        )
        self._resumable_url = _helpers.header_required(
            response, "location", self._get_headers
        )

    def initiate(
        self,
        transport,
        stream,
        metadata,
        content_type,
        total_bytes=None,
        stream_final=True,
        timeout=None,
    ):
        
        raise NotImplementedError("This implementation is virtual.")

    def _prepare_request(self):
        
        if self.finished:
            raise ValueError("Upload has finished.")
        if self.invalid:
            raise ValueError(
                "Upload is in an invalid state. To recover call `recover()`."
            )
        if self.resumable_url is None:
            raise ValueError(
                "This upload has not been initiated. Please call "
                "initiate() before beginning to transmit chunks."
            )

        start_byte, payload, content_range = get_next_chunk(
            self._stream, self._chunk_size, self._total_bytes
        )
        if start_byte != self.bytes_uploaded:
            msg = _STREAM_ERROR_TEMPLATE.format(start_byte, self.bytes_uploaded)
            raise ValueError(msg)

        self._update_checksum(start_byte, payload)

        headers = {
            **self._headers,
            _CONTENT_TYPE_HEADER: self._content_type,
            _helpers.CONTENT_RANGE_HEADER: content_range,
        }
        return _PUT, self.resumable_url, payload, headers

    def _update_checksum(self, start_byte, payload):
        
        if not self._checksum_type:
            return

        if not self._checksum_object:
            self._checksum_object = _helpers._get_checksum_object(self._checksum_type)

        if start_byte < self._bytes_checksummed:
            offset = self._bytes_checksummed - start_byte
            data = payload[offset:]
        else:
            data = payload

        self._checksum_object.update(data)
        self._bytes_checksummed += len(data)

    def _make_invalid(self):
        
        self._invalid = True

    def _process_resumable_response(self, response, bytes_sent):
        
        status_code = _helpers.require_status_code(
            response,
            (http.client.OK, http.client.PERMANENT_REDIRECT),
            self._get_status_code,
            callback=self._make_invalid,
        )
        if status_code == http.client.OK:
            
            
            
            
            
            
            
            
            self._bytes_uploaded = self._bytes_uploaded + bytes_sent
            
            self._finished = True
            
            self._validate_checksum(response)
        else:
            bytes_range = _helpers.header_required(
                response,
                _helpers.RANGE_HEADER,
                self._get_headers,
                callback=self._make_invalid,
            )
            match = _BYTES_RANGE_RE.match(bytes_range)
            if match is None:
                self._make_invalid()
                raise common.InvalidResponse(
                    response,
                    'Unexpected "range" header',
                    bytes_range,
                    'Expected to be of the form "bytes=0-{end}"',
                )
            self._bytes_uploaded = int(match.group("end_byte")) + 1

    def _validate_checksum(self, response):
        
        if self._checksum_type is None:
            return
        metadata_key = _helpers._get_metadata_key(self._checksum_type)
        metadata = response.json()
        remote_checksum = metadata.get(metadata_key)
        if remote_checksum is None:
            raise common.InvalidResponse(
                response,
                _UPLOAD_METADATA_NO_APPROPRIATE_CHECKSUM_MESSAGE.format(metadata_key),
                self._get_headers(response),
            )
        local_checksum = _helpers.prepare_checksum_digest(
            self._checksum_object.digest()
        )
        if local_checksum != remote_checksum:
            raise common.DataCorruption(
                response,
                _UPLOAD_CHECKSUM_MISMATCH_MESSAGE.format(
                    self._checksum_type.upper(), local_checksum, remote_checksum
                ),
            )

    def transmit_next_chunk(self, transport, timeout=None):
        
        raise NotImplementedError("This implementation is virtual.")

    def _prepare_recover_request(self):
        
        headers = {_helpers.CONTENT_RANGE_HEADER: "bytes */*"}
        return _PUT, self.resumable_url, None, headers

    def _process_recover_response(self, response):
        
        _helpers.require_status_code(
            response, (http.client.PERMANENT_REDIRECT,), self._get_status_code
        )
        headers = self._get_headers(response)
        if _helpers.RANGE_HEADER in headers:
            bytes_range = headers[_helpers.RANGE_HEADER]
            match = _BYTES_RANGE_RE.match(bytes_range)
            if match is None:
                raise common.InvalidResponse(
                    response,
                    'Unexpected "range" header',
                    bytes_range,
                    'Expected to be of the form "bytes=0-{end}"',
                )
            self._bytes_uploaded = int(match.group("end_byte")) + 1
        else:
            
            self._bytes_uploaded = 0

        self._stream.seek(self._bytes_uploaded)
        self._invalid = False

    def recover(self, transport):
        
        raise NotImplementedError("This implementation is virtual.")


class XMLMPUContainer(UploadBase):
    

    def __init__(self, upload_url, filename, headers=None, upload_id=None):
        super().__init__(upload_url, headers=headers)
        self._filename = filename
        self._upload_id = upload_id
        self._parts = {}

    @property
    def upload_id(self):
        return self._upload_id

    def register_part(self, part_number, etag):
        
        self._parts[part_number] = etag

    def _prepare_initiate_request(self, content_type):
        
        if self.upload_id is not None:
            raise ValueError("This upload has already been initiated.")

        initiate_url = self.upload_url + _MPU_INITIATE_QUERY

        headers = {
            **self._headers,
            _CONTENT_TYPE_HEADER: content_type,
        }
        return _POST, initiate_url, None, headers

    def _process_initiate_response(self, response):
        
        _helpers.require_status_code(response, (http.client.OK,), self._get_status_code)
        root = ElementTree.fromstring(response.text)
        self._upload_id = root.find(_S3_COMPAT_XML_NAMESPACE + _UPLOAD_ID_NODE).text

    def initiate(
        self,
        transport,
        content_type,
        timeout=None,
    ):
        
        raise NotImplementedError("This implementation is virtual.")

    def _prepare_finalize_request(self):
        
        if self.upload_id is None:
            raise ValueError("This upload has not yet been initiated.")

        final_query = _MPU_FINAL_QUERY_TEMPLATE.format(upload_id=self._upload_id)
        finalize_url = self.upload_url + final_query
        final_xml_root = ElementTree.Element("CompleteMultipartUpload")
        for part_number, etag in self._parts.items():
            part = ElementTree.SubElement(final_xml_root, "Part")  
            ElementTree.SubElement(part, "PartNumber").text = str(part_number)
            ElementTree.SubElement(part, "ETag").text = etag
        payload = ElementTree.tostring(final_xml_root)
        return _POST, finalize_url, payload, self._headers

    def _process_finalize_response(self, response):
        

        _helpers.require_status_code(response, (http.client.OK,), self._get_status_code)
        self._finished = True

    def finalize(
        self,
        transport,
        timeout=None,
    ):
        
        raise NotImplementedError("This implementation is virtual.")

    def _prepare_cancel_request(self):
        
        if self.upload_id is None:
            raise ValueError("This upload has not yet been initiated.")

        cancel_query = _MPU_FINAL_QUERY_TEMPLATE.format(upload_id=self._upload_id)
        cancel_url = self.upload_url + cancel_query
        return _DELETE, cancel_url, None, self._headers

    def _process_cancel_response(self, response):
        

        _helpers.require_status_code(
            response, (http.client.NO_CONTENT,), self._get_status_code
        )

    def cancel(
        self,
        transport,
        timeout=None,
    ):
        
        raise NotImplementedError("This implementation is virtual.")


class XMLMPUPart(UploadBase):
    

    def __init__(
        self,
        upload_url,
        upload_id,
        filename,
        start,
        end,
        part_number,
        headers=None,
        checksum=None,
    ):
        super().__init__(upload_url, headers=headers)
        self._filename = filename
        self._start = start
        self._end = end
        self._upload_id = upload_id
        self._part_number = part_number
        self._etag = None
        self._checksum_type = checksum
        self._checksum_object = None

    @property
    def part_number(self):
        return self._part_number

    @property
    def upload_id(self):
        return self._upload_id

    @property
    def filename(self):
        return self._filename

    @property
    def etag(self):
        return self._etag

    @property
    def start(self):
        return self._start

    @property
    def end(self):
        return self._end

    def _prepare_upload_request(self):
        
        if self.finished:
            raise ValueError("This part has already been uploaded.")

        with open(self._filename, "br") as f:
            f.seek(self._start)
            payload = f.read(self._end - self._start)

        self._checksum_object = _helpers._get_checksum_object(self._checksum_type)
        if self._checksum_object is not None:
            self._checksum_object.update(payload)

        part_query = _MPU_PART_QUERY_TEMPLATE.format(
            part=self._part_number, upload_id=self._upload_id
        )
        upload_url = self.upload_url + part_query
        return _PUT, upload_url, payload, self._headers

    def _process_upload_response(self, response):
        
        _helpers.require_status_code(
            response,
            (http.client.OK,),
            self._get_status_code,
        )

        self._validate_checksum(response)

        etag = _helpers.header_required(response, "etag", self._get_headers)
        self._etag = etag
        self._finished = True

    def upload(
        self,
        transport,
        timeout=None,
    ):
        
        raise NotImplementedError("This implementation is virtual.")

    def _validate_checksum(self, response):
        
        if self._checksum_type is None:
            return

        remote_checksum = _helpers._get_uploaded_checksum_from_headers(
            response, self._get_headers, self._checksum_type
        )

        if remote_checksum is None:
            metadata_key = _helpers._get_metadata_key(self._checksum_type)
            raise common.InvalidResponse(
                response,
                _UPLOAD_METADATA_NO_APPROPRIATE_CHECKSUM_MESSAGE.format(metadata_key),
                self._get_headers(response),
            )
        local_checksum = _helpers.prepare_checksum_digest(
            self._checksum_object.digest()
        )
        if local_checksum != remote_checksum:
            raise common.DataCorruption(
                response,
                _UPLOAD_CHECKSUM_MISMATCH_MESSAGE.format(
                    self._checksum_type.upper(), local_checksum, remote_checksum
                ),
            )


def get_boundary():
    
    random_int = random.randrange(sys.maxsize)
    boundary = _BOUNDARY_FORMAT.format(random_int)
    
    
    return boundary.encode("utf-8")


def construct_multipart_request(data, metadata, content_type):
    
    multipart_boundary = get_boundary()
    json_bytes = json.dumps(metadata).encode("utf-8")
    content_type = content_type.encode("utf-8")
    
    
    boundary_sep = _MULTIPART_SEP + multipart_boundary
    content = (
        boundary_sep
        + _MULTIPART_BEGIN
        + json_bytes
        + _CRLF
        + boundary_sep
        + _CRLF
        + b"content-type: "
        + content_type
        + _CRLF
        + _CRLF
        + data  
        + _CRLF
        + boundary_sep
        + _MULTIPART_SEP
    )

    return content, multipart_boundary


def get_total_bytes(stream):
    
    current_position = stream.tell()
    
    
    stream.seek(0, os.SEEK_END)
    end_position = stream.tell()
    
    stream.seek(current_position)

    return end_position


def get_next_chunk(stream, chunk_size, total_bytes):
    
    start_byte = stream.tell()
    if total_bytes is not None and start_byte + chunk_size >= total_bytes > 0:
        payload = stream.read(total_bytes - start_byte)
    else:
        payload = stream.read(chunk_size)
    end_byte = stream.tell() - 1

    num_bytes_read = len(payload)
    if total_bytes is None:
        if num_bytes_read < chunk_size:
            
            total_bytes = end_byte + 1
    elif total_bytes == 0:
        
        
        
        if num_bytes_read != 0:
            raise ValueError(
                "Stream specified as empty, but produced non-empty content."
            )
    else:
        if num_bytes_read == 0:
            raise ValueError(
                "Stream is already exhausted. There is no content remaining."
            )

    content_range = get_content_range(start_byte, end_byte, total_bytes)
    return start_byte, payload, content_range


def get_content_range(start_byte, end_byte, total_bytes):
    
    if total_bytes is None:
        return _RANGE_UNKNOWN_TEMPLATE.format(start_byte, end_byte)
    elif end_byte < start_byte:
        return _EMPTY_RANGE_TEMPLATE.format(total_bytes)
    else:
        return _CONTENT_RANGE_TEMPLATE.format(start_byte, end_byte, total_bytes)
