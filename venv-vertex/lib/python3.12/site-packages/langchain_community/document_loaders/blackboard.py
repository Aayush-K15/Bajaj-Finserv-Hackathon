import contextlib
import re
from pathlib import Path
from typing import Any, List, Optional, Tuple
from urllib.parse import unquote

from langchain_core.documents import Document

from langchain_community.document_loaders.directory import DirectoryLoader
from langchain_community.document_loaders.pdf import PyPDFLoader
from langchain_community.document_loaders.web_base import WebBaseLoader


class BlackboardLoader(WebBaseLoader):
    

    def __init__(
        self,
        blackboard_course_url: str,
        bbrouter: str,
        load_all_recursively: bool = True,
        basic_auth: Optional[Tuple[str, str]] = None,
        cookies: Optional[dict] = None,
        continue_on_failure: bool = False,
        show_progress: bool = True,
    ):
        
        super().__init__(
            web_paths=(blackboard_course_url),
            continue_on_failure=continue_on_failure,
            show_progress=show_progress,
        )
        
        try:
            self.base_url = blackboard_course_url.split("/webapps/blackboard")[0]
        except IndexError:
            raise IndexError(
                "Invalid blackboard course url. "
                "Please provide a url that starts with "
                "https://<blackboard_url>/webapps/blackboard"
            )
        if basic_auth is not None:
            self.session.auth = basic_auth
        
        if cookies is None:
            cookies = {}
        cookies.update({"BbRouter": bbrouter})
        self.session.cookies.update(cookies)
        self.load_all_recursively = load_all_recursively
        self.check_bs4()

    def check_bs4(self) -> None:
        
        try:
            import bs4  
        except ImportError:
            raise ImportError(
                "BeautifulSoup4 is required for BlackboardLoader. "
                "Please install it with `pip install beautifulsoup4`."
            )

    def load(self) -> List[Document]:
        
        if self.load_all_recursively:
            soup_info = self.scrape()
            self.folder_path = self._get_folder_path(soup_info)
            relative_paths = self._get_paths(soup_info)
            documents = []
            for path in relative_paths:
                url = self.base_url + path
                print(f"Fetching documents from {url}")  
                soup_info = self._scrape(url)
                with contextlib.suppress(ValueError):
                    documents.extend(self._get_documents(soup_info))
            return documents
        else:
            print(f"Fetching documents from {self.web_path}")  
            soup_info = self.scrape()
            self.folder_path = self._get_folder_path(soup_info)
            return self._get_documents(soup_info)

    def _get_folder_path(self, soup: Any) -> str:
        
        
        course_name = soup.find("span", {"id": "crumb_1"})
        if course_name is None:
            raise ValueError("No course name found.")
        course_name = course_name.text.strip()
        
        course_name_clean = (
            unquote(course_name)
            .replace(" ", "_")
            .replace("/", "_")
            .replace(":", "_")
            .replace(",", "_")
            .replace("?", "_")
            .replace("'", "_")
            .replace("!", "_")
            .replace('"', "_")
        )
        
        folder_path = Path(".") / course_name_clean
        return str(folder_path)

    def _get_documents(self, soup: Any) -> List[Document]:
        
        attachments = self._get_attachments(soup)
        self._download_attachments(attachments)
        documents = self._load_documents()
        return documents

    def _get_attachments(self, soup: Any) -> List[str]:
        
        from bs4 import BeautifulSoup, Tag

        
        content_list: BeautifulSoup
        content_list = soup.find("ul", {"class": "contentList"})
        if content_list is None:
            raise ValueError("No content list found.")
        
        attachments = []
        attachment: Tag
        for attachment in content_list.find_all("ul", {"class": "attachments"}):
            link: Tag
            for link in attachment.find_all("a"):
                href = link.get("href")
                
                if href is not None and not href.startswith("
                    attachments.append(href)
        return attachments

    def _download_attachments(self, attachments: List[str]) -> None:
        
        
        Path(self.folder_path).mkdir(parents=True, exist_ok=True)
        
        for attachment in attachments:
            self.download(attachment)

    def _load_documents(self) -> List[Document]:
        
        
        loader = DirectoryLoader(
            path=self.folder_path,
            glob="*.pdf",
            loader_cls=PyPDFLoader,  
        )
        
        documents = loader.load()
        
        return documents

    def _get_paths(self, soup: Any) -> List[str]:
        
        relative_paths = []
        course_menu = soup.find("ul", {"class": "courseMenu"})
        if course_menu is None:
            raise ValueError("No course menu found.")
        for link in course_menu.find_all("a"):
            href = link.get("href")
            if href is not None and href.startswith("/"):
                relative_paths.append(href)
        return relative_paths

    def download(self, path: str) -> None:
        
        
        response = self.session.get(self.base_url + path, allow_redirects=True)
        
        filename = self.parse_filename(response.url)
        
        with open(Path(self.folder_path) / filename, "wb") as f:
            f.write(response.content)

    def parse_filename(self, url: str) -> str:
        
        if (url_path := Path(url)) and url_path.suffix == ".pdf":
            return url_path.name
        else:
            return self._parse_filename_from_url(url)

    def _parse_filename_from_url(self, url: str) -> str:
        
        filename_matches = re.search(r"filename%2A%3DUTF-8%27%27(.+)", url)
        if filename_matches:
            filename = filename_matches.group(1)
        else:
            raise ValueError(f"Could not parse filename from {url}")
        if ".pdf" not in filename:
            raise ValueError(f"Incorrect file type: {filename}")
        filename = filename.split(".pdf")[0] + ".pdf"
        filename = unquote(filename)
        filename = filename.replace("%20", " ")
        return filename


if __name__ == "__main__":
    loader = BlackboardLoader(
        "https://<YOUR BLACKBOARD URL"
        " HERE>/webapps/blackboard/content/listContent.jsp?course_id=_<YOUR COURSE ID"
        " HERE>_1&content_id=_<YOUR CONTENT ID HERE>_1&mode=reset",
        "<YOUR BBROUTER COOKIE HERE>",
        load_all_recursively=True,
    )
    documents = loader.load()
    print(f"Loaded {len(documents)} pages of PDFs from {loader.web_path}")  
