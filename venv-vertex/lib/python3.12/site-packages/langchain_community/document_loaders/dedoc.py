import html
import json
import os
from abc import ABC, abstractmethod
from typing import (
    Dict,
    Iterator,
    Optional,
    Tuple,
    Union,
)

from langchain_core.documents import Document

from langchain_community.document_loaders.base import BaseLoader


class DedocBaseLoader(BaseLoader, ABC):
    

    def __init__(
        self,
        file_path: str,
        *,
        split: str = "document",
        with_tables: bool = True,
        with_attachments: Union[str, bool] = False,
        recursion_deep_attachments: int = 10,
        pdf_with_text_layer: str = "auto_tabby",
        language: str = "rus+eng",
        pages: str = ":",
        is_one_column_document: str = "auto",
        document_orientation: str = "auto",
        need_header_footer_analysis: Union[str, bool] = False,
        need_binarization: Union[str, bool] = False,
        need_pdf_table_analysis: Union[str, bool] = True,
        delimiter: Optional[str] = None,
        encoding: Optional[str] = None,
    ) -> None:
        
        self.parsing_parameters = {
            key: value
            for key, value in locals().items()
            if key not in {"self", "file_path", "split", "with_tables"}
        }
        self.valid_split_values = {"document", "page", "node", "line"}
        if split not in self.valid_split_values:
            raise ValueError(
                f"Got {split} for `split`, but should be one of "
                f"`{self.valid_split_values}`"
            )
        self.split = split
        self.with_tables = with_tables
        self.file_path = file_path

        structure_type = "tree" if self.split == "node" else "linear"
        self.parsing_parameters["structure_type"] = structure_type
        self.parsing_parameters["need_content_analysis"] = with_attachments

    def lazy_load(self) -> Iterator[Document]:
        
        import tempfile

        try:
            from dedoc import DedocManager
        except ImportError:
            raise ImportError(
                "`dedoc` package not found, please install it with `pip install dedoc`"
            )
        dedoc_manager = DedocManager(manager_config=self._make_config())
        dedoc_manager.config["logger"].disabled = True

        with tempfile.TemporaryDirectory() as tmpdir:
            document_tree = dedoc_manager.parse(
                file_path=self.file_path,
                parameters={**self.parsing_parameters, "attachments_dir": tmpdir},
            )
        yield from self._split_document(
            document_tree=document_tree.to_api_schema().dict(), split=self.split
        )

    @abstractmethod
    def _make_config(self) -> dict:
        
        pass

    def _json2txt(self, paragraph: dict) -> str:
        
        subparagraphs_text = "\n".join(
            [
                self._json2txt(subparagraph)
                for subparagraph in paragraph["subparagraphs"]
            ]
        )
        text = (
            f"{paragraph['text']}\n{subparagraphs_text}"
            if subparagraphs_text
            else paragraph["text"]
        )
        return text

    def _parse_subparagraphs(
        self, document_tree: dict, document_metadata: dict
    ) -> Iterator[Document]:
        
        if len(document_tree["subparagraphs"]) > 0:
            for subparagraph in document_tree["subparagraphs"]:
                yield from self._parse_subparagraphs(
                    document_tree=subparagraph, document_metadata=document_metadata
                )
        else:
            yield Document(
                page_content=document_tree["text"],
                metadata={**document_metadata, **document_tree["metadata"]},
            )

    def _split_document(
        self,
        document_tree: dict,
        split: str,
        additional_metadata: Optional[dict] = None,
    ) -> Iterator[Document]:
        
        document_metadata = document_tree["metadata"]
        if additional_metadata:
            document_metadata = {**document_metadata, **additional_metadata}

        if split == "document":
            text = self._json2txt(paragraph=document_tree["content"]["structure"])
            yield Document(page_content=text, metadata=document_metadata)

        elif split == "page":
            nodes = document_tree["content"]["structure"]["subparagraphs"]
            page_id = nodes[0]["metadata"]["page_id"]
            page_text = ""

            for node in nodes:
                if node["metadata"]["page_id"] == page_id:
                    page_text += self._json2txt(node)
                else:
                    yield Document(
                        page_content=page_text,
                        metadata={**document_metadata, "page_id": page_id},
                    )
                    page_id = node["metadata"]["page_id"]
                    page_text = self._json2txt(node)

            yield Document(
                page_content=page_text,
                metadata={**document_metadata, "page_id": page_id},
            )

        elif split == "line":
            for node in document_tree["content"]["structure"]["subparagraphs"]:
                line_metadata = node["metadata"]
                yield Document(
                    page_content=self._json2txt(node),
                    metadata={**document_metadata, **line_metadata},
                )

        elif split == "node":
            yield from self._parse_subparagraphs(
                document_tree=document_tree["content"]["structure"],
                document_metadata=document_metadata,
            )

        else:
            raise ValueError(
                f"Got {split} for `split`, but should be one of "
                f"`{self.valid_split_values}`"
            )

        if self.with_tables:
            for table in document_tree["content"]["tables"]:
                table_text, table_html = self._get_table(table)
                yield Document(
                    page_content=table_text,
                    metadata={
                        **table["metadata"],
                        "type": "table",
                        "text_as_html": table_html,
                    },
                )

        for attachment in document_tree["attachments"]:
            yield from self._split_document(
                document_tree=attachment,
                split=self.split,
                additional_metadata={"type": "attachment"},
            )

    def _get_table(self, table: dict) -> Tuple[str, str]:
        
        table_text = ""
        for row in table["cells"]:
            for cell in row:
                table_text += " ".join(line["text"] for line in cell["lines"])
                table_text += "\t"
            table_text += "\n"

        table_html = (
            '<table border="1" style="border-collapse: collapse; width: 100%;'
            '">\n<tbody>\n'
        )
        for row in table["cells"]:
            table_html += "<tr>\n"
            for cell in row:
                cell_text = "\n".join(line["text"] for line in cell["lines"])
                cell_text = html.escape(cell_text)
                table_html += "<td"
                if cell["invisible"]:
                    table_html += ' style="display: none" '
                table_html += (
                    f' colspan="{cell["colspan"]}" rowspan='
                    f'"{cell["rowspan"]}">{cell_text}</td>\n'
                )
            table_html += "</tr>\n"
        table_html += "</tbody>\n</table>"

        return table_text, table_html


class DedocFileLoader(DedocBaseLoader):
    

    def _make_config(self) -> dict:
        from dedoc.utils.langchain import make_manager_config

        return make_manager_config(
            file_path=self.file_path,
            parsing_params=self.parsing_parameters,
            split=self.split,
        )


class DedocAPIFileLoader(DedocBaseLoader):
    

    def __init__(
        self,
        file_path: str,
        *,
        url: str = "http://0.0.0.0:1231",
        split: str = "document",
        with_tables: bool = True,
        with_attachments: Union[str, bool] = False,
        recursion_deep_attachments: int = 10,
        pdf_with_text_layer: str = "auto_tabby",
        language: str = "rus+eng",
        pages: str = ":",
        is_one_column_document: str = "auto",
        document_orientation: str = "auto",
        need_header_footer_analysis: Union[str, bool] = False,
        need_binarization: Union[str, bool] = False,
        need_pdf_table_analysis: Union[str, bool] = True,
        delimiter: Optional[str] = None,
        encoding: Optional[str] = None,
    ) -> None:
        
        super().__init__(
            file_path=file_path,
            split=split,
            with_tables=with_tables,
            with_attachments=with_attachments,
            recursion_deep_attachments=recursion_deep_attachments,
            pdf_with_text_layer=pdf_with_text_layer,
            language=language,
            pages=pages,
            is_one_column_document=is_one_column_document,
            document_orientation=document_orientation,
            need_header_footer_analysis=need_header_footer_analysis,
            need_binarization=need_binarization,
            need_pdf_table_analysis=need_pdf_table_analysis,
            delimiter=delimiter,
            encoding=encoding,
        )
        self.url = url
        self.parsing_parameters["return_format"] = "json"

    def lazy_load(self) -> Iterator[Document]:
        
        doc_tree = self._send_file(
            url=self.url, file_path=self.file_path, parameters=self.parsing_parameters
        )
        yield from self._split_document(document_tree=doc_tree, split=self.split)

    def _make_config(self) -> dict:
        return {}

    def _send_file(
        self, url: str, file_path: str, parameters: dict
    ) -> Dict[str, Union[list, dict, str]]:
        
        import requests

        file_name = os.path.basename(file_path)
        with open(file_path, "rb") as file:
            files = {"file": (file_name, file)}
            r = requests.post(f"{url}/upload", files=files, data=parameters)

        if r.status_code != 200:
            raise ValueError(f"Error during file handling: {r.content.decode()}")

        result = json.loads(r.content.decode())
        return result
