from typing import Any, Dict, List, Optional, cast

import requests
from langchain_core.callbacks import CallbackManagerForLLMRun
from langchain_core.language_models.llms import LLM
from langchain_core.utils import convert_to_secret_str, get_from_dict_or_env, pre_init
from pydantic import BaseModel, ConfigDict, SecretStr


class AI21PenaltyData(BaseModel):
    

    scale: int = 0
    applyToWhitespaces: bool = True
    applyToPunctuations: bool = True
    applyToNumbers: bool = True
    applyToStopwords: bool = True
    applyToEmojis: bool = True


class AI21(LLM):
    

    model: str = "j2-jumbo-instruct"
    

    temperature: float = 0.7
    

    maxTokens: int = 256
    

    minTokens: int = 0
    

    topP: float = 1.0
    

    presencePenalty: AI21PenaltyData = AI21PenaltyData()
    

    countPenalty: AI21PenaltyData = AI21PenaltyData()
    

    frequencyPenalty: AI21PenaltyData = AI21PenaltyData()
    

    numResults: int = 1
    

    logitBias: Optional[Dict[str, float]] = None
    

    ai21_api_key: Optional[SecretStr] = None

    stop: Optional[List[str]] = None

    base_url: Optional[str] = None
    

    model_config = ConfigDict(
        extra="forbid",
    )

    @pre_init
    def validate_environment(cls, values: Dict) -> Dict:
        
        ai21_api_key = convert_to_secret_str(
            get_from_dict_or_env(values, "ai21_api_key", "AI21_API_KEY")
        )
        values["ai21_api_key"] = ai21_api_key
        return values

    @property
    def _default_params(self) -> Dict[str, Any]:
        
        return {
            "temperature": self.temperature,
            "maxTokens": self.maxTokens,
            "minTokens": self.minTokens,
            "topP": self.topP,
            "presencePenalty": self.presencePenalty.dict(),
            "countPenalty": self.countPenalty.dict(),
            "frequencyPenalty": self.frequencyPenalty.dict(),
            "numResults": self.numResults,
            "logitBias": self.logitBias,
        }

    @property
    def _identifying_params(self) -> Dict[str, Any]:
        
        return {**{"model": self.model}, **self._default_params}

    @property
    def _llm_type(self) -> str:
        
        return "ai21"

    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        
        if self.stop is not None and stop is not None:
            raise ValueError("`stop` found in both the input and default params.")
        elif self.stop is not None:
            stop = self.stop
        elif stop is None:
            stop = []
        if self.base_url is not None:
            base_url = self.base_url
        else:
            if self.model in ("j1-grande-instruct",):
                base_url = "https://api.ai21.com/studio/v1/experimental"
            else:
                base_url = "https://api.ai21.com/studio/v1"
        params = {**self._default_params, **kwargs}
        self.ai21_api_key = cast(SecretStr, self.ai21_api_key)
        response = requests.post(
            url=f"{base_url}/{self.model}/complete",
            headers={"Authorization": f"Bearer {self.ai21_api_key.get_secret_value()}"},
            json={"prompt": prompt, "stopSequences": stop, **params},
        )
        if response.status_code != 200:
            optional_detail = response.json().get("error")
            raise ValueError(
                f"AI21 /complete call failed with status code {response.status_code}."
                f" Details: {optional_detail}"
            )
        response_json = response.json()
        return response_json["completions"][0]["data"]["text"]
