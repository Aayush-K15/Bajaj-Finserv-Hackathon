from __future__ import annotations

import enum
import os
import random
import string
from hashlib import md5
from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Type

import numpy as np
from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from langchain_core.vectorstores import VectorStore

from langchain_community.graphs import FalkorDBGraph
from langchain_community.vectorstores.utils import (
    DistanceStrategy,
    maximal_marginal_relevance,
)


def generate_random_string(length: int) -> str:
    
    
    characters = string.ascii_letters
    
    random_string = "".join(random.choice(characters) for _ in range(length))
    return random_string


DEFAULT_DISTANCE_STRATEGY = DistanceStrategy.COSINE
DISTANCE_MAPPING = {
    DistanceStrategy.EUCLIDEAN_DISTANCE: "euclidean",
    DistanceStrategy.COSINE: "cosine",
}


class SearchType(str, enum.Enum):
    

    VECTOR = "vector"
    HYBRID = "hybrid"


DEFAULT_SEARCH_TYPE = SearchType.VECTOR


class IndexType(str, enum.Enum):
    

    NODE = "NODE"
    RELATIONSHIP = "RELATIONSHIP"


DEFAULT_INDEX_TYPE = IndexType.NODE


def dict_to_yaml_str(input_dict: Dict, indent: int = 0) -> str:
    
    yaml_str = ""
    for key, value in input_dict.items():
        padding = "  " * indent
        if isinstance(value, dict):
            yaml_str += f"{padding}{key}:\n{dict_to_yaml_str(value, indent + 1)}"
        elif isinstance(value, list):
            yaml_str += f"{padding}{key}:\n"
            for item in value:
                yaml_str += f"{padding}- {item}\n"
        else:
            yaml_str += f"{padding}{key}: {value}\n"
    return yaml_str


def construct_metadata_filter(
    filter: Optional[Dict[str, Any]] = None,
) -> Tuple[str, Dict[str, Any]]:
    
    if not filter:
        return "", {}

    filter_snippet = ""

    for i, (key, value) in enumerate(filter.items(), start=1):
        if filter_snippet:
            filter_snippet += " AND "

        
        
        if isinstance(value, str):
            filter_snippet += f"n.{key} = '{value}'"
        else:
            filter_snippet += f"n.{key} = {value}"

    return filter_snippet, {}


def _get_search_index_query(
    search_type: SearchType, index_type: IndexType = DEFAULT_INDEX_TYPE
) -> str:
    if index_type == IndexType.NODE:
        if search_type == SearchType.VECTOR:
            return (
                "CALL db.idx.vector.queryNodes($entity_label, "
                "$entity_property, $k, vecf32($embedding)) "
                "YIELD node, score "
            )
        elif search_type == SearchType.HYBRID:
            return (
                "CALL { "
                "CALL db.idx.vector.queryNodes($entity_label, "
                "$entity_property, $k, vecf32($embedding)) "
                "YIELD node, score "
                "WITH collect({node: node, score: score})"
                " AS nodes, max(score) AS max_score "
                "UNWIND nodes AS n "
                "RETURN n.node AS node, (n.score / max_score) AS score "
                "UNION "
                "CALL db.idx.fulltext.queryNodes($entity_label, $query) "
                "YIELD node, score "
                "WITH collect({node: node, score: score})"
                " AS nodes, max(score) AS max_score "
                "UNWIND nodes AS n "
                "RETURN n.node AS node, (n.score / max_score) AS score "
                "} "
                "WITH node, max(score) AS score "
                "ORDER BY score DESC LIMIT $k "
            )
    elif index_type == IndexType.RELATIONSHIP:
        return (
            "CALL db.idx.vector.queryRelationships"
            "($entity_label, $entity_property, $k, vecf32($embedding)) "
            "YIELD relationship, score "
        )


def process_index_data(data: List[List[Any]]) -> List[Dict[str, Any]]:
    

    result = []

    for entity in data:
        

        entity_label = entity[0]

        index_type_dict = entity[2]

        index_status = entity[7]

        entity_type = entity[6]

        
        for prop, index_types in index_type_dict.items():
            entity_info = {
                "entity_label": entity_label,
                "entity_property": prop,
                "entity_type": entity_type,
                "index_type": index_types[0],
                "index_status": index_status,
                "index_dimension": None,
                "index_similarityFunction": None,
            }

            
            if "VECTOR" in index_types:
                if isinstance(entity[3], str):
                    entity_info["index_dimension"] = None
                    entity_info["index_similarityFunction"] = None
                else:
                    vector_info = entity[3].get(prop, {})
                    entity_info["index_dimension"] = vector_info.get("dimension")
                    entity_info["index_similarityFunction"] = vector_info.get(
                        "similarityFunction"
                    )

            result.append(entity_info)

    return result


class FalkorDBVector(VectorStore):
    

    def __init__(
        self,
        embedding: Embeddings,
        *,
        search_type: SearchType = SearchType.VECTOR,
        username: Optional[str] = None,
        password: Optional[str] = None,
        host: str = "localhost",
        port: int = 6379,
        distance_strategy: DistanceStrategy = DEFAULT_DISTANCE_STRATEGY,
        database: Optional[str] = generate_random_string(4),
        node_label: str = "Chunk",
        relation_type: str = "",
        embedding_node_property: str = "embedding",
        text_node_property: str = "text",
        embedding_dimension: Optional[int] = None,
        retrieval_query: Optional[str] = "",
        index_type: IndexType = DEFAULT_INDEX_TYPE,
        graph: Optional[FalkorDBGraph] = None,
        relevance_score_fn: Optional[Callable[[float], float]] = None,
        ssl: bool = False,
        pre_delete_collection: bool = False,
        metadata: List[Any] = [],
    ) -> None:
        try:
            import falkordb
        except ImportError:
            raise ImportError(
                "Could not import falkordb python package."
                "Please install it with `pip install falkordb`"
            )

        try:
            import redis.exceptions
        except ImportError:
            raise ImportError(
                "Could not import redis.exceptions."
                "Please install it with `pip install redis`"
            )

        
        if distance_strategy not in [
            DistanceStrategy.EUCLIDEAN_DISTANCE,
            DistanceStrategy.COSINE,
        ]:
            raise ValueError(
                "`distance_strategy` must be either 'EULIDEAN_DISTANCE` or `COSINE`"
            )

        
        if graph:
            self._database = graph._graph
            self._driver = graph._driver
        else:
            
            self._host = host
            self._port = port
            self._username = username or os.environ.get("FALKORDB_USERNAME")
            self._password = password or os.environ.get("FALKORDB_PASSWORD")
            self._ssl = ssl

            
            try:
                self._driver = falkordb.FalkorDB(
                    host=self._host,
                    port=self._port,
                    username=self._username,
                    password=self._password,
                    ssl=self._ssl,
                )
            except redis.exceptions.ConnectionError:
                raise ValueError(
                    "Could not connect to FalkorDB database."
                    "Please ensure that the host and port is correct"
                )
            except redis.exceptions.AuthenticationError:
                raise ValueError(
                    "Could not connect to FalkorDB database. "
                    "Please ensure that the username and password are correct"
                )

            
            if not embedding_node_property:
                raise ValueError(
                    "The `embedding_node_property` must not be None or empty string"
                )
            if not node_label:
                raise ValueError("The `node_label` must not be None or empty string")

            self._database = self._driver.select_graph(database)
            self.database_name = database
            self.embedding = embedding
            self.node_label = node_label
            self.relation_type = relation_type
            self.embedding_node_property = embedding_node_property
            self.text_node_property = text_node_property
            self._distance_strategy = distance_strategy
            self.override_relevance_score_fn = relevance_score_fn
            self.pre_delete_collection = pre_delete_collection
            self.retrieval_query = retrieval_query
            self.search_type = search_type
            self._index_type = index_type
            self.metadata = metadata

            
            if not embedding_dimension:
                self.embedding_dimension = len(self.embedding.embed_query("foo"))

            
            if pre_delete_collection:
                self._database.query(f)

    @property
    def embeddings(self) -> Embeddings:
        
        return self.embedding

    def _query(
        self,
        query: str,
        *,
        params: Optional[dict] = None,
        retry_on_timeout: bool = True,
    ) -> List[List]:
        
        params = params or {}
        try:
            data = self._database.query(query, params)
            return data.result_set
        except Exception as e:
            if "Invalid input" in str(e):
                raise ValueError(f"Cypher Statement is not valid\n{e}")
            if retry_on_timeout:
                return self._query(query, params=params, retry_on_timeout=False)
            else:
                raise e

    def retrieve_existing_node_index(
        self, node_label: Optional[str] = ""
    ) -> Tuple[Optional[int], Optional[str], Optional[str], Optional[str]]:
        
        if node_label:
            pass
        elif self.node_label:
            node_label = self.node_label
        else:
            raise ValueError("`node_label` property must be set to use this function")

        embedding_dimension = None
        entity_type = None
        entity_label = None
        entity_property = None
        index_information = self._database.query("CALL db.indexes()")

        if index_information:
            processed_index_information = process_index_data(
                index_information.result_set
            )
            for dict in processed_index_information:
                if (
                    dict.get("entity_label", False) == node_label
                    and dict.get("entity_type", False) == "NODE"
                ):
                    if dict["index_type"] == "VECTOR":
                        embedding_dimension = int(dict["index_dimension"])
                        entity_type = str(dict["entity_type"])
                        entity_label = str(dict["entity_label"])
                        entity_property = str(dict["entity_property"])
                        break
            if embedding_dimension and entity_type and entity_label and entity_property:
                self._index_type = IndexType(entity_type)
                return embedding_dimension, entity_type, entity_label, entity_property
            else:
                return None, None, None, None
        else:
            return None, None, None, None

    def retrieve_existing_relationship_index(
        self, relation_type: Optional[str] = ""
    ) -> Tuple[Optional[int], Optional[str], Optional[str], Optional[str]]:
        
        if relation_type:
            pass
        elif self.relation_type:
            relation_type = self.relation_type
        else:
            raise ValueError(
                "Couldn't find any specified `relation_type`."
                " Check if you spelled it correctly"
            )

        embedding_dimension = None
        entity_type = None
        entity_label = None
        entity_property = None
        index_information = self._database.query("CALL db.indexes()")

        if index_information:
            processed_index_information = process_index_data(
                index_information.result_set
            )
            for dict in processed_index_information:
                if (
                    dict.get("entity_label", False) == relation_type
                    and dict.get("entity_type", False) == "RELATIONSHIP"
                ):
                    if dict["index_type"] == "VECTOR":
                        embedding_dimension = int(dict["index_dimension"])
                        entity_type = str(dict["entity_type"])
                        entity_label = str(dict["entity_label"])
                        entity_property = str(dict["entity_property"])
                        break
            if embedding_dimension and entity_type and entity_label and entity_property:
                self._index_type = IndexType(entity_type)
                return embedding_dimension, entity_type, entity_label, entity_property
            else:
                return None, None, None, None
        else:
            return None, None, None, None

    def retrieve_existing_fts_index(self) -> Optional[str]:
        

        entity_label = None
        index_information = self._database.query("CALL db.indexes()")
        if index_information:
            processed_index_information = process_index_data(
                index_information.result_set
            )
            for dict in processed_index_information:
                if dict.get("entity_label", False) == self.node_label:
                    if dict["index_type"] == "FULLTEXT":
                        entity_label = str(dict["entity_label"])
                        break

            if entity_label:
                return entity_label
            else:
                return None
        else:
            return None

    def create_new_node_index(
        self,
        node_label: Optional[str] = "",
        embedding_node_property: Optional[str] = "",
        embedding_dimension: Optional[int] = None,
    ) -> None:
        
        if node_label:
            pass
        elif self.node_label:
            node_label = self.node_label
        else:
            raise ValueError("`node_label` property must be set to use this function")

        if embedding_node_property:
            pass
        elif self.embedding_node_property:
            embedding_node_property = self.embedding_node_property
        else:
            raise ValueError(
                "`embedding_node_property` property must be set to use this function"
            )

        if embedding_dimension:
            pass
        elif self.embedding_dimension:
            embedding_dimension = self.embedding_dimension
        else:
            raise ValueError(
                "`embedding_dimension` property must be set to use this function"
            )
        try:
            self._database.create_node_vector_index(
                node_label,
                embedding_node_property,
                dim=embedding_dimension,
                similarity_function=DISTANCE_MAPPING[self._distance_strategy],
            )
        except Exception as e:
            if "already indexed" in str(e):
                raise ValueError(
                    f"A vector index on (:{node_label}"
                    "{"
                    f"{embedding_node_property}"
                    "}) has already been created"
                )
            else:
                raise ValueError(f"Error occurred: {e}")

    def create_new_index_on_relationship(
        self,
        relation_type: str = "",
        embedding_node_property: str = "",
        embedding_dimension: int = 0,
    ) -> None:
        
        if relation_type:
            pass
        elif self.relation_type:
            relation_type = self.relation_type
        else:
            raise ValueError("`relation_type` must be set to use this function")
        if embedding_node_property:
            pass
        elif self.embedding_node_property:
            embedding_node_property = self.embedding_node_property
        else:
            raise ValueError(
                "`embedding_node_property` must be set to use this function"
            )
        if embedding_dimension and embedding_dimension != 0:
            pass
        elif self.embedding_dimension:
            embedding_dimension = self.embedding_dimension
        else:
            raise ValueError("`embedding_dimension` must be set to use this function")

        try:
            self._database.create_edge_vector_index(
                relation_type,
                embedding_node_property,
                dim=embedding_dimension,
                similarity_function=DISTANCE_MAPPING[DEFAULT_DISTANCE_STRATEGY],
            )
        except Exception as e:
            if "already indexed" in str(e):
                raise ValueError(
                    f"A vector index on [:{relation_type}"
                    "{"
                    f"{embedding_node_property}"
                    "}] has already been created"
                )
            else:
                raise ValueError(f"Error occurred: {e}")

    def create_new_keyword_index(self, text_node_properties: List[str] = []) -> None:
        
        
        node_props = text_node_properties or [self.text_node_property]

        
        
        self._database.create_node_fulltext_index(self.node_label, *node_props)

    def add_embeddings(
        self,
        texts: Iterable[str],
        embeddings: List[List[float]],
        metadatas: Optional[List[dict]] = None,
        ids: Optional[List[str]] = None,
        **kwargs: Any,
    ) -> List[str]:
        
        if ids is None:
            ids = [md5(text.encode("utf-8")).hexdigest() for text in texts]

        if not metadatas:
            metadatas = [{} for _ in texts]

        self.metadata = []

        
        if all(not metadata for metadata in metadatas):
            pass
        else:
            
            unique_non_empty_keys: set[str] = set()

            
            for metadata in metadatas:
                
                unique_non_empty_keys.update(
                    key for key, value in metadata.items() if value
                )

            
            if unique_non_empty_keys:
                self.metadata = list(unique_non_empty_keys)

        parameters = {
            "data": [
                {"text": text, "metadata": metadata, "embedding": embedding, "id": id}
                for text, metadata, embedding, id in zip(
                    texts, metadatas, embeddings, ids
                )
            ]
        }

        self._database.query(
            "UNWIND $data AS row "
            f"MERGE (c:`{self.node_label}` {{id: row.id}}) "
            f"SET c.`{self.embedding_node_property}`"
            f" = vecf32(row.embedding), c.`{self.text_node_property}`"
            " = row.text, c += row.metadata",
            params=parameters,
        )

        return ids

    def add_texts(
        self,
        texts: Iterable[str],
        metadatas: Optional[List[dict]] = None,
        ids: Optional[List[str]] = None,
        **kwargs: Any,
    ) -> List[str]:
        
        embeddings = self.embedding.embed_documents(list(texts))
        return self.add_embeddings(
            texts=texts, embeddings=embeddings, metadatas=metadatas, ids=ids, **kwargs
        )

    def add_documents(
        self,
        documents: List[Document],
        ids: Optional[List[str]] = None,
        **kwargs: Any,
    ) -> List[str]:
        
        
        
        if ids and len(ids) != len(documents):
            raise ValueError("The number of ids must match the number of documents.")

        result_ids = []

        
        self.from_documents(
            embedding=self.embedding,
            documents=documents,
        )

        for i, doc in enumerate(documents):
            page_content = doc.page_content
            if ids:
                
                assigned_id = ids[i]
                self._query(
                    ,
                    params={"page_content": page_content, "assigned_id": assigned_id},
                )
                result_ids.append(assigned_id)

            else:
                
                
                result = self._query(
                    ,
                    params={"page_content": page_content},
                )
                try:
                    result_ids.append(result[0][0])

                except Exception:
                    raise ValueError(
                        "Your document wasn't added to the store"
                        " successfully. Check your spellings."
                    )

        return result_ids

    @classmethod
    def from_texts(
        cls: type[FalkorDBVector],
        texts: List[str],
        embedding: Embeddings,
        metadatas: Optional[List[Dict]] = None,  
        distance_strategy: Optional[DistanceStrategy] = None,  
        ids: Optional[List[str]] = None,
        **kwargs: Any,
    ) -> FalkorDBVector:
        
        embeddings = embedding.embed_documents(list(texts))

        
        if metadatas is None:
            metadatas = [{} for _ in texts]
        if distance_strategy is None:
            distance_strategy = DEFAULT_DISTANCE_STRATEGY

        return cls.__from(
            texts,
            embeddings,
            embedding,
            metadatas=metadatas,
            ids=ids,
            distance_strategy=distance_strategy,
            **kwargs,
        )

    @classmethod
    def __from(
        cls,
        texts: List[str],
        embeddings: List[List[float]],
        embedding: Embeddings,
        metadatas: Optional[List[dict]] = None,
        ids: Optional[List[str]] = None,
        search_type: SearchType = SearchType.VECTOR,
        **kwargs: Any,
    ) -> FalkorDBVector:
        if ids is None:
            ids = [md5(text.encode("utf-8")).hexdigest() for text in texts]

        if not metadatas:
            metadatas = [{} for _ in texts]

        store = cls(
            embedding=embedding,
            search_type=search_type,
            **kwargs,
        )

        
        embedding_dimension, index_type, entity_label, entity_property = (
            store.retrieve_existing_node_index()
        )

        
        if index_type == "RELATIONSHIP":
            raise ValueError(
                "Data ingestion is not supported with relationship vector index"
            )

        
        if not index_type:
            store.create_new_node_index()
            embedding_dimension, index_type, entity_label, entity_property = (
                store.retrieve_existing_node_index()
            )

        
        elif (
            embedding_dimension and not store.embedding_dimension == embedding_dimension
        ):
            raise ValueError(
                f"A Vector index for {entity_label} on {entity_property} exists"
                "The provided embedding function and vector index "
                "dimensions do not match.\n"
                f"Embedding function dimension: {store.embedding_dimension}\n"
                f"Vector index dimension: {embedding_dimension}"
            )

        if search_type == SearchType.HYBRID:
            fts_node_label = store.retrieve_existing_fts_index()
            
            if not fts_node_label:
                store.create_new_keyword_index()
            else:  
                if not fts_node_label == store.node_label:
                    raise ValueError(
                        "Vector and keyword index don't index the same node label"
                    )

        store.add_embeddings(
            texts=texts, embeddings=embeddings, metadatas=metadatas, ids=ids, **kwargs
        )

        return store

    @classmethod
    def from_existing_index(
        cls: Type[FalkorDBVector],
        embedding: Embeddings,
        node_label: str,
        search_type: SearchType = DEFAULT_SEARCH_TYPE,
        **kwargs: Any,
    ) -> FalkorDBVector:
        

        store = cls(
            embedding=embedding,
            node_label=node_label,
            search_type=search_type,
            **kwargs,
        )

        embedding_dimension, index_type, entity_label, entity_property = (
            store.retrieve_existing_node_index()
        )

        
        if index_type == "RELATIONSHIP":
            raise ValueError(
                "Relationship vector index is not supported with "
                "`from_existing_index` method. Please use the "
                "`from_existing_relationship_index` method."
            )

        if not index_type:
            raise ValueError(
                f"The specified vector index node label `{node_label}` does not exist. "
                "Make sure to check if you spelled the node label correctly"
            )

        
        if embedding_dimension and not store.embedding_dimension == embedding_dimension:
            raise ValueError(
                "The provided embedding function and vector index "
                "dimensions do not match.\n"
                f"Embedding function dimension: {store.embedding_dimension}\n"
                f"Vector index dimension: {embedding_dimension}"
            )

        if search_type == SearchType.HYBRID:
            fts_node_label = store.retrieve_existing_fts_index()
            
            if not fts_node_label:
                raise ValueError(
                    "The specified keyword index name does not exist. "
                    "Make sure to check if you spelled it correctly"
                )
            else:  
                if not fts_node_label == store.node_label:
                    raise ValueError(
                        "Vector and keyword index don't index the same node label"
                    )

        return store

    @classmethod
    def from_existing_relationship_index(
        cls: Type[FalkorDBVector],
        embedding: Embeddings,
        relation_type: str,
        search_type: SearchType = DEFAULT_SEARCH_TYPE,
        **kwargs: Any,
    ) -> FalkorDBVector:
        
        if search_type == SearchType.HYBRID:
            raise ValueError(
                "Hybrid search is not supported in combination "
                "with relationship vector index"
            )

        store = cls(
            embedding=embedding,
            relation_type=relation_type,
            **kwargs,
        )

        embedding_dimension, index_type, entity_label, entity_property = (
            store.retrieve_existing_relationship_index()
        )

        if not index_type:
            raise ValueError(
                "The specified vector index on the relationship"
                f" {relation_type} does not exist. "
                "Make sure to check if you spelled it correctly"
            )
        
        if index_type == "NODE":
            raise ValueError(
                "Node vector index is not supported with "
                "`from_existing_relationship_index` method. Please use the "
                "`from_existing_index` method."
            )

        
        if embedding_dimension and not store.embedding_dimension == embedding_dimension:
            raise ValueError(
                "The provided embedding function and vector index "
                "dimensions do not match.\n"
                f"Embedding function dimension: {store.embedding_dimension}\n"
                f"Vector index dimension: {embedding_dimension}"
            )

        return store

    @classmethod
    def from_existing_graph(
        cls: Type[FalkorDBVector],
        embedding: Embeddings,
        database: str,
        node_label: str,
        embedding_node_property: str,
        text_node_properties: List[str],
        *,
        search_type: SearchType = DEFAULT_SEARCH_TYPE,
        retrieval_query: str = "",
        **kwargs: Any,
    ) -> FalkorDBVector:
        
        
        if not database:
            raise ValueError("Parameter `database` must be given")
        if not text_node_properties:
            raise ValueError(
                "Parameter `text_node_properties` must not be an empty list"
            )

        
        if not retrieval_query:
            retrieval_query = (
                f"RETURN reduce(str='', k IN {text_node_properties} |"
                " str + '\\n' + k + ': ' + coalesce(node[k], '')) AS text, "
                "node {.*, `"
                + embedding_node_property
                + "`: Null, id: Null, "
                + ", ".join([f"`{prop}`: Null" for prop in text_node_properties])
                + "} AS metadata, score"
            )

        store = cls(
            database=database,
            embedding=embedding,
            search_type=search_type,
            retrieval_query=retrieval_query,
            node_label=node_label,
            embedding_node_property=embedding_node_property,
            **kwargs,
        )

        embedding_dimension, index_type, entity_label, entity_property = (
            store.retrieve_existing_node_index()
        )

        
        if index_type == "RELATIONSHIP":
            raise ValueError(
                "`from_existing_graph` method does not support "
                " existing relationship vector index. "
                "Please use `from_existing_relationship_index` method"
            )

        
        if not index_type:
            store.create_new_node_index(node_label=node_label)
        
        elif (
            embedding_dimension and not store.embedding_dimension == embedding_dimension
        ):
            raise ValueError(
                f"Index on Node {store.node_label} already exists."
                "The provided embedding function and vector index "
                "dimensions do not match.\n"
                f"Embedding function dimension: {store.embedding_dimension}\n"
                f"Vector index dimension: {embedding_dimension}"
            )
        
        if search_type == SearchType.HYBRID:
            fts_node_label = store.retrieve_existing_fts_index()
            
            if not fts_node_label:
                store.create_new_keyword_index(text_node_properties)
            else:  
                if not fts_node_label == store.node_label:
                    raise ValueError(
                        "Vector and keyword index don't index the same node label"
                    )

        

        while True:
            fetch_query = (
                f"MATCH (n:`{node_label}`) "
                f"WHERE n.`{embedding_node_property}` IS null "
                "AND any(k IN $props WHERE n[k] IS NOT null) "
                "RETURN id(n) AS id, "
                "coalesce(n.text, '') AS text "
                "LIMIT 1000"
            )
            data = store._query(fetch_query, params={"props": text_node_properties})
            if not data:
                break
            text_embeddings = embedding.embed_documents([el[1] for el in data])

            params = {
                "data": [
                    {"id": el[0], "embedding": embedding}
                    for el, embedding in zip(data, text_embeddings)
                ]
            }

            store._query(
                "UNWIND $data AS row "
                f"MATCH (n:`{node_label}`) "
                "WHERE id(n) = row.id "
                f"SET n.`{embedding_node_property}` = vecf32(row.embedding)"
                "RETURN count(*)",
                params=params,
            )
            
            if len(data) < 1000:
                break
        return store

    @classmethod
    def from_documents(
        cls: Type[FalkorDBVector],
        documents: List[Document],
        embedding: Embeddings,
        distance_strategy: DistanceStrategy = DEFAULT_DISTANCE_STRATEGY,
        ids: Optional[List[str]] = None,
        **kwargs: Any,
    ) -> FalkorDBVector:
        
        texts = [d.page_content for d in documents]
        metadatas = [d.metadata for d in documents]

        return cls.from_texts(
            texts=texts,
            embedding=embedding,
            distance_strategy=distance_strategy,
            metadatas=metadatas,
            ids=ids,
            **kwargs,
        )

    @classmethod
    def from_embeddings(
        cls,
        text_embeddings: List[Tuple[str, List[float]]],
        embedding: Embeddings,
        metadatas: Optional[List[dict]] = None,
        distance_strategy: DistanceStrategy = DEFAULT_DISTANCE_STRATEGY,
        ids: Optional[List[str]] = None,
        pre_delete_collection: bool = False,
        **kwargs: Any,
    ) -> FalkorDBVector:
        
        texts = [t[0] for t in text_embeddings]
        embeddings = [t[1] for t in text_embeddings]

        return cls.__from(
            texts,
            embeddings,
            embedding,
            metadatas=metadatas,
            ids=ids,
            distance_strategy=distance_strategy,
            pre_delete_collection=pre_delete_collection,
            **kwargs,
        )

    def similarity_search(
        self,
        query: str,
        k: int = 4,
        params: Dict[str, Any] = {},
        filter: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> List[Document]:
        
        embedding = self.embedding.embed_query(text=query)
        return self.similarity_search_by_vector(
            embedding=embedding,
            k=k,
            query=query,
            params=params,
            filter=filter,
            **kwargs,
        )

    def similarity_search_by_vector(
        self,
        embedding: List[float],
        k: int = 4,
        filter: Optional[Dict[str, Any]] = None,
        params: Dict[str, Any] = {},
        **kwargs: Any,
    ) -> List[Document]:
        
        docs_and_scores = self.similarity_search_with_score_by_vector(
            embedding=embedding, k=k, filter=filter, params=params, **kwargs
        )
        return [doc for doc, _ in docs_and_scores]

    def similarity_search_with_score_by_vector(
        self,
        embedding: List[float],
        k: int = 4,
        params: Dict[str, Any] = {},
        filter: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> List[Tuple[Document, float]]:
        
        if filter:
            if self.search_type == SearchType.HYBRID:
                raise ValueError(
                    "Metadata filtering can't be use in combination with "
                    "a hybrid search approach"
                )

            base_index_query = (
                f"MATCH (n:{self.node_label}) WHERE "
                f"n.{self.embedding_node_property} IS NOT NULL AND "
            )

            base_cosine_query = (
                " WITH n as node, "
                f" vec.cosineDistance(n.{self.embedding_node_property}"
                ", vecf32($embedding)) as score "
            )

            filter_snippets, filter_params = construct_metadata_filter(filter)

            index_query = base_index_query + filter_snippets + base_cosine_query
        else:
            index_query = _get_search_index_query(self.search_type, self._index_type)
            filter_params = {}

        if self._index_type == IndexType.RELATIONSHIP:
            if kwargs.get("return_embeddings"):
                if self.metadata:
                    
                    metadata_fields = ", ".join(
                        f"`{key}`: relationship.{key}" for key in self.metadata
                    )
                    default_retrieval = (
                        f"RETURN relationship.{self.text_node_property} "
                        "AS text, score, "
                        f"{{text: relationship.{self.text_node_property}, "
                        f"embedding: relationship.{self.embedding_node_property}, "
                        f"id: relationship.id, source: relationship.source, "
                        f"{metadata_fields}}} AS metadata"
                    )
                else:
                    default_retrieval = (
                        f"RETURN relationship.{self.text_node_property}"
                        " AS text, score, "
                        f"{{text: relationship.{self.text_node_property}, "
                        f"embedding: relationship.{self.embedding_node_property}, "
                        f"id: relationship.id, source: relationship.source}}"
                        " AS metadata"
                    )
            else:
                if self.metadata:
                    
                    metadata_fields = ", ".join(
                        f"`{key}`: relationship.{key}" for key in self.metadata
                    )
                    default_retrieval = (
                        f"RETURN relationship.{self.text_node_property} "
                        "AS text, score, "
                        f"{{text: relationship.{self.text_node_property}, "
                        f"id: relationship.id, source: relationship.source, "
                        f"{metadata_fields}}} AS metadata"
                    )
                else:
                    default_retrieval = (
                        f"RETURN relationship.{self.text_node_property}"
                        " AS text, score, "
                        f"{{text: relationship.{self.text_node_property}, "
                        f"id: relationship.id, source: relationship.source}}"
                        " AS metadata"
                    )
        else:
            if kwargs.get("return_embeddings"):
                if self.metadata:
                    
                    metadata_fields = ", ".join(
                        f"`{key}`: node.`{key}`" for key in self.metadata
                    )
                    default_retrieval = (
                        f"RETURN node.{self.text_node_property} AS text, score, "
                        f"{{text: node.{self.text_node_property}, "
                        f"embedding: node.{self.embedding_node_property}, "
                        f"id: node.id, source: node.source, "
                        f"{metadata_fields}}} AS metadata"
                    )
                else:
                    default_retrieval = (
                        f"RETURN node.{self.text_node_property} AS text, score, "
                        f"{{text: node.{self.text_node_property}, "
                        f"embedding: node.{self.embedding_node_property}, "
                        f"id: node.id, source: node.source}} AS metadata"
                    )
            else:
                if self.metadata:
                    
                    metadata_fields = ", ".join(
                        f"`{key}`: node.`{key}`" for key in self.metadata
                    )
                    default_retrieval = (
                        f"RETURN node.{self.text_node_property} AS text, score, "
                        f"{{text: node.{self.text_node_property}, "
                        f"id: node.id, source: node.source, "
                        f"{metadata_fields}}} AS metadata"
                    )
                else:
                    default_retrieval = (
                        f"RETURN node.{self.text_node_property} AS text, score, "
                        f"{{text: node.{self.text_node_property}, "
                        f"id: node.id, source: node.source}} AS metadata"
                    )

        retrieval_query = (
            self.retrieval_query if self.retrieval_query else default_retrieval
        )

        read_query = index_query + retrieval_query
        parameters = {
            "entity_property": self.embedding_node_property,
            "k": k,
            "embedding": embedding,
            "query": kwargs["query"],
            **params,
            **filter_params,
        }
        if self._index_type == "NODE":
            parameters["entity_label"] = self.node_label
        elif self._index_type == "RELATIONSHIP":
            parameters["entity_label"] = self.relation_type

        results = self._query(read_query, params=parameters)

        if not results:
            if not self.retrieval_query:
                raise ValueError(
                    f"Make sure that none of the `{self.text_node_property}` "
                    f"properties on nodes with label `{self.node_label}` "
                    "are missing or empty"
                )
            else:
                raise ValueError(
                    "Inspect the `retrieval_query` and ensure it doesn't "
                    "return None for the `text` column"
                )
        elif any(result[0] is None for result in results):
            if not self.retrieval_query:
                raise ValueError(
                    f"Make sure that none of the `{self.text_node_property}` "
                    f"properties on nodes with label `{self.node_label}` "
                    "are missing or empty"
                )
            else:
                raise ValueError(
                    "Inspect the `retrieval_query` and ensure it doesn't "
                    "return None for the `text` column"
                )

        
        if kwargs.get("return_embeddings") and any(
            result[2]["embedding"] is None for result in results
        ):
            if not self.retrieval_query:
                raise ValueError(
                    f"Make sure that none of the `{self.embedding_node_property}` "
                    f"properties on nodes with label `{self.node_label}` "
                    "are missing or empty"
                )
            else:
                raise ValueError(
                    "Inspect the `retrieval_query` and ensure it doesn't "
                    "return None for the `embedding` metadata column"
                )

        try:
            docs = [
                (
                    Document(
                        
                        page_content=result[0],
                        metadata={
                            k: v for k, v in result[2].items() if v is not None
                        },  
                    ),
                    result[1],  
                )
                for result in results
            ]
        except AttributeError:
            try:
                sorted_results = sorted(results, key=lambda r: r[2], reverse=True)
                docs = [
                    (
                        Document(
                            
                            page_content=result[0],
                            metadata={
                                k: v for k, v in result[1].items() if v is not None
                            },  
                        ),
                        result[2],  
                    )
                    for result in sorted_results
                ]
            except Exception as e:
                raise ValueError(f"An error occurred: {e}")

        return docs

    def similarity_search_with_score(
        self,
        query: str,
        k: int = 4,
        params: Dict[str, Any] = {},
        filter: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> List[Tuple[Document, float]]:
        
        embedding = self.embedding.embed_query(query)
        docs = self.similarity_search_with_score_by_vector(
            embedding=embedding,
            k=k,
            query=query,
            params=params,
            filter=filter,
            **kwargs,
        )
        return docs

    def similarity_search_with_relevance_scores(
        self,
        query: str,
        k: int = 4,
        filter: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> List[Tuple[Document, float]]:
        docs_with_scores = self.similarity_search_with_score(
            query=query, k=k, filter=filter, **kwargs
        )

        return docs_with_scores

    def max_marginal_relevance_search(
        self,
        query: str,
        k: int = 4,
        fetch_k: int = 20,
        lambda_mult: float = 0.5,
        filter: Optional[dict] = None,
        **kwargs: Any,
    ) -> List[Document]:
        
        
        query_embedding = self.embedding.embed_query(query)

        
        got_docs = self.similarity_search_with_score_by_vector(
            embedding=query_embedding,
            query=query,
            k=fetch_k,
            return_embeddings=True,
            filter=filter,
            **kwargs,
        )

        got_embeddings = [doc.metadata["embedding"] for doc, _ in got_docs]

        
        selected_indices = maximal_marginal_relevance(
            np.array(query_embedding), got_embeddings, lambda_mult=lambda_mult, k=k
        )
        selected_docs = [got_docs[i][0] for i in selected_indices]

        
        for doc in selected_docs:
            del doc.metadata["embedding"]

        return selected_docs

    def _select_relevance_score_fn(self) -> Callable[[float], float]:
        
        if self.override_relevance_score_fn is not None:
            return self.override_relevance_score_fn

        
        
        if self._distance_strategy == DistanceStrategy.COSINE:
            return lambda x: x
        elif self._distance_strategy == DistanceStrategy.EUCLIDEAN_DISTANCE:
            return lambda x: x
        else:
            raise ValueError(
                "No supported normalization function"
                f" for distance_strategy of {self._distance_strategy}."
                "Consider providing relevance_score_fn to PGVector constructor."
            )

    def update_documents(
        self,
        document_id: str,
        document: Document,
    ) -> None:
        

        
        existing_document = self._query(
            ,
            params={"document_id": document_id},
        )

        if not existing_document:
            raise ValueError(f"Document with id {document_id} not found in the store.")

        
        self._query(
            ,
            params={"document_id": document_id, "new_content": document.page_content},
        )

        
        if document.metadata:
            for key, value in document.metadata.items():
                self._query(
                    f,
                    params={"document_id": document_id, "value": value},
                )

    def delete(
        self,
        ids: Optional[List[str]] = None,  
        **kwargs: Any,
    ) -> Optional[bool]:  
        
        if ids is None:
            raise ValueError("You must provide at least one ID to delete.")
        for id in ids:
            item_id = id
            
            existing_document = self._query(
                ,
                params={"item_id": item_id},
            )
            if not existing_document:
                raise ValueError(f"Document with id {item_id} not found in the store.")
            
            self._query(
                ,
                params={"item_id": item_id},
            )
        return True
