from __future__ import annotations

import logging
import uuid
from typing import TYPE_CHECKING, Any, Iterable, List, Optional, Tuple, Union, cast

import numpy as np
from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from langchain_core.utils.iter import batch_iterate
from langchain_core.vectorstores import VectorStore

from langchain_community.vectorstores.utils import (
    maximal_marginal_relevance,
)

if TYPE_CHECKING:
    from upstash_vector import AsyncIndex, Index
    from upstash_vector.types import InfoResult

logger = logging.getLogger(__name__)


class UpstashVectorStore(VectorStore):
    

    def __init__(
        self,
        text_key: str = "text",
        index: Optional[Index] = None,
        async_index: Optional[AsyncIndex] = None,
        index_url: Optional[str] = None,
        index_token: Optional[str] = None,
        embedding: Optional[Union[Embeddings, bool]] = None,
        *,
        namespace: str = "",
    ):
        

        try:
            from upstash_vector import AsyncIndex, Index
        except ImportError:
            raise ImportError(
                "Could not import upstash_vector python package. "
                "Please install it with `pip install upstash_vector`."
            )

        if index:
            if not isinstance(index, Index):
                raise ValueError(
                    "Passed index object should be an "
                    "instance of upstash_vector.Index, "
                    f"got {type(index)}"
                )
            self._index = index
            logger.info("Using the index passed as parameter")
        if async_index:
            if not isinstance(async_index, AsyncIndex):
                raise ValueError(
                    "Passed index object should be an "
                    "instance of upstash_vector.AsyncIndex, "
                    f"got {type(async_index)}"
                )
            self._async_index = async_index
            logger.info("Using the async index passed as parameter")

        if index_url and index_token:
            self._index = Index(url=index_url, token=index_token)
            self._async_index = AsyncIndex(url=index_url, token=index_token)
            logger.info("Created index from the index_url and index_token parameters")
        elif not index and not async_index:
            self._index = Index.from_env()
            self._async_index = AsyncIndex.from_env()
            logger.info("Created index using environment variables")

        self._embeddings = embedding
        self._text_key = text_key
        self._namespace = namespace

    @property
    def embeddings(self) -> Optional[Union[Embeddings, bool]]:  
        
        return self._embeddings

    def _embed_documents(
        self, texts: Iterable[str]
    ) -> Union[List[List[float]], List[str]]:
        
        if not self._embeddings:
            raise ValueError(
                "No embeddings object provided. "
                "Pass an embeddings object to the constructor."
            )
        if isinstance(self._embeddings, Embeddings):
            return self._embeddings.embed_documents(list(texts))

        
        
        return list(texts)

    def _embed_query(self, text: str) -> Union[List[float], str]:
        
        if not self._embeddings:
            raise ValueError(
                "No embeddings object provided. "
                "Pass an embeddings object to the constructor."
            )
        if isinstance(self._embeddings, Embeddings):
            return self._embeddings.embed_query(text)

        
        
        return text

    def add_documents(
        self,
        documents: List[Document],
        ids: Optional[List[str]] = None,
        batch_size: int = 32,
        embedding_chunk_size: int = 1000,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[str]:
        
        texts = [doc.page_content for doc in documents]
        metadatas = [doc.metadata for doc in documents]

        return self.add_texts(
            texts,
            metadatas=metadatas,
            batch_size=batch_size,
            ids=ids,
            embedding_chunk_size=embedding_chunk_size,
            namespace=namespace,
            **kwargs,
        )

    async def aadd_documents(
        self,
        documents: Iterable[Document],
        ids: Optional[List[str]] = None,
        batch_size: int = 32,
        embedding_chunk_size: int = 1000,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[str]:
        
        texts = [doc.page_content for doc in documents]
        metadatas = [doc.metadata for doc in documents]

        return await self.aadd_texts(
            texts,
            metadatas=metadatas,
            ids=ids,
            batch_size=batch_size,
            embedding_chunk_size=embedding_chunk_size,
            namespace=namespace,
            **kwargs,
        )

    def add_texts(
        self,
        texts: Iterable[str],
        metadatas: Optional[List[dict]] = None,
        ids: Optional[List[str]] = None,
        batch_size: int = 32,
        embedding_chunk_size: int = 1000,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[str]:
        
        if namespace is None:
            namespace = self._namespace

        texts = list(texts)
        ids = ids or [str(uuid.uuid4()) for _ in texts]

        
        if metadatas:
            metadatas = [m.copy() for m in metadatas]
        else:
            metadatas = [{} for _ in texts]

        
        for metadata, text in zip(metadatas, texts):
            metadata[self._text_key] = text

        for i in range(0, len(texts), embedding_chunk_size):
            chunk_texts = texts[i : i + embedding_chunk_size]
            chunk_ids = ids[i : i + embedding_chunk_size]
            chunk_metadatas = metadatas[i : i + embedding_chunk_size]
            embeddings = self._embed_documents(chunk_texts)

            for batch in batch_iterate(
                batch_size, zip(chunk_ids, embeddings, chunk_metadatas)
            ):
                self._index.upsert(
                    vectors=batch, namespace=cast(str, namespace), **kwargs
                )

        return ids

    async def aadd_texts(
        self,
        texts: Iterable[str],
        metadatas: Optional[List[dict]] = None,
        ids: Optional[List[str]] = None,
        batch_size: int = 32,
        embedding_chunk_size: int = 1000,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[str]:
        
        if namespace is None:
            namespace = self._namespace

        texts = list(texts)
        ids = ids or [str(uuid.uuid4()) for _ in texts]

        
        if metadatas:
            metadatas = [m.copy() for m in metadatas]
        else:
            metadatas = [{} for _ in texts]

        
        for metadata, text in zip(metadatas, texts):
            metadata[self._text_key] = text

        for i in range(0, len(texts), embedding_chunk_size):
            chunk_texts = texts[i : i + embedding_chunk_size]
            chunk_ids = ids[i : i + embedding_chunk_size]
            chunk_metadatas = metadatas[i : i + embedding_chunk_size]
            embeddings = self._embed_documents(chunk_texts)

            for batch in batch_iterate(
                batch_size, zip(chunk_ids, embeddings, chunk_metadatas)
            ):
                await self._async_index.upsert(
                    vectors=batch, namespace=cast(str, namespace), **kwargs
                )

        return ids

    def similarity_search_with_score(
        self,
        query: str,
        k: int = 4,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Tuple[Document, float]]:
        
        return self.similarity_search_by_vector_with_score(
            self._embed_query(query), k=k, filter=filter, namespace=namespace, **kwargs
        )

    async def asimilarity_search_with_score(
        self,
        query: str,
        k: int = 4,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Tuple[Document, float]]:
        
        return await self.asimilarity_search_by_vector_with_score(
            self._embed_query(query), k=k, filter=filter, namespace=namespace, **kwargs
        )

    def _process_results(self, results: List) -> List[Tuple[Document, float]]:
        docs = []
        for res in results:
            metadata = res.metadata
            if metadata and self._text_key in metadata:
                text = metadata.pop(self._text_key)
                doc = Document(page_content=text, metadata=metadata)
                docs.append((doc, res.score))
            else:
                logger.warning(
                    f"Found document with no `{self._text_key}` key. Skipping."
                )
        return docs

    def similarity_search_by_vector_with_score(
        self,
        embedding: Union[List[float], str],
        k: int = 4,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Tuple[Document, float]]:
        

        filter = filter or ""

        if namespace is None:
            namespace = self._namespace

        if isinstance(embedding, str):
            results = self._index.query(
                data=embedding,
                top_k=k,
                include_metadata=True,
                filter=filter,
                namespace=namespace,
                **kwargs,
            )
        else:
            results = self._index.query(
                vector=embedding,
                top_k=k,
                include_metadata=True,
                filter=filter,
                namespace=namespace,
                **kwargs,
            )

        return self._process_results(results)

    async def asimilarity_search_by_vector_with_score(
        self,
        embedding: Union[List[float], str],
        k: int = 4,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Tuple[Document, float]]:
        

        filter = filter or ""

        if namespace is None:
            namespace = self._namespace

        if isinstance(embedding, str):
            results = await self._async_index.query(
                data=embedding,
                top_k=k,
                include_metadata=True,
                filter=filter,
                namespace=namespace,
                **kwargs,
            )
        else:
            results = await self._async_index.query(
                vector=embedding,
                top_k=k,
                include_metadata=True,
                filter=filter,
                namespace=namespace,
                **kwargs,
            )

        return self._process_results(results)

    def similarity_search(
        self,
        query: str,
        k: int = 4,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Document]:
        
        docs_and_scores = self.similarity_search_with_score(
            query, k=k, filter=filter, namespace=namespace, **kwargs
        )
        return [doc for doc, _ in docs_and_scores]

    async def asimilarity_search(
        self,
        query: str,
        k: int = 4,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Document]:
        
        docs_and_scores = await self.asimilarity_search_with_score(
            query, k=k, filter=filter, namespace=namespace, **kwargs
        )
        return [doc for doc, _ in docs_and_scores]

    def similarity_search_by_vector(
        self,
        embedding: Union[List[float], str],
        k: int = 4,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Document]:
        
        docs_and_scores = self.similarity_search_by_vector_with_score(
            embedding, k=k, filter=filter, namespace=namespace, **kwargs
        )
        return [doc for doc, _ in docs_and_scores]

    async def asimilarity_search_by_vector(
        self,
        embedding: Union[List[float], str],
        k: int = 4,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Document]:
        
        docs_and_scores = await self.asimilarity_search_by_vector_with_score(
            embedding, k=k, filter=filter, namespace=namespace, **kwargs
        )
        return [doc for doc, _ in docs_and_scores]

    def _similarity_search_with_relevance_scores(
        self,
        query: str,
        k: int = 4,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Tuple[Document, float]]:
        
        return self.similarity_search_with_score(
            query, k=k, filter=filter, namespace=namespace, **kwargs
        )

    async def _asimilarity_search_with_relevance_scores(
        self,
        query: str,
        k: int = 4,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Tuple[Document, float]]:
        
        return await self.asimilarity_search_with_score(
            query, k=k, filter=filter, namespace=namespace, **kwargs
        )

    def max_marginal_relevance_search_by_vector(
        self,
        embedding: Union[List[float], str],
        k: int = 4,
        fetch_k: int = 20,
        lambda_mult: float = 0.5,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Document]:
        
        if namespace is None:
            namespace = self._namespace

        assert isinstance(self.embeddings, Embeddings)
        if isinstance(embedding, str):
            results = self._index.query(
                data=embedding,
                top_k=fetch_k,
                include_vectors=True,
                include_metadata=True,
                filter=filter or "",
                namespace=namespace,
                **kwargs,
            )
        else:
            results = self._index.query(
                vector=embedding,
                top_k=fetch_k,
                include_vectors=True,
                include_metadata=True,
                filter=filter or "",
                namespace=namespace,
                **kwargs,
            )

        mmr_selected = maximal_marginal_relevance(
            np.array([embedding], dtype=np.float32),
            [item.vector for item in results],
            k=k,
            lambda_mult=lambda_mult,
        )
        selected = [results[i].metadata for i in mmr_selected]
        return [
            Document(page_content=metadata.pop((self._text_key)), metadata=metadata)
            for metadata in selected
        ]

    async def amax_marginal_relevance_search_by_vector(
        self,
        embedding: Union[List[float], str],
        k: int = 4,
        fetch_k: int = 20,
        lambda_mult: float = 0.5,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Document]:
        

        if namespace is None:
            namespace = self._namespace

        assert isinstance(self.embeddings, Embeddings)
        if isinstance(embedding, str):
            results = await self._async_index.query(
                data=embedding,
                top_k=fetch_k,
                include_vectors=True,
                include_metadata=True,
                filter=filter or "",
                namespace=namespace,
                **kwargs,
            )
        else:
            results = await self._async_index.query(
                vector=embedding,
                top_k=fetch_k,
                include_vectors=True,
                include_metadata=True,
                filter=filter or "",
                namespace=namespace,
                **kwargs,
            )

        mmr_selected = maximal_marginal_relevance(
            np.array([embedding], dtype=np.float32),
            [item.vector for item in results],
            k=k,
            lambda_mult=lambda_mult,
        )
        selected = [results[i].metadata for i in mmr_selected]
        return [
            Document(page_content=metadata.pop((self._text_key)), metadata=metadata)
            for metadata in selected
        ]

    def max_marginal_relevance_search(
        self,
        query: str,
        k: int = 4,
        fetch_k: int = 20,
        lambda_mult: float = 0.5,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Document]:
        
        embedding = self._embed_query(query)
        return self.max_marginal_relevance_search_by_vector(
            embedding=embedding,
            k=k,
            fetch_k=fetch_k,
            lambda_mult=lambda_mult,
            filter=filter,
            namespace=namespace,
            **kwargs,
        )

    async def amax_marginal_relevance_search(
        self,
        query: str,
        k: int = 4,
        fetch_k: int = 20,
        lambda_mult: float = 0.5,
        filter: Optional[str] = None,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> List[Document]:
        
        embedding = self._embed_query(query)
        return await self.amax_marginal_relevance_search_by_vector(
            embedding=embedding,
            k=k,
            fetch_k=fetch_k,
            lambda_mult=lambda_mult,
            filter=filter,
            namespace=namespace,
            **kwargs,
        )

    @classmethod
    def from_texts(
        cls,
        texts: List[str],
        embedding: Embeddings,
        metadatas: Optional[List[dict]] = None,
        ids: Optional[List[str]] = None,
        embedding_chunk_size: int = 1000,
        batch_size: int = 32,
        text_key: str = "text",
        index: Optional[Index] = None,
        async_index: Optional[AsyncIndex] = None,
        index_url: Optional[str] = None,
        index_token: Optional[str] = None,
        *,
        namespace: str = "",
        **kwargs: Any,
    ) -> UpstashVectorStore:
        
        vector_store = cls(
            embedding=embedding,
            text_key=text_key,
            index=index,
            async_index=async_index,
            index_url=index_url,
            index_token=index_token,
            namespace=namespace,
            **kwargs,
        )

        vector_store.add_texts(
            texts,
            metadatas=metadatas,
            ids=ids,
            batch_size=batch_size,
            embedding_chunk_size=embedding_chunk_size,
            namespace=namespace,
        )
        return vector_store

    @classmethod
    async def afrom_texts(
        cls,
        texts: List[str],
        embedding: Embeddings,
        metadatas: Optional[List[dict]] = None,
        ids: Optional[List[str]] = None,
        embedding_chunk_size: int = 1000,
        batch_size: int = 32,
        text_key: str = "text",
        index: Optional[Index] = None,
        async_index: Optional[AsyncIndex] = None,
        index_url: Optional[str] = None,
        index_token: Optional[str] = None,
        *,
        namespace: str = "",
        **kwargs: Any,
    ) -> UpstashVectorStore:
        
        vector_store = cls(
            embedding=embedding,
            text_key=text_key,
            index=index,
            async_index=async_index,
            namespace=namespace,
            index_url=index_url,
            index_token=index_token,
            **kwargs,
        )

        await vector_store.aadd_texts(
            texts,
            metadatas=metadatas,
            ids=ids,
            batch_size=batch_size,
            namespace=namespace,
            embedding_chunk_size=embedding_chunk_size,
        )
        return vector_store

    def delete(
        self,
        ids: Optional[List[str]] = None,
        delete_all: Optional[bool] = None,
        batch_size: Optional[int] = 1000,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> None:
        
        if namespace is None:
            namespace = self._namespace

        if delete_all:
            self._index.reset(namespace=namespace)
        elif ids is not None:
            for batch in batch_iterate(batch_size, ids):
                self._index.delete(ids=batch, namespace=namespace)
        else:
            raise ValueError("Either ids or delete_all should be provided")

        return None

    async def adelete(
        self,
        ids: Optional[List[str]] = None,
        delete_all: Optional[bool] = None,
        batch_size: Optional[int] = 1000,
        *,
        namespace: Optional[str] = None,
        **kwargs: Any,
    ) -> None:
        
        if namespace is None:
            namespace = self._namespace

        if delete_all:
            await self._async_index.reset(namespace=namespace)
        elif ids is not None:
            for batch in batch_iterate(batch_size, ids):
                await self._async_index.delete(ids=batch, namespace=namespace)
        else:
            raise ValueError("Either ids or delete_all should be provided")

        return None

    def info(self) -> InfoResult:
        
        return self._index.info()

    async def ainfo(self) -> InfoResult:
        
        return await self._async_index.info()
