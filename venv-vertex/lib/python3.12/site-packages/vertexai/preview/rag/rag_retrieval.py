

















import re
from typing import List, Optional
import warnings

from google.cloud import aiplatform_v1beta1
from google.cloud.aiplatform import initializer
from vertexai.preview.rag.utils import _gapic_utils
from vertexai.preview.rag.utils import resources


def retrieval_query(
    text: str,
    rag_resources: Optional[List[resources.RagResource]] = None,
    rag_corpora: Optional[List[str]] = None,
    similarity_top_k: Optional[int] = None,
    vector_distance_threshold: Optional[float] = None,
    vector_search_alpha: Optional[float] = None,
    rag_retrieval_config: Optional[resources.RagRetrievalConfig] = None,
) -> aiplatform_v1beta1.RetrieveContextsResponse:
    
    parent = initializer.global_config.common_location_path()

    client = _gapic_utils.create_rag_service_client()

    if rag_resources:
        if len(rag_resources) > 1:
            raise ValueError("Currently only support 1 RagResource.")
        name = rag_resources[0].rag_corpus
    elif rag_corpora:
        if len(rag_corpora) > 1:
            raise ValueError("Currently only support 1 RagCorpus.")
        name = rag_corpora[0]
        warnings.warn(
            f"rag_corpora is deprecated. Please use rag_resources instead."
            f" After {resources.DEPRECATION_DATE} using"
            " rag_corpora will raise error",
            DeprecationWarning,
        )
    else:
        raise ValueError("rag_resources or rag_corpora must be specified.")

    data_client = _gapic_utils.create_rag_data_service_client()
    if data_client.parse_rag_corpus_path(name):
        rag_corpus_name = name
    elif re.match("^{}$".format(_gapic_utils._VALID_RESOURCE_NAME_REGEX), name):
        rag_corpus_name = parent + "/ragCorpora/" + name
    else:
        raise ValueError(
            f"Invalid RagCorpus name: {rag_corpora}. Proper format should be:"
            " projects/{project}/locations/{location}/ragCorpora/{rag_corpus_id}"
        )

    if rag_resources:
        gapic_rag_resource = (
            aiplatform_v1beta1.RetrieveContextsRequest.VertexRagStore.RagResource(
                rag_corpus=rag_corpus_name,
                rag_file_ids=rag_resources[0].rag_file_ids,
            )
        )
        vertex_rag_store = aiplatform_v1beta1.RetrieveContextsRequest.VertexRagStore(
            rag_resources=[gapic_rag_resource],
        )
    else:
        vertex_rag_store = aiplatform_v1beta1.RetrieveContextsRequest.VertexRagStore(
            rag_corpora=[rag_corpus_name],
        )

    
    if similarity_top_k:
        
        warnings.warn(
            "similarity_top_k is deprecated. Please use"
            " rag_retrieval_config.top_k instead."
            f" After {resources.DEPRECATION_DATE} using"
            " similarity_top_k will raise error",
            DeprecationWarning,
        )
    if vector_search_alpha:
        
        warnings.warn(
            "vector_search_alpha is deprecated. Please use"
            " rag_retrieval_config.alpha instead."
            f" After {resources.DEPRECATION_DATE} using"
            " vector_search_alpha will raise error",
            DeprecationWarning,
        )
    if vector_distance_threshold:
        
        warnings.warn(
            "vector_distance_threshold is deprecated. Please use"
            " rag_retrieval_config.filter.vector_distance_threshold instead."
            f" After {resources.DEPRECATION_DATE} using"
            " vector_distance_threshold will raise error",
            DeprecationWarning,
        )

    
    if not rag_retrieval_config:
        api_retrival_config = aiplatform_v1beta1.RagRetrievalConfig(
            top_k=similarity_top_k,
            hybrid_search=aiplatform_v1beta1.RagRetrievalConfig.HybridSearch(
                alpha=vector_search_alpha,
            ),
            filter=aiplatform_v1beta1.RagRetrievalConfig.Filter(
                vector_distance_threshold=vector_distance_threshold
            ),
        )
    else:
        
        api_retrival_config = aiplatform_v1beta1.RagRetrievalConfig()
        
        if rag_retrieval_config.top_k:
            api_retrival_config.top_k = rag_retrieval_config.top_k
        else:
            api_retrival_config.top_k = similarity_top_k
        
        if (
            rag_retrieval_config.hybrid_search
            and rag_retrieval_config.hybrid_search.alpha
        ):
            api_retrival_config.hybrid_search.alpha = (
                rag_retrieval_config.hybrid_search.alpha
            )
        else:
            api_retrival_config.hybrid_search.alpha = vector_search_alpha
        
        
        if (
            rag_retrieval_config.filter
            and rag_retrieval_config.filter.vector_distance_threshold
            and rag_retrieval_config.filter.vector_similarity_threshold
        ):
            raise ValueError(
                "Only one of vector_distance_threshold or"
                " vector_similarity_threshold can be specified at a time"
                " in rag_retrieval_config."
            )
        
        if (
            rag_retrieval_config.filter
            and rag_retrieval_config.filter.vector_distance_threshold
        ):
            api_retrival_config.filter.vector_distance_threshold = (
                rag_retrieval_config.filter.vector_distance_threshold
            )
        else:
            api_retrival_config.filter.vector_distance_threshold = (
                vector_distance_threshold
            )
        
        if (
            rag_retrieval_config.filter
            and rag_retrieval_config.filter.vector_similarity_threshold
        ):
            api_retrival_config.filter.vector_similarity_threshold = (
                rag_retrieval_config.filter.vector_similarity_threshold
            )

        if (
            rag_retrieval_config.ranking
            and rag_retrieval_config.ranking.rank_service
            and rag_retrieval_config.ranking.llm_ranker
        ):
            raise ValueError("Only one of rank_service and llm_ranker can be set.")
        if rag_retrieval_config.ranking and rag_retrieval_config.ranking.rank_service:
            api_retrival_config.ranking.rank_service.model_name = (
                rag_retrieval_config.ranking.rank_service.model_name
            )
        elif rag_retrieval_config.ranking and rag_retrieval_config.ranking.llm_ranker:
            api_retrival_config.ranking.llm_ranker.model_name = (
                rag_retrieval_config.ranking.llm_ranker.model_name
            )
    query = aiplatform_v1beta1.RagQuery(
        text=text,
        rag_retrieval_config=api_retrival_config,
    )
    request = aiplatform_v1beta1.RetrieveContextsRequest(
        vertex_rag_store=vertex_rag_store,
        parent=parent,
        query=query,
    )
    try:
        response = client.retrieve_contexts(request=request)
    except Exception as e:
        raise RuntimeError("Failed in retrieving contexts due to: ", e) from e

    return response
