


















import dataclasses
from typing import Any, Dict, List, Optional, Union, TYPE_CHECKING

from google.cloud.aiplatform_v1beta1.services import (
    evaluation_service as gapic_evaluation_services,
)
from google.cloud.aiplatform_v1beta1.types import (
    evaluation_service as gapic_eval_service_types,
)
from vertexai.preview.evaluation.metrics import (
    _base as metrics_base,
)


if TYPE_CHECKING:
    import pandas as pd

AutoraterConfig = gapic_eval_service_types.AutoraterConfig


@dataclasses.dataclass
class EvaluationRunConfig:
    

    dataset: "pd.DataFrame"
    metrics: List[Union[str, metrics_base._Metric]]
    metric_column_mapping: Dict[str, str]
    client: gapic_evaluation_services.EvaluationServiceClient
    evaluation_service_qps: float
    retry_timeout: float
    autorater_config: Optional[AutoraterConfig] = None

    def validate_dataset_column(self, column_name: str) -> None:
        
        if (
            self.metric_column_mapping.get(column_name, column_name)
            not in self.dataset.columns
        ):
            raise KeyError(
                "Required column"
                f" `{self.metric_column_mapping.get(column_name, column_name)}` not"
                " found in the evaluation dataset. The columns in the evaluation"
                f" dataset are {list(self.dataset.columns)}."
            )


@dataclasses.dataclass
class EvalResult:
    

    summary_metrics: Dict[str, float]
    metrics_table: Optional["pd.DataFrame"] = None
    metadata: Optional[Dict[str, str]] = None


@dataclasses.dataclass
class AutoraterEvalResult:
    

    def __init__(
        self,
        eval_result: Optional[List[Dict[str, Any]]],
        eval_dataset_metadata: Optional[Dict[str, Any]],
        autorater_config: Optional[AutoraterConfig],
        **kwargs,
    ):
        
        self.eval_result = eval_result
        self.eval_dataset_metadata = eval_dataset_metadata
        self.autorater_config = autorater_config
        self.__dict__.update(kwargs)
