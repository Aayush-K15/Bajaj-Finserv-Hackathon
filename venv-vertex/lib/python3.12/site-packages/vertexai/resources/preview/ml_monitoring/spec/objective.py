
















from typing import Dict, List, Optional

from google.cloud.aiplatform.compat.types import (
    explanation_v1beta1 as explanation,
    machine_resources_v1beta1 as machine_resources,
    model_monitoring_alert_v1beta1 as model_monitoring_alert,
    model_monitoring_spec_v1beta1 as model_monitoring_spec,
)

from google.protobuf import timestamp_pb2
from google.type import interval_pb2


TF_RECORD = "tf-record"
CSV = "csv"
JSONL = "jsonl"
JENSEN_SHANNON_DIVERGENCE = "jensen_shannon_divergence"
L_INFINITY = "l_infinity"
SUPPORTED_NUMERIC_METRICS = [JENSEN_SHANNON_DIVERGENCE]
SUPPORTED_CATEGORICAL_METRICS = [JENSEN_SHANNON_DIVERGENCE, L_INFINITY]


class DataDriftSpec:
    

    def __init__(
        self,
        features: Optional[List[str]] = None,
        categorical_metric_type: Optional[str] = L_INFINITY,
        numeric_metric_type: Optional[str] = JENSEN_SHANNON_DIVERGENCE,
        default_categorical_alert_threshold: Optional[float] = None,
        default_numeric_alert_threshold: Optional[float] = None,
        feature_alert_thresholds: Optional[Dict[str, float]] = None,
    ):
        self.features = features
        self.categorical_metric_type = categorical_metric_type
        self.numeric_metric_type = numeric_metric_type
        self.default_categorical_alert_threshold = default_categorical_alert_threshold
        self.default_numeric_alert_threshold = default_numeric_alert_threshold
        self.feature_alert_thresholds = feature_alert_thresholds

    def _as_proto(
        self,
    ) -> model_monitoring_spec.ModelMonitoringObjectiveSpec.DataDriftSpec:
        
        user_default_categorical_alert_threshold = None
        user_default_numeric_alert_threshold = None
        user_alert_thresholds = None
        user_features = None
        if self.numeric_metric_type not in SUPPORTED_NUMERIC_METRICS:
            raise ValueError(
                f"The numeric metric type is not supported"
                f" {self.numeric_metric_type}"
            )
        user_numeric_metric_type = self.numeric_metric_type
        if self.categorical_metric_type not in SUPPORTED_CATEGORICAL_METRICS:
            raise ValueError(
                f"The categorical metric type is not supported"
                f" {self.categorical_metric_type}"
            )
        user_categorical_metric_type = self.categorical_metric_type
        if self.default_categorical_alert_threshold:
            user_default_categorical_alert_threshold = (
                model_monitoring_alert.ModelMonitoringAlertCondition(
                    threshold=self.default_categorical_alert_threshold
                )
            )
        if self.default_numeric_alert_threshold:
            user_default_numeric_alert_threshold = (
                model_monitoring_alert.ModelMonitoringAlertCondition(
                    threshold=self.default_numeric_alert_threshold
                )
            )
        if self.feature_alert_thresholds:
            user_alert_thresholds = {}
            for feature in self.feature_alert_thresholds:
                user_alert_thresholds.update(
                    {
                        feature: model_monitoring_alert.ModelMonitoringAlertCondition(
                            threshold=self.feature_alert_thresholds[feature]
                        )
                    }
                )
        if self.features:
            user_features = self.features
        return model_monitoring_spec.ModelMonitoringObjectiveSpec.DataDriftSpec(
            default_categorical_alert_condition=user_default_categorical_alert_threshold,
            default_numeric_alert_condition=user_default_numeric_alert_threshold,
            categorical_metric_type=user_categorical_metric_type,
            numeric_metric_type=user_numeric_metric_type,
            feature_alert_conditions=user_alert_thresholds,
            features=user_features,
        )


class FeatureAttributionSpec:
    

    def __init__(
        self,
        features: Optional[List[str]] = None,
        default_alert_threshold: Optional[float] = None,
        feature_alert_thresholds: Optional[Dict[str, float]] = None,
        batch_dedicated_resources: Optional[
            machine_resources.BatchDedicatedResources
        ] = None,
    ):
        self.features = features
        self.default_alert_threshold = default_alert_threshold
        self.feature_alert_thresholds = feature_alert_thresholds
        self.batch_dedicated_resources = batch_dedicated_resources

    def _as_proto(
        self,
    ) -> model_monitoring_spec.ModelMonitoringObjectiveSpec.FeatureAttributionSpec:
        
        user_default_alert_threshold = None
        user_alert_thresholds = None
        user_features = None
        if self.default_alert_threshold:
            user_default_alert_threshold = (
                model_monitoring_alert.ModelMonitoringAlertCondition(
                    threshold=self.default_alert_threshold
                )
            )
        if self.feature_alert_thresholds:
            user_alert_thresholds = {}
            for feature in self.feature_alert_thresholds:
                user_alert_thresholds.update(
                    {
                        feature: model_monitoring_alert.ModelMonitoringAlertCondition(
                            threshold=self.feature_alert_thresholds[feature]
                        )
                    }
                )
        if self.features:
            user_features = self.features
        return (
            model_monitoring_spec.ModelMonitoringObjectiveSpec.FeatureAttributionSpec(
                default_alert_condition=user_default_alert_threshold,
                feature_alert_conditions=user_alert_thresholds,
                features=user_features,
                batch_explanation_dedicated_resources=self.batch_dedicated_resources,
            )
        )


class MonitoringInput:
    

    def __init__(
        self,
        vertex_dataset: Optional[str] = None,
        gcs_uri: Optional[str] = None,
        data_format: Optional[str] = None,
        table_uri: Optional[str] = None,
        query: Optional[str] = None,
        timestamp_field: Optional[str] = None,
        batch_prediction_job: Optional[str] = None,
        endpoints: Optional[List[str]] = None,
        start_time: Optional[timestamp_pb2.Timestamp] = None,
        end_time: Optional[timestamp_pb2.Timestamp] = None,
        offset: Optional[str] = None,
        window: Optional[str] = None,
    ):
        self.vertex_dataset = vertex_dataset
        self.gcs_uri = gcs_uri
        self.data_format = data_format
        self.table_uri = table_uri
        self.query = query
        self.timestamp_field = timestamp_field
        self.batch_prediction_job = batch_prediction_job
        self.endpoints = endpoints
        self.start_time = start_time
        self.end_time = end_time
        self.offset = offset
        self.window = window

    def _as_proto(self) -> model_monitoring_spec.ModelMonitoringInput:
        
        user_time_interval = None
        user_time_spec = None
        if self.offset or self.window:
            user_time_spec = model_monitoring_spec.ModelMonitoringInput.TimeOffset(
                offset=self.offset if self.offset else None,
                window=self.window if self.window else None,
            )
        elif self.start_time or self.end_time:
            user_time_interval = interval_pb2.Interval(
                start_time=self.start_time if self.start_time else None,
                end_time=self.end_time if self.end_time else None,
            )
        if self.vertex_dataset or self.gcs_uri or self.table_uri or self.query:
            user_vertex_dataset = None
            user_gcs_source = None
            user_bigquery_source = None
            if self.vertex_dataset:
                user_vertex_dataset = self.vertex_dataset
            elif self.gcs_uri:
                if not self.data_format:
                    raise ValueError("`data_format` must be provided with gcs uri.")
                if self.data_format == CSV:
                    user_data_format = (
                        model_monitoring_spec.ModelMonitoringInput.ModelMonitoringDataset.ModelMonitoringGcsSource.DataFormat.CSV
                    )
                elif self.data_format == JSONL:
                    user_data_format = (
                        model_monitoring_spec.ModelMonitoringInput.ModelMonitoringDataset.ModelMonitoringGcsSource.DataFormat.JSONL
                    )
                elif self.data_format == TF_RECORD:
                    user_data_format = (
                        model_monitoring_spec.ModelMonitoringInput.ModelMonitoringDataset.ModelMonitoringGcsSource.DataFormat.TF_RECORD
                    )
                else:
                    raise ValueError(
                        (
                            "Unsupported value in data format. `data_format` "
                            "must be one of %s, %s, or %s"
                        )
                        % (TF_RECORD, CSV, JSONL)
                    )
                user_gcs_source = model_monitoring_spec.ModelMonitoringInput.ModelMonitoringDataset.ModelMonitoringGcsSource(
                    gcs_uri=self.gcs_uri,
                    format_=user_data_format,
                )
            elif self.table_uri or self.query:
                user_bigquery_source = model_monitoring_spec.ModelMonitoringInput.ModelMonitoringDataset.ModelMonitoringBigQuerySource(
                    table_uri=self.table_uri,
                    query=self.query,
                )
            else:
                raise ValueError(
                    ("At least one source of dataset must" " be provided.")
                )
            user_model_monitoring_dataset = (
                model_monitoring_spec.ModelMonitoringInput.ModelMonitoringDataset(
                    vertex_dataset=user_vertex_dataset,
                    gcs_source=user_gcs_source,
                    bigquery_source=user_bigquery_source,
                    timestamp_field=self.timestamp_field,
                )
            )
            return model_monitoring_spec.ModelMonitoringInput(
                columnized_dataset=user_model_monitoring_dataset,
                time_offset=user_time_spec,
                time_interval=user_time_interval,
            )
        elif self.batch_prediction_job:
            user_batch_prediction_output = (
                model_monitoring_spec.ModelMonitoringInput.BatchPredictionOutput(
                    batch_prediction_job=self.batch_prediction_job,
                )
            )
            return model_monitoring_spec.ModelMonitoringInput(
                batch_prediction_output=user_batch_prediction_output,
                time_offset=user_time_spec,
                time_interval=user_time_interval,
            )
        elif self.endpoints:
            user_vertex_endpoint_logs = (
                model_monitoring_spec.ModelMonitoringInput.VertexEndpointLogs(
                    endpoints=self.endpoints,
                )
            )
            return model_monitoring_spec.ModelMonitoringInput(
                vertex_endpoint_logs=user_vertex_endpoint_logs,
                time_offset=user_time_spec,
                time_interval=user_time_interval,
            )
        else:
            raise ValueError("At least one source of dataInput must be provided.")


class TabularObjective:
    

    def __init__(
        self,
        feature_drift_spec: Optional[DataDriftSpec] = None,
        prediction_output_drift_spec: Optional[DataDriftSpec] = None,
        feature_attribution_spec: Optional[FeatureAttributionSpec] = None,
    ):
        self.feature_drift_spec = feature_drift_spec
        self.prediction_output_drift_spec = prediction_output_drift_spec
        self.feature_attribution_spec = feature_attribution_spec

    def _as_proto(
        self,
    ) -> model_monitoring_spec.ModelMonitoringObjectiveSpec.TabularObjective:
        
        user_feature_drift_spec = None
        user_prediction_output_drift_spec = None
        user_feature_attribution_spec = None
        if self.feature_drift_spec:
            user_feature_drift_spec = self.feature_drift_spec._as_proto()
        if self.prediction_output_drift_spec:
            user_prediction_output_drift_spec = (
                self.prediction_output_drift_spec._as_proto()
            )
        if self.feature_attribution_spec:
            user_feature_attribution_spec = self.feature_attribution_spec._as_proto()
        return model_monitoring_spec.ModelMonitoringObjectiveSpec.TabularObjective(
            feature_drift_spec=user_feature_drift_spec,
            prediction_output_drift_spec=user_prediction_output_drift_spec,
            feature_attribution_spec=user_feature_attribution_spec,
        )


class ObjectiveSpec:
    

    def __init__(
        self,
        baseline_dataset: MonitoringInput,
        target_dataset: MonitoringInput,
        tabular_objective: Optional[TabularObjective] = None,
        explanation_spec: Optional[explanation.ExplanationSpec] = None,
    ):
        self.baseline = baseline_dataset
        self.target = target_dataset
        self.tabular_objective = tabular_objective
        self.explanation_spec = explanation_spec

    def _as_proto(self) -> model_monitoring_spec.ModelMonitoringObjectiveSpec:
        
        user_tabular_objective = None
        if not self.baseline or not self.target:
            raise ValueError("At least one objective must be provided.")
        if self.tabular_objective:
            user_tabular_objective = self.tabular_objective._as_proto()
        return model_monitoring_spec.ModelMonitoringObjectiveSpec(
            tabular_objective=user_tabular_objective,
            explanation_spec=self.explanation_spec if self.explanation_spec else None,
            target_dataset=self.target._as_proto(),
            baseline_dataset=self.baseline._as_proto(),
        )
