














from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    Dict,
    Mapping,
    Optional,
    Sequence,
    Union,
)

if TYPE_CHECKING:
    try:
        from autogen import agentchat

        ConversableAgent = agentchat.ConversableAgent
        ChatResult = agentchat.ChatResult
    except ImportError:
        ConversableAgent = Any

    try:
        from opentelemetry.sdk import trace

        TracerProvider = trace.TracerProvider
        SpanProcessor = trace.SpanProcessor
        SynchronousMultiSpanProcessor = trace.SynchronousMultiSpanProcessor
    except ImportError:
        TracerProvider = Any
        SpanProcessor = Any
        SynchronousMultiSpanProcessor = Any


def _prepare_runnable_kwargs(
    runnable_kwargs: Mapping[str, Any],
    system_instruction: str,
    runnable_name: str,
    llm_config: Mapping[str, Any],
) -> Mapping[str, Any]:
    
    if runnable_kwargs is None:
        runnable_kwargs = {}

    if (
        "human_input_mode" in runnable_kwargs
        and runnable_kwargs["human_input_mode"] != "NEVER"
    ):
        from google.cloud.aiplatform import base

        _LOGGER = base.Logger(__name__)
        _LOGGER.warning(
            f"human_input_mode={runnable_kwargs['human_input_mode']}"
            "is not supported. Will be enforced to 'NEVER'."
        )
    runnable_kwargs["human_input_mode"] = "NEVER"

    if "system_message" not in runnable_kwargs and system_instruction:
        runnable_kwargs["system_message"] = system_instruction

    if "name" not in runnable_kwargs:
        runnable_kwargs["name"] = runnable_name

    if "llm_config" not in runnable_kwargs:
        runnable_kwargs["llm_config"] = llm_config

    return runnable_kwargs


def _default_runnable_builder(
    **runnable_kwargs: Any,
) -> "ConversableAgent":
    from autogen import agentchat

    return agentchat.ConversableAgent(**runnable_kwargs)


def _default_instrumentor_builder(project_id: str):
    from vertexai.agent_engines import _utils

    cloud_trace_exporter = _utils._import_cloud_trace_exporter_or_warn()
    cloud_trace_v2 = _utils._import_cloud_trace_v2_or_warn()
    openinference_autogen = _utils._import_openinference_autogen_or_warn()
    opentelemetry = _utils._import_opentelemetry_or_warn()
    opentelemetry_sdk_trace = _utils._import_opentelemetry_sdk_trace_or_warn()
    if all(
        (
            cloud_trace_exporter,
            cloud_trace_v2,
            openinference_autogen,
            opentelemetry,
            opentelemetry_sdk_trace,
        )
    ):
        import google.auth

        credentials, _ = google.auth.default()
        span_exporter = cloud_trace_exporter.CloudTraceSpanExporter(
            project_id=project_id,
            client=cloud_trace_v2.TraceServiceClient(
                credentials=credentials.with_quota_project(project_id),
            ),
        )
        span_processor: SpanProcessor = (
            opentelemetry_sdk_trace.export.SimpleSpanProcessor(
                span_exporter=span_exporter,
            )
        )
        tracer_provider: TracerProvider = opentelemetry.trace.get_tracer_provider()
        
        
        
        
        
        
        
        if not tracer_provider:
            from google.cloud.aiplatform import base

            _LOGGER = base.Logger(__name__)
            _LOGGER.warning(
                "No tracer provider. By default, "
                "we should get one of the following providers: "
                "OTEL_PYTHON_TRACER_PROVIDER, _TRACER_PROVIDER, "
                "or _PROXY_TRACER_PROVIDER."
            )
            tracer_provider = opentelemetry_sdk_trace.TracerProvider()
            opentelemetry.trace.set_tracer_provider(tracer_provider)
        
        
        
        if _utils.is_noop_or_proxy_tracer_provider(tracer_provider):
            tracer_provider = opentelemetry_sdk_trace.TracerProvider()
            opentelemetry.trace.set_tracer_provider(tracer_provider)
        
        _override_active_span_processor(
            tracer_provider,
            opentelemetry_sdk_trace.SynchronousMultiSpanProcessor(),
        )
        tracer_provider.add_span_processor(span_processor)
        
        
        
        
        
        
        
        instrumentor = openinference_autogen.AutogenInstrumentor()
        instrumentor.uninstrument()
        instrumentor.instrument()
        return instrumentor
    else:
        from google.cloud.aiplatform import base

        _LOGGER = base.Logger(__name__)
        _LOGGER.warning(
            "enable_tracing=True but proceeding with tracing disabled "
            "because not all packages for tracing have been installed"
        )
        return None


def _validate_callable_parameters_are_annotated(callable: Callable):
    
    import inspect

    parameters = dict(inspect.signature(callable).parameters)
    for name, parameter in parameters.items():
        if parameter.annotation == inspect.Parameter.empty:
            raise TypeError(
                f"Callable={callable.__name__} has untyped input_arg={name}. "
                f"Please specify a type when defining it, e.g. `{name}: str`."
            )


def _validate_tools(tools: Sequence[Callable[..., Any]]):
    
    for tool in tools:
        if isinstance(tool, Callable):
            _validate_callable_parameters_are_annotated(tool)


def _override_active_span_processor(
    tracer_provider: "TracerProvider",
    active_span_processor: "SynchronousMultiSpanProcessor",
):
    
    if tracer_provider._active_span_processor:
        tracer_provider._active_span_processor.shutdown()
    tracer_provider._active_span_processor = active_span_processor


class AG2Agent:
    

    agent_framework = "ag2"

    def __init__(
        self,
        model: str,
        runnable_name: str,
        *,
        api_type: Optional[str] = None,
        llm_config: Optional[Mapping[str, Any]] = None,
        system_instruction: Optional[str] = None,
        runnable_kwargs: Optional[Mapping[str, Any]] = None,
        runnable_builder: Optional[Callable[..., "ConversableAgent"]] = None,
        tools: Optional[Sequence[Callable[..., Any]]] = None,
        enable_tracing: bool = False,
        instrumentor_builder: Optional[Callable[..., Any]] = None,
    ):
        
        from google.cloud.aiplatform import initializer

        self._tmpl_attrs: dict[str, Any] = {
            "project": initializer.global_config.project,
            "location": initializer.global_config.location,
            "model_name": model,
            "api_type": api_type or "google",
            "system_instruction": system_instruction,
            "runnable_name": runnable_name,
            "tools": [],
            "ag2_tool_objects": [],
            "runnable": None,
            "runnable_builder": runnable_builder,
            "instrumentor": None,
            "instrumentor_builder": instrumentor_builder,
            "enable_tracing": enable_tracing,
        }
        self._tmpl_attrs["llm_config"] = llm_config or {
            "config_list": [
                {
                    "project_id": self._tmpl_attrs.get("project"),
                    "location": self._tmpl_attrs.get("location"),
                    "model": self._tmpl_attrs.get("model_name"),
                    "api_type": self._tmpl_attrs.get("api_type"),
                }
            ]
        }
        self._tmpl_attrs["runnable_kwargs"] = _prepare_runnable_kwargs(
            runnable_kwargs=runnable_kwargs,
            llm_config=self._tmpl_attrs.get("llm_config"),
            system_instruction=self._tmpl_attrs.get("system_instruction"),
            runnable_name=self._tmpl_attrs.get("runnable_name"),
        )
        if tools:
            
            
            _validate_tools(tools)
            self._tmpl_attrs["tools"] = tools

    def set_up(self):
        
        if self._tmpl_attrs.get("enable_tracing"):
            instrumentor_builder = (
                self._tmpl_attrs.get("instrumentor_builder")
                or _default_instrumentor_builder
            )
            self._tmpl_attrs["instrumentor"] = instrumentor_builder(
                project_id=self._tmpl_attrs.get("project")
            )

        
        tools = self._tmpl_attrs.get("tools")
        ag2_tool_objects = self._tmpl_attrs.get("ag2_tool_objects")
        if tools and not ag2_tool_objects:
            from vertexai.agent_engines import _utils

            autogen_tools = _utils._import_autogen_tools_or_warn()
            if autogen_tools:
                for tool in tools:
                    ag2_tool_objects.append(autogen_tools.Tool(func_or_tool=tool))

        
        runnable_builder = (
            self._tmpl_attrs.get("runnable_builder") or _default_runnable_builder
        )
        self._tmpl_attrs["runnable"] = runnable_builder(
            **self._tmpl_attrs.get("runnable_kwargs")
        )

    def clone(self) -> "AG2Agent":
        
        import copy

        return AG2Agent(
            model=self._tmpl_attrs.get("model_name"),
            api_type=self._tmpl_attrs.get("api_type"),
            llm_config=copy.deepcopy(self._tmpl_attrs.get("llm_config")),
            system_instruction=self._tmpl_attrs.get("system_instruction"),
            runnable_name=self._tmpl_attrs.get("runnable_name"),
            tools=copy.deepcopy(self._tmpl_attrs.get("tools")),
            runnable_kwargs=copy.deepcopy(self._tmpl_attrs.get("runnable_kwargs")),
            runnable_builder=self._tmpl_attrs.get("runnable_builder"),
            enable_tracing=self._tmpl_attrs.get("enable_tracing"),
            instrumentor_builder=self._tmpl_attrs.get("instrumentor_builder"),
        )

    def query(
        self,
        *,
        input: Union[str, Mapping[str, Any]],
        max_turns: Optional[int] = None,
        **kwargs: Any,
    ) -> Dict[str, Any]:
        
        if isinstance(input, str):
            input = {"content": input}

        if max_turns and isinstance(max_turns, float):
            
            max_turns = round(max_turns)

        if "user_input" in kwargs:
            from google.cloud.aiplatform import base

            _LOGGER = base.Logger(__name__)
            _LOGGER.warning(
                "The `user_input` parameter should not be passed through"
                "kwargs. The `user_input` defaults to `False`."
            )
            kwargs.pop("user_input")

        if not self._tmpl_attrs.get("runnable"):
            self.set_up()

        response = self._tmpl_attrs.get("runnable").run(
            message=input,
            user_input=False,
            tools=self._tmpl_attrs.get("ag2_tool_objects"),
            max_turns=max_turns,
            **kwargs,
        )

        from vertexai.agent_engines import _utils

        return _utils.to_json_serializable_autogen_object(response)
