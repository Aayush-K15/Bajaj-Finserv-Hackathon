from __future__ import annotations

from functools import wraps
import inspect
import re
from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    Literal,
    cast,
    final,
)
import warnings
import weakref

import numpy as np

from pandas._config import (
    get_option,
    using_copy_on_write,
    warn_copy_on_write,
)

from pandas._libs import (
    NaT,
    internals as libinternals,
    lib,
)
from pandas._libs.internals import (
    BlockPlacement,
    BlockValuesRefs,
)
from pandas._libs.missing import NA
from pandas._typing import (
    ArrayLike,
    AxisInt,
    DtypeBackend,
    DtypeObj,
    F,
    FillnaOptions,
    IgnoreRaise,
    InterpolateOptions,
    QuantileInterpolation,
    Self,
    Shape,
    npt,
)
from pandas.errors import AbstractMethodError
from pandas.util._decorators import cache_readonly
from pandas.util._exceptions import find_stack_level
from pandas.util._validators import validate_bool_kwarg

from pandas.core.dtypes.astype import (
    astype_array_safe,
    astype_is_view,
)
from pandas.core.dtypes.cast import (
    LossySetitemError,
    can_hold_element,
    convert_dtypes,
    find_result_type,
    maybe_downcast_to_dtype,
    np_can_hold_element,
)
from pandas.core.dtypes.common import (
    is_1d_only_ea_dtype,
    is_float_dtype,
    is_integer_dtype,
    is_list_like,
    is_scalar,
    is_string_dtype,
)
from pandas.core.dtypes.dtypes import (
    DatetimeTZDtype,
    ExtensionDtype,
    IntervalDtype,
    NumpyEADtype,
    PeriodDtype,
)
from pandas.core.dtypes.generic import (
    ABCDataFrame,
    ABCIndex,
    ABCNumpyExtensionArray,
    ABCSeries,
)
from pandas.core.dtypes.inference import is_re
from pandas.core.dtypes.missing import (
    is_valid_na_for_dtype,
    isna,
    na_value_for_dtype,
)

from pandas.core import missing
import pandas.core.algorithms as algos
from pandas.core.array_algos.putmask import (
    extract_bool_array,
    putmask_inplace,
    putmask_without_repeat,
    setitem_datetimelike_compat,
    validate_putmask,
)
from pandas.core.array_algos.quantile import quantile_compat
from pandas.core.array_algos.replace import (
    compare_or_regex_search,
    replace_regex,
    should_use_regex,
)
from pandas.core.array_algos.transforms import shift
from pandas.core.arrays import (
    Categorical,
    DatetimeArray,
    ExtensionArray,
    IntervalArray,
    NumpyExtensionArray,
    PeriodArray,
    TimedeltaArray,
)
from pandas.core.arrays.string_ import StringDtype
from pandas.core.base import PandasObject
import pandas.core.common as com
from pandas.core.computation import expressions
from pandas.core.construction import (
    ensure_wrapped_if_datetimelike,
    extract_array,
)
from pandas.core.indexers import check_setitem_lengths
from pandas.core.indexes.base import get_values_for_csv

if TYPE_CHECKING:
    from collections.abc import (
        Iterable,
        Sequence,
    )

    from pandas.core.api import Index
    from pandas.core.arrays._mixins import NDArrayBackedExtensionArray


_dtype_obj = np.dtype("object")


COW_WARNING_GENERAL_MSG = 


COW_WARNING_SETITEM_MSG = 


def maybe_split(meth: F) -> F:
    

    @wraps(meth)
    def newfunc(self, *args, **kwargs) -> list[Block]:
        if self.ndim == 1 or self.shape[0] == 1:
            return meth(self, *args, **kwargs)
        else:
            
            return self.split_and_operate(meth, *args, **kwargs)

    return cast(F, newfunc)


class Block(PandasObject, libinternals.Block):
    

    values: np.ndarray | ExtensionArray
    ndim: int
    refs: BlockValuesRefs
    __init__: Callable

    __slots__ = ()
    is_numeric = False

    @final
    @cache_readonly
    def _validate_ndim(self) -> bool:
        
        dtype = self.dtype
        return not isinstance(dtype, ExtensionDtype) or isinstance(
            dtype, DatetimeTZDtype
        )

    @final
    @cache_readonly
    def is_object(self) -> bool:
        return self.values.dtype == _dtype_obj

    @final
    @cache_readonly
    def is_extension(self) -> bool:
        return not lib.is_np_dtype(self.values.dtype)

    @final
    @cache_readonly
    def _can_consolidate(self) -> bool:
        
        return not self.is_extension

    @final
    @cache_readonly
    def _consolidate_key(self):
        return self._can_consolidate, self.dtype.name

    @final
    @cache_readonly
    def _can_hold_na(self) -> bool:
        
        dtype = self.dtype
        if isinstance(dtype, np.dtype):
            return dtype.kind not in "iub"
        return dtype._can_hold_na

    @final
    @property
    def is_bool(self) -> bool:
        
        return self.values.dtype == np.dtype(bool)

    @final
    def external_values(self):
        return external_values(self.values)

    @final
    @cache_readonly
    def fill_value(self):
        
        return na_value_for_dtype(self.dtype, compat=False)

    @final
    def _standardize_fill_value(self, value):
        
        if self.dtype != _dtype_obj and is_valid_na_for_dtype(value, self.dtype):
            value = self.fill_value
        return value

    @property
    def mgr_locs(self) -> BlockPlacement:
        return self._mgr_locs

    @mgr_locs.setter
    def mgr_locs(self, new_mgr_locs: BlockPlacement) -> None:
        self._mgr_locs = new_mgr_locs

    @final
    def make_block(
        self,
        values,
        placement: BlockPlacement | None = None,
        refs: BlockValuesRefs | None = None,
    ) -> Block:
        
        if placement is None:
            placement = self._mgr_locs
        if self.is_extension:
            values = ensure_block_shape(values, ndim=self.ndim)

        return new_block(values, placement=placement, ndim=self.ndim, refs=refs)

    @final
    def make_block_same_class(
        self,
        values,
        placement: BlockPlacement | None = None,
        refs: BlockValuesRefs | None = None,
    ) -> Self:
        
        
        
        if placement is None:
            placement = self._mgr_locs

        
        return type(self)(values, placement=placement, ndim=self.ndim, refs=refs)

    @final
    def __repr__(self) -> str:
        
        name = type(self).__name__
        if self.ndim == 1:
            result = f"{name}: {len(self)} dtype: {self.dtype}"
        else:
            shape = " x ".join([str(s) for s in self.shape])
            result = f"{name}: {self.mgr_locs.indexer}, {shape}, dtype: {self.dtype}"

        return result

    @final
    def __len__(self) -> int:
        return len(self.values)

    @final
    def slice_block_columns(self, slc: slice) -> Self:
        
        new_mgr_locs = self._mgr_locs[slc]

        new_values = self._slice(slc)
        refs = self.refs
        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)

    @final
    def take_block_columns(self, indices: npt.NDArray[np.intp]) -> Self:
        
        
        

        new_mgr_locs = self._mgr_locs[indices]

        new_values = self._slice(indices)
        return type(self)(new_values, new_mgr_locs, self.ndim, refs=None)

    @final
    def getitem_block_columns(
        self, slicer: slice, new_mgr_locs: BlockPlacement, ref_inplace_op: bool = False
    ) -> Self:
        
        new_values = self._slice(slicer)
        refs = self.refs if not ref_inplace_op or self.refs.has_reference() else None
        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)

    @final
    def _can_hold_element(self, element: Any) -> bool:
        
        element = extract_array(element, extract_numpy=True)
        return can_hold_element(self.values, element)

    @final
    def should_store(self, value: ArrayLike) -> bool:
        
        return value.dtype == self.dtype

    
    

    @final
    def apply(self, func, **kwargs) -> list[Block]:
        
        result = func(self.values, **kwargs)

        result = maybe_coerce_values(result)
        return self._split_op_result(result)

    @final
    def reduce(self, func) -> list[Block]:
        
        
        assert self.ndim == 2

        result = func(self.values)

        if self.values.ndim == 1:
            res_values = result
        else:
            res_values = result.reshape(-1, 1)

        nb = self.make_block(res_values)
        return [nb]

    @final
    def _split_op_result(self, result: ArrayLike) -> list[Block]:
        
        if result.ndim > 1 and isinstance(result.dtype, ExtensionDtype):
            
            
            nbs = []
            for i, loc in enumerate(self._mgr_locs):
                if not is_1d_only_ea_dtype(result.dtype):
                    vals = result[i : i + 1]
                else:
                    vals = result[i]

                bp = BlockPlacement(loc)
                block = self.make_block(values=vals, placement=bp)
                nbs.append(block)
            return nbs

        nb = self.make_block(result)

        return [nb]

    @final
    def _split(self) -> list[Block]:
        
        assert self.ndim == 2

        new_blocks = []
        for i, ref_loc in enumerate(self._mgr_locs):
            vals = self.values[slice(i, i + 1)]

            bp = BlockPlacement(ref_loc)
            nb = type(self)(vals, placement=bp, ndim=2, refs=self.refs)
            new_blocks.append(nb)
        return new_blocks

    @final
    def split_and_operate(self, func, *args, **kwargs) -> list[Block]:
        
        assert self.ndim == 2 and self.shape[0] != 1

        res_blocks = []
        for nb in self._split():
            rbs = func(nb, *args, **kwargs)
            res_blocks.extend(rbs)
        return res_blocks

    
    

    @final
    def coerce_to_target_dtype(
        self, other, warn_on_upcast: bool = False, using_cow: bool = False
    ) -> Block:
        
        new_dtype = find_result_type(self.values.dtype, other)
        if new_dtype == self.dtype:
            
            raise AssertionError(
                "Something has gone wrong, please report a bug at "
                "https://github.com/pandas-dev/pandas/issues"
            )

        
        
        if (
            is_scalar(other)
            and is_integer_dtype(self.values.dtype)
            and isna(other)
            and other is not NaT
            and not (
                isinstance(other, (np.datetime64, np.timedelta64)) and np.isnat(other)
            )
        ):
            warn_on_upcast = False
        elif (
            isinstance(other, np.ndarray)
            and other.ndim == 1
            and is_integer_dtype(self.values.dtype)
            and is_float_dtype(other.dtype)
            and lib.has_only_ints_or_nan(other)
        ):
            warn_on_upcast = False

        if warn_on_upcast:
            warnings.warn(
                f"Setting an item of incompatible dtype is deprecated "
                "and will raise an error in a future version of pandas. "
                f"Value '{other}' has dtype incompatible with {self.values.dtype}, "
                "please explicitly cast to a compatible dtype first.",
                FutureWarning,
                stacklevel=find_stack_level(),
            )
        if self.values.dtype == new_dtype:
            raise AssertionError(
                f"Did not expect new dtype {new_dtype} to equal self.dtype "
                f"{self.values.dtype}. Please report a bug at "
                "https://github.com/pandas-dev/pandas/issues."
            )
        copy = False
        if (
            not using_cow
            and isinstance(self.dtype, StringDtype)
            and self.dtype.storage == "python"
        ):
            copy = True
        return self.astype(new_dtype, copy=copy, using_cow=using_cow)

    @final
    def _maybe_downcast(
        self,
        blocks: list[Block],
        downcast,
        using_cow: bool,
        caller: str,
    ) -> list[Block]:
        if downcast is False:
            return blocks

        if self.dtype == _dtype_obj:
            
            
            
            
            

            if caller == "fillna" and get_option("future.no_silent_downcasting"):
                return blocks

            nbs = extend_blocks(
                [
                    blk.convert(
                        using_cow=using_cow, copy=not using_cow, convert_string=False
                    )
                    for blk in blocks
                ]
            )
            if caller == "fillna":
                if len(nbs) != len(blocks) or not all(
                    x.dtype == y.dtype for x, y in zip(nbs, blocks)
                ):
                    
                    warnings.warn(
                        "Downcasting object dtype arrays on .fillna, .ffill, .bfill "
                        "is deprecated and will change in a future version. "
                        "Call result.infer_objects(copy=False) instead. "
                        "To opt-in to the future "
                        "behavior, set "
                        "`pd.set_option('future.no_silent_downcasting', True)`",
                        FutureWarning,
                        stacklevel=find_stack_level(),
                    )

            return nbs

        elif downcast is None:
            return blocks
        elif caller == "where" and get_option("future.no_silent_downcasting") is True:
            return blocks
        else:
            nbs = extend_blocks([b._downcast_2d(downcast, using_cow) for b in blocks])

        
        
        
        
        
        if caller == "where":
            
            if len(blocks) != len(nbs) or any(
                left.dtype != right.dtype for left, right in zip(blocks, nbs)
            ):
                
                
                warnings.warn(
                    "Downcasting behavior in Series and DataFrame methods 'where', "
                    "'mask', and 'clip' is deprecated. In a future "
                    "version this will not infer object dtypes or cast all-round "
                    "floats to integers. Instead call "
                    "result.infer_objects(copy=False) for object inference, "
                    "or cast round floats explicitly. To opt-in to the future "
                    "behavior, set "
                    "`pd.set_option('future.no_silent_downcasting', True)`",
                    FutureWarning,
                    stacklevel=find_stack_level(),
                )

        return nbs

    @final
    @maybe_split
    def _downcast_2d(self, dtype, using_cow: bool = False) -> list[Block]:
        
        new_values = maybe_downcast_to_dtype(self.values, dtype=dtype)
        new_values = maybe_coerce_values(new_values)
        refs = self.refs if new_values is self.values else None
        return [self.make_block(new_values, refs=refs)]

    @final
    def convert(
        self,
        *,
        copy: bool = True,
        using_cow: bool = False,
        convert_string: bool = True,
    ) -> list[Block]:
        
        if not self.is_object:
            if not copy and using_cow:
                return [self.copy(deep=False)]
            return [self.copy()] if copy else [self]

        if self.ndim != 1 and self.shape[0] != 1:
            blocks = self.split_and_operate(
                Block.convert,
                copy=copy,
                using_cow=using_cow,
                convert_string=convert_string,
            )
            if all(blk.dtype.kind == "O" for blk in blocks):
                
                if using_cow:
                    return [self.copy(deep=False)]
                return [self.copy()] if copy else [self]
            return blocks

        values = self.values
        if values.ndim == 2:
            
            
            values = values[0]

        res_values = lib.maybe_convert_objects(
            values,  
            convert_non_numeric=True,
            convert_string=convert_string,
        )
        refs = None
        if (
            copy
            and res_values is values
            or isinstance(res_values, NumpyExtensionArray)
            and res_values._ndarray is values
        ):
            res_values = res_values.copy()
        elif res_values is values:
            refs = self.refs

        res_values = ensure_block_shape(res_values, self.ndim)
        res_values = maybe_coerce_values(res_values)
        return [self.make_block(res_values, refs=refs)]

    def convert_dtypes(
        self,
        copy: bool,
        using_cow: bool,
        infer_objects: bool = True,
        convert_string: bool = True,
        convert_integer: bool = True,
        convert_boolean: bool = True,
        convert_floating: bool = True,
        dtype_backend: DtypeBackend = "numpy_nullable",
    ) -> list[Block]:
        if infer_objects and self.is_object:
            blks = self.convert(copy=False, using_cow=using_cow)
        else:
            blks = [self]

        if not any(
            [convert_floating, convert_integer, convert_boolean, convert_string]
        ):
            return [b.copy(deep=copy) for b in blks]

        rbs = []
        for blk in blks:
            
            sub_blks = [blk] if blk.ndim == 1 or self.shape[0] == 1 else blk._split()
            dtypes = [
                convert_dtypes(
                    b.values,
                    convert_string,
                    convert_integer,
                    convert_boolean,
                    convert_floating,
                    infer_objects,
                    dtype_backend,
                )
                for b in sub_blks
            ]
            if all(dtype == self.dtype for dtype in dtypes):
                
                rbs.append(blk.copy(deep=copy))
                continue

            for dtype, b in zip(dtypes, sub_blks):
                rbs.append(b.astype(dtype=dtype, copy=copy, squeeze=b.ndim != 1))
        return rbs

    
    

    @final
    @cache_readonly
    def dtype(self) -> DtypeObj:
        return self.values.dtype

    @final
    def astype(
        self,
        dtype: DtypeObj,
        copy: bool = False,
        errors: IgnoreRaise = "raise",
        using_cow: bool = False,
        squeeze: bool = False,
    ) -> Block:
        
        values = self.values
        if squeeze and values.ndim == 2 and is_1d_only_ea_dtype(dtype):
            if values.shape[0] != 1:
                raise ValueError("Can not squeeze with more than one column.")
            values = values[0, :]  

        new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)

        new_values = maybe_coerce_values(new_values)

        refs = None
        if (using_cow or not copy) and astype_is_view(values.dtype, new_values.dtype):
            refs = self.refs

        newb = self.make_block(new_values, refs=refs)
        if newb.shape != self.shape:
            raise TypeError(
                f"cannot set astype for copy = [{copy}] for dtype "
                f"({self.dtype.name} [{self.shape}]) to different shape "
                f"({newb.dtype.name} [{newb.shape}])"
            )
        return newb

    @final
    def get_values_for_csv(
        self, *, float_format, date_format, decimal, na_rep: str = "nan", quoting=None
    ) -> Block:
        
        result = get_values_for_csv(
            self.values,
            na_rep=na_rep,
            quoting=quoting,
            float_format=float_format,
            date_format=date_format,
            decimal=decimal,
        )
        return self.make_block(result)

    @final
    def copy(self, deep: bool = True) -> Self:
        
        values = self.values
        refs: BlockValuesRefs | None
        if deep:
            values = values.copy()
            refs = None
        else:
            refs = self.refs
        return type(self)(values, placement=self._mgr_locs, ndim=self.ndim, refs=refs)

    
    

    @final
    def _maybe_copy(self, using_cow: bool, inplace: bool) -> Self:
        if using_cow and inplace:
            deep = self.refs.has_reference()
            blk = self.copy(deep=deep)
        else:
            blk = self if inplace else self.copy()
        return blk

    @final
    def _get_refs_and_copy(self, using_cow: bool, inplace: bool):
        refs = None
        copy = not inplace
        if inplace:
            if using_cow and self.refs.has_reference():
                copy = True
            else:
                refs = self.refs
        return copy, refs

    
    

    @final
    def replace(
        self,
        to_replace,
        value,
        inplace: bool = False,
        
        mask: npt.NDArray[np.bool_] | None = None,
        using_cow: bool = False,
        already_warned=None,
        convert_string=None,
    ) -> list[Block]:
        

        
        
        
        values = self.values

        if isinstance(values, Categorical):
            
            
            blk = self._maybe_copy(using_cow, inplace)
            values = cast(Categorical, blk.values)
            values._replace(to_replace=to_replace, value=value, inplace=True)
            return [blk]

        if not self._can_hold_element(to_replace):
            
            
            
            
            if using_cow:
                return [self.copy(deep=False)]
            else:
                return [self] if inplace else [self.copy()]

        if mask is None:
            mask = missing.mask_missing(values, to_replace)
        if not mask.any():
            
            
            if using_cow:
                return [self.copy(deep=False)]
            else:
                return [self] if inplace else [self.copy()]

        elif self._can_hold_element(value) or (self.dtype == "string" and is_re(value)):
            
            
            blk = self._maybe_copy(using_cow, inplace)
            putmask_inplace(blk.values, mask, value)
            if (
                inplace
                and warn_copy_on_write()
                and already_warned is not None
                and not already_warned.warned_already
            ):
                if self.refs.has_reference():
                    warnings.warn(
                        COW_WARNING_GENERAL_MSG,
                        FutureWarning,
                        stacklevel=find_stack_level(),
                    )
                    already_warned.warned_already = True

            if not (self.is_object and value is None):
                
                
                if get_option("future.no_silent_downcasting") is True:
                    blocks = [blk]
                else:
                    blocks = blk.convert(
                        copy=False,
                        using_cow=using_cow,
                        convert_string=convert_string or self.dtype == "string",
                    )
                    if len(blocks) > 1 or blocks[0].dtype != blk.dtype:
                        warnings.warn(
                            
                            "Downcasting behavior in `replace` is deprecated and "
                            "will be removed in a future version. To retain the old "
                            "behavior, explicitly call "
                            "`result.infer_objects(copy=False)`. "
                            "To opt-in to the future "
                            "behavior, set "
                            "`pd.set_option('future.no_silent_downcasting', True)`",
                            FutureWarning,
                            stacklevel=find_stack_level(),
                        )
            else:
                blocks = [blk]
            return blocks

        elif self.ndim == 1 or self.shape[0] == 1:
            if value is None or value is NA:
                blk = self.astype(np.dtype(object))
            else:
                blk = self.coerce_to_target_dtype(value, using_cow=using_cow)
            return blk.replace(
                to_replace=to_replace,
                value=value,
                inplace=True,
                mask=mask,
                using_cow=using_cow,
                convert_string=convert_string,
            )

        else:
            
            blocks = []
            for i, nb in enumerate(self._split()):
                blocks.extend(
                    type(self).replace(
                        nb,
                        to_replace=to_replace,
                        value=value,
                        inplace=True,
                        mask=mask[i : i + 1],
                        using_cow=using_cow,
                        convert_string=convert_string,
                    )
                )
            return blocks

    @final
    def _replace_regex(
        self,
        to_replace,
        value,
        inplace: bool = False,
        mask=None,
        using_cow: bool = False,
        convert_string=None,
        already_warned=None,
    ) -> list[Block]:
        
        if not is_re(to_replace) and not self._can_hold_element(to_replace):
            
            
            if using_cow:
                return [self.copy(deep=False)]
            return [self] if inplace else [self.copy()]

        if is_re(to_replace) and self.dtype not in [object, "string"]:
            
            
            return [self.copy(deep=False)]

        if not (
            self._can_hold_element(value) or (self.dtype == "string" and is_re(value))
        ):
            block = self.astype(np.dtype(object))
        else:
            block = self._maybe_copy(using_cow, inplace)

        rx = re.compile(to_replace)

        replace_regex(block.values, rx, value, mask)

        if (
            inplace
            and warn_copy_on_write()
            and already_warned is not None
            and not already_warned.warned_already
        ):
            if self.refs.has_reference():
                warnings.warn(
                    COW_WARNING_GENERAL_MSG,
                    FutureWarning,
                    stacklevel=find_stack_level(),
                )
                already_warned.warned_already = True

        nbs = block.convert(
            copy=False,
            using_cow=using_cow,
            convert_string=convert_string or self.dtype == "string",
        )
        opt = get_option("future.no_silent_downcasting")
        if (
            len(nbs) > 1
            or (
                nbs[0].dtype != block.dtype
                and not (self.dtype == "string" and nbs[0].dtype == "string")
            )
        ) and not opt:
            warnings.warn(
                
                "Downcasting behavior in `replace` is deprecated and "
                "will be removed in a future version. To retain the old "
                "behavior, explicitly call `result.infer_objects(copy=False)`. "
                "To opt-in to the future "
                "behavior, set "
                "`pd.set_option('future.no_silent_downcasting', True)`",
                FutureWarning,
                stacklevel=find_stack_level(),
            )
        return nbs

    @final
    def replace_list(
        self,
        src_list: Iterable[Any],
        dest_list: Sequence[Any],
        inplace: bool = False,
        regex: bool = False,
        using_cow: bool = False,
        already_warned=None,
    ) -> list[Block]:
        
        values = self.values

        if isinstance(values, Categorical):
            
            
            blk = self._maybe_copy(using_cow, inplace)
            values = cast(Categorical, blk.values)
            values._replace(to_replace=src_list, value=dest_list, inplace=True)
            return [blk]

        convert_string = self.dtype == "string"

        
        pairs = [
            (x, y)
            for x, y in zip(src_list, dest_list)
            if (self._can_hold_element(x) or (self.dtype == "string" and is_re(x)))
        ]
        if not len(pairs):
            if using_cow:
                return [self.copy(deep=False)]
            
            return [self] if inplace else [self.copy()]

        src_len = len(pairs) - 1

        if is_string_dtype(values.dtype):
            
            
            na_mask = ~isna(values)
            masks: Iterable[npt.NDArray[np.bool_]] = (
                extract_bool_array(
                    cast(
                        ArrayLike,
                        compare_or_regex_search(
                            values, s[0], regex=regex, mask=na_mask
                        ),
                    )
                )
                for s in pairs
            )
        else:
            
            masks = (missing.mask_missing(values, s[0]) for s in pairs)
        
        
        if inplace:
            masks = list(masks)

        if using_cow:
            
            
            rb = [self]
        else:
            rb = [self if inplace else self.copy()]

        if (
            inplace
            and warn_copy_on_write()
            and already_warned is not None
            and not already_warned.warned_already
        ):
            if self.refs.has_reference():
                warnings.warn(
                    COW_WARNING_GENERAL_MSG,
                    FutureWarning,
                    stacklevel=find_stack_level(),
                )
                already_warned.warned_already = True

        opt = get_option("future.no_silent_downcasting")
        for i, ((src, dest), mask) in enumerate(zip(pairs, masks)):
            convert = i == src_len  
            new_rb: list[Block] = []

            
            
            
            for blk_num, blk in enumerate(rb):
                if len(rb) == 1:
                    m = mask
                else:
                    mib = mask
                    assert not isinstance(mib, bool)
                    m = mib[blk_num : blk_num + 1]

                
                
                
                result = blk._replace_coerce(
                    to_replace=src,
                    value=dest,
                    mask=m,
                    inplace=inplace,
                    regex=regex,
                    using_cow=using_cow,
                    convert_string=convert_string,
                )

                if using_cow and i != src_len:
                    
                    
                    
                    for b in result:
                        ref = weakref.ref(b)
                        b.refs.referenced_blocks.pop(
                            b.refs.referenced_blocks.index(ref)
                        )

                if (
                    not opt
                    and convert
                    and blk.is_object
                    and not all(x is None for x in dest_list)
                ):
                    
                    nbs = []
                    for res_blk in result:
                        converted = res_blk.convert(
                            copy=True and not using_cow,
                            using_cow=using_cow,
                            convert_string=convert_string,
                        )
                        if len(converted) > 1 or converted[0].dtype != res_blk.dtype:
                            warnings.warn(
                                
                                "Downcasting behavior in `replace` is deprecated "
                                "and will be removed in a future version. To "
                                "retain the old behavior, explicitly call "
                                "`result.infer_objects(copy=False)`. "
                                "To opt-in to the future "
                                "behavior, set "
                                "`pd.set_option('future.no_silent_downcasting', True)`",
                                FutureWarning,
                                stacklevel=find_stack_level(),
                            )
                        nbs.extend(converted)
                    result = nbs
                new_rb.extend(result)
            rb = new_rb
        return rb

    @final
    def _replace_coerce(
        self,
        to_replace,
        value,
        mask: npt.NDArray[np.bool_],
        inplace: bool = True,
        regex: bool = False,
        using_cow: bool = False,
        convert_string: bool = True,
    ) -> list[Block]:
        
        if should_use_regex(regex, to_replace):
            return self._replace_regex(
                to_replace,
                value,
                inplace=inplace,
                mask=mask,
                using_cow=using_cow,
                convert_string=convert_string,
            )
        else:
            if value is None:
                
                if mask.any():
                    has_ref = self.refs.has_reference()
                    nb = self.astype(np.dtype(object), copy=False, using_cow=using_cow)
                    if (nb is self or using_cow) and not inplace:
                        nb = nb.copy()
                    elif inplace and has_ref and nb.refs.has_reference() and using_cow:
                        
                        nb = nb.copy()
                    putmask_inplace(nb.values, mask, value)
                    return [nb]
                if using_cow:
                    return [self.copy(deep=False)]
                return [self] if inplace else [self.copy()]
            return self.replace(
                to_replace=to_replace,
                value=value,
                inplace=inplace,
                mask=mask,
                using_cow=using_cow,
                convert_string=convert_string,
            )

    
    
    

    def _maybe_squeeze_arg(self, arg: np.ndarray) -> np.ndarray:
        
        return arg

    def _unwrap_setitem_indexer(self, indexer):
        
        return indexer

    
    
    @property
    def shape(self) -> Shape:
        return self.values.shape

    def iget(self, i: int | tuple[int, int] | tuple[slice, int]) -> np.ndarray:
        
        
        
        
        
        
        return self.values[i]  

    def _slice(
        self, slicer: slice | npt.NDArray[np.bool_] | npt.NDArray[np.intp]
    ) -> ArrayLike:
        

        return self.values[slicer]

    def set_inplace(self, locs, values: ArrayLike, copy: bool = False) -> None:
        
        if copy:
            self.values = self.values.copy()
        self.values[locs] = values

    @final
    def take_nd(
        self,
        indexer: npt.NDArray[np.intp],
        axis: AxisInt,
        new_mgr_locs: BlockPlacement | None = None,
        fill_value=lib.no_default,
    ) -> Block:
        
        values = self.values

        if fill_value is lib.no_default:
            fill_value = self.fill_value
            allow_fill = False
        else:
            allow_fill = True

        
        new_values = algos.take_nd(
            values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value
        )

        
        
        if isinstance(self, ExtensionBlock):
            
            
            assert not (self.ndim == 1 and new_mgr_locs is None)
        assert not (axis == 0 and new_mgr_locs is None)

        if new_mgr_locs is None:
            new_mgr_locs = self._mgr_locs

        if new_values.dtype != self.dtype:
            return self.make_block(new_values, new_mgr_locs)
        else:
            return self.make_block_same_class(new_values, new_mgr_locs)

    def _unstack(
        self,
        unstacker,
        fill_value,
        new_placement: npt.NDArray[np.intp],
        needs_masking: npt.NDArray[np.bool_],
    ):
        
        new_values, mask = unstacker.get_new_values(
            self.values.T, fill_value=fill_value
        )

        mask = mask.any(0)
        

        
        
        
        
        new_values = new_values.T[mask]
        new_placement = new_placement[mask]

        bp = BlockPlacement(new_placement)
        blocks = [new_block_2d(new_values, placement=bp)]
        return blocks, mask

    

    def setitem(self, indexer, value, using_cow: bool = False) -> Block:
        

        value = self._standardize_fill_value(value)

        values = cast(np.ndarray, self.values)
        if self.ndim == 2:
            values = values.T

        
        check_setitem_lengths(indexer, value, values)

        if self.dtype != _dtype_obj:
            
            value = extract_array(value, extract_numpy=True)
        try:
            casted = np_can_hold_element(values.dtype, value)
        except LossySetitemError:
            
            nb = self.coerce_to_target_dtype(value, warn_on_upcast=True)
            return nb.setitem(indexer, value)
        else:
            if self.dtype == _dtype_obj:
                
                vi = values[indexer]
                if lib.is_list_like(vi):
                    
                    
                    casted = setitem_datetimelike_compat(values, len(vi), casted)

            self = self._maybe_copy(using_cow, inplace=True)
            values = cast(np.ndarray, self.values.T)
            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:
                
                casted = casted[0, ...]
            try:
                values[indexer] = casted
            except (TypeError, ValueError) as err:
                if is_list_like(casted):
                    raise ValueError(
                        "setting an array element with a sequence."
                    ) from err
                raise
        return self

    def putmask(
        self, mask, new, using_cow: bool = False, already_warned=None
    ) -> list[Block]:
        
        orig_mask = mask
        values = cast(np.ndarray, self.values)
        mask, noop = validate_putmask(values.T, mask)
        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))

        if new is lib.no_default:
            new = self.fill_value

        new = self._standardize_fill_value(new)
        new = extract_array(new, extract_numpy=True)

        if noop:
            if using_cow:
                return [self.copy(deep=False)]
            return [self]

        if (
            warn_copy_on_write()
            and already_warned is not None
            and not already_warned.warned_already
        ):
            if self.refs.has_reference():
                warnings.warn(
                    COW_WARNING_GENERAL_MSG,
                    FutureWarning,
                    stacklevel=find_stack_level(),
                )
                already_warned.warned_already = True

        try:
            casted = np_can_hold_element(values.dtype, new)

            self = self._maybe_copy(using_cow, inplace=True)
            values = cast(np.ndarray, self.values)

            putmask_without_repeat(values.T, mask, casted)
            return [self]
        except LossySetitemError:
            if self.ndim == 1 or self.shape[0] == 1:
                

                if not is_list_like(new):
                    
                    return self.coerce_to_target_dtype(
                        new, warn_on_upcast=True
                    ).putmask(mask, new)
                else:
                    indexer = mask.nonzero()[0]
                    nb = self.setitem(indexer, new[indexer], using_cow=using_cow)
                    return [nb]

            else:
                is_array = isinstance(new, np.ndarray)

                res_blocks = []
                nbs = self._split()
                for i, nb in enumerate(nbs):
                    n = new
                    if is_array:
                        
                        n = new[:, i : i + 1]

                    submask = orig_mask[:, i : i + 1]
                    rbs = nb.putmask(submask, n, using_cow=using_cow)
                    res_blocks.extend(rbs)
                return res_blocks

    def where(
        self, other, cond, _downcast: str | bool = "infer", using_cow: bool = False
    ) -> list[Block]:
        
        assert cond.ndim == self.ndim
        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))

        transpose = self.ndim == 2

        cond = extract_bool_array(cond)

        
        values = cast(np.ndarray, self.values)
        orig_other = other
        if transpose:
            values = values.T

        icond, noop = validate_putmask(values, ~cond)
        if noop:
            
            if using_cow:
                return [self.copy(deep=False)]
            return [self.copy()]

        if other is lib.no_default:
            other = self.fill_value

        other = self._standardize_fill_value(other)

        try:
            
            
            
            casted = np_can_hold_element(values.dtype, other)
        except (ValueError, TypeError, LossySetitemError):
            

            if self.ndim == 1 or self.shape[0] == 1:
                

                block = self.coerce_to_target_dtype(other)
                blocks = block.where(orig_other, cond, using_cow=using_cow)
                return self._maybe_downcast(
                    blocks, downcast=_downcast, using_cow=using_cow, caller="where"
                )

            else:
                
                
                
                is_array = isinstance(other, (np.ndarray, ExtensionArray))

                res_blocks = []
                nbs = self._split()
                for i, nb in enumerate(nbs):
                    oth = other
                    if is_array:
                        
                        oth = other[:, i : i + 1]

                    submask = cond[:, i : i + 1]
                    rbs = nb.where(
                        oth, submask, _downcast=_downcast, using_cow=using_cow
                    )
                    res_blocks.extend(rbs)
                return res_blocks

        else:
            other = casted
            alt = setitem_datetimelike_compat(values, icond.sum(), other)
            if alt is not other:
                if is_list_like(other) and len(other) < len(values):
                    
                    np.where(~icond, values, other)
                    raise NotImplementedError(
                        "This should not be reached; call to np.where above is "
                        "expected to raise ValueError. Please report a bug at "
                        "github.com/pandas-dev/pandas"
                    )
                result = values.copy()
                np.putmask(result, icond, alt)
            else:
                
                
                if (
                    is_list_like(other)
                    and not isinstance(other, np.ndarray)
                    and len(other) == self.shape[-1]
                ):
                    
                    
                    
                    other = np.array(other).reshape(values.shape)
                    
                    

                
                result = expressions.where(~icond, values, other)
                
                

        if transpose:
            result = result.T

        return [self.make_block(result)]

    def fillna(
        self,
        value,
        limit: int | None = None,
        inplace: bool = False,
        downcast=None,
        using_cow: bool = False,
        already_warned=None,
    ) -> list[Block]:
        
        
        inplace = validate_bool_kwarg(inplace, "inplace")

        if not self._can_hold_na:
            
            noop = True
        else:
            mask = isna(self.values)
            mask, noop = validate_putmask(self.values, mask)

        if noop:
            
            if inplace:
                if using_cow:
                    return [self.copy(deep=False)]
                
                
                return [self]
            else:
                
                nb = self.copy(deep=not using_cow)
                nbs = nb._maybe_downcast(
                    [nb], downcast=downcast, using_cow=using_cow, caller="fillna"
                )
                return nbs

        if limit is not None:
            mask[mask.cumsum(self.values.ndim - 1) > limit] = False

        if inplace:
            nbs = self.putmask(
                mask.T, value, using_cow=using_cow, already_warned=already_warned
            )
        else:
            
            
            nbs = self.where(value, ~mask.T, _downcast=False)

        
        
        
        return extend_blocks(
            [
                blk._maybe_downcast(
                    [blk], downcast=downcast, using_cow=using_cow, caller="fillna"
                )
                for blk in nbs
            ]
        )

    def pad_or_backfill(
        self,
        *,
        method: FillnaOptions,
        axis: AxisInt = 0,
        inplace: bool = False,
        limit: int | None = None,
        limit_area: Literal["inside", "outside"] | None = None,
        downcast: Literal["infer"] | None = None,
        using_cow: bool = False,
        already_warned=None,
    ) -> list[Block]:
        if not self._can_hold_na:
            
            if using_cow:
                return [self.copy(deep=False)]
            return [self] if inplace else [self.copy()]

        copy, refs = self._get_refs_and_copy(using_cow, inplace)

        
        
        vals = cast(NumpyExtensionArray, self.array_values)
        if axis == 1:
            vals = vals.T
        new_values = vals._pad_or_backfill(
            method=method,
            limit=limit,
            limit_area=limit_area,
            copy=copy,
        )
        if (
            not copy
            and warn_copy_on_write()
            and already_warned is not None
            and not already_warned.warned_already
        ):
            if self.refs.has_reference():
                warnings.warn(
                    COW_WARNING_GENERAL_MSG,
                    FutureWarning,
                    stacklevel=find_stack_level(),
                )
                already_warned.warned_already = True
        if axis == 1:
            new_values = new_values.T

        data = extract_array(new_values, extract_numpy=True)

        nb = self.make_block_same_class(data, refs=refs)
        return nb._maybe_downcast([nb], downcast, using_cow, caller="fillna")

    @final
    def interpolate(
        self,
        *,
        method: InterpolateOptions,
        index: Index,
        inplace: bool = False,
        limit: int | None = None,
        limit_direction: Literal["forward", "backward", "both"] = "forward",
        limit_area: Literal["inside", "outside"] | None = None,
        downcast: Literal["infer"] | None = None,
        using_cow: bool = False,
        already_warned=None,
        **kwargs,
    ) -> list[Block]:
        inplace = validate_bool_kwarg(inplace, "inplace")
        
        if method == "asfreq":  
            
            missing.clean_fill_method(method)

        if not self._can_hold_na:
            
            if using_cow:
                return [self.copy(deep=False)]
            return [self] if inplace else [self.copy()]

        
        if self.dtype == _dtype_obj:
            
            
            
            if using_cow:
                return [self.copy(deep=False)]
            return [self] if inplace else [self.copy()]

        copy, refs = self._get_refs_and_copy(using_cow, inplace)

        
        new_values = self.array_values.interpolate(
            method=method,
            axis=self.ndim - 1,
            index=index,
            limit=limit,
            limit_direction=limit_direction,
            limit_area=limit_area,
            copy=copy,
            **kwargs,
        )
        data = extract_array(new_values, extract_numpy=True)

        if (
            not copy
            and warn_copy_on_write()
            and already_warned is not None
            and not already_warned.warned_already
        ):
            if self.refs.has_reference():
                warnings.warn(
                    COW_WARNING_GENERAL_MSG,
                    FutureWarning,
                    stacklevel=find_stack_level(),
                )
                already_warned.warned_already = True

        nb = self.make_block_same_class(data, refs=refs)
        return nb._maybe_downcast([nb], downcast, using_cow, caller="interpolate")

    @final
    def diff(self, n: int) -> list[Block]:
        
        
        
        new_values = algos.diff(self.values.T, n, axis=0).T
        return [self.make_block(values=new_values)]

    def shift(self, periods: int, fill_value: Any = None) -> list[Block]:
        
        
        
        axis = self.ndim - 1

        
        
        

        if not lib.is_scalar(fill_value) and self.dtype != _dtype_obj:
            
            
            
            raise ValueError("fill_value must be a scalar")

        fill_value = self._standardize_fill_value(fill_value)

        try:
            
            
            casted = np_can_hold_element(
                self.dtype, fill_value  
            )
        except LossySetitemError:
            nb = self.coerce_to_target_dtype(fill_value)
            return nb.shift(periods, fill_value=fill_value)

        else:
            values = cast(np.ndarray, self.values)
            new_values = shift(values, periods, axis, casted)
            return [self.make_block_same_class(new_values)]

    @final
    def quantile(
        self,
        qs: Index,  
        interpolation: QuantileInterpolation = "linear",
    ) -> Block:
        
        
        assert self.ndim == 2
        assert is_list_like(qs)  

        result = quantile_compat(self.values, np.asarray(qs._values), interpolation)
        
        
        result = ensure_block_shape(result, ndim=2)
        return new_block_2d(result, placement=self._mgr_locs)

    @final
    def round(self, decimals: int, using_cow: bool = False) -> Self:
        
        if not self.is_numeric or self.is_bool:
            return self.copy(deep=not using_cow)
        refs = None
        
        
        
        
        values = self.values.round(decimals)  
        if values is self.values:
            if not using_cow:
                
                
                
                
                values = values.copy()
            else:
                refs = self.refs
        return self.make_block_same_class(values, refs=refs)

    
    

    def delete(self, loc) -> list[Block]:
        
        if not is_list_like(loc):
            loc = [loc]

        if self.ndim == 1:
            values = cast(np.ndarray, self.values)
            values = np.delete(values, loc)
            mgr_locs = self._mgr_locs.delete(loc)
            return [type(self)(values, placement=mgr_locs, ndim=self.ndim)]

        if np.max(loc) >= self.values.shape[0]:
            raise IndexError

        
        
        loc = np.concatenate([loc, [self.values.shape[0]]])
        mgr_locs_arr = self._mgr_locs.as_array
        new_blocks: list[Block] = []

        previous_loc = -1
        
        
        
        refs = self.refs if self.refs.has_reference() else None
        for idx in loc:
            if idx == previous_loc + 1:
                
                pass
            else:
                
                
                values = self.values[previous_loc + 1 : idx, :]  
                locs = mgr_locs_arr[previous_loc + 1 : idx]
                nb = type(self)(
                    values, placement=BlockPlacement(locs), ndim=self.ndim, refs=refs
                )
                new_blocks.append(nb)

            previous_loc = idx

        return new_blocks

    @property
    def is_view(self) -> bool:
        
        raise AbstractMethodError(self)

    @property
    def array_values(self) -> ExtensionArray:
        
        raise AbstractMethodError(self)

    def get_values(self, dtype: DtypeObj | None = None) -> np.ndarray:
        
        raise AbstractMethodError(self)


class EABackedBlock(Block):
    

    values: ExtensionArray

    @final
    def shift(self, periods: int, fill_value: Any = None) -> list[Block]:
        
        
        
        new_values = self.values.T.shift(periods=periods, fill_value=fill_value).T
        return [self.make_block_same_class(new_values)]

    @final
    def setitem(self, indexer, value, using_cow: bool = False):
        
        orig_indexer = indexer
        orig_value = value

        indexer = self._unwrap_setitem_indexer(indexer)
        value = self._maybe_squeeze_arg(value)

        values = self.values
        if values.ndim == 2:
            
            
            values = values.T
        check_setitem_lengths(indexer, value, values)

        try:
            values[indexer] = value
        except (ValueError, TypeError):
            if isinstance(self.dtype, IntervalDtype):
                
                nb = self.coerce_to_target_dtype(orig_value, warn_on_upcast=True)
                return nb.setitem(orig_indexer, orig_value)

            elif isinstance(self, NDArrayBackedExtensionBlock):
                nb = self.coerce_to_target_dtype(orig_value, warn_on_upcast=True)
                return nb.setitem(orig_indexer, orig_value)

            else:
                raise

        else:
            return self

    @final
    def where(
        self, other, cond, _downcast: str | bool = "infer", using_cow: bool = False
    ) -> list[Block]:
        
        arr = self.values.T

        cond = extract_bool_array(cond)

        orig_other = other
        orig_cond = cond
        other = self._maybe_squeeze_arg(other)
        cond = self._maybe_squeeze_arg(cond)

        if other is lib.no_default:
            other = self.fill_value

        icond, noop = validate_putmask(arr, ~cond)
        if noop:
            
            
            if using_cow:
                return [self.copy(deep=False)]
            return [self.copy()]

        try:
            res_values = arr._where(cond, other).T
        except (ValueError, TypeError):
            if self.ndim == 1 or self.shape[0] == 1:
                if isinstance(self.dtype, (IntervalDtype, StringDtype)):
                    
                    blk = self.coerce_to_target_dtype(orig_other)
                    if (
                        self.ndim == 2
                        and isinstance(orig_cond, np.ndarray)
                        and orig_cond.ndim == 1
                        and not is_1d_only_ea_dtype(blk.dtype)
                    ):
                        orig_cond = orig_cond[:, None]
                    nbs = blk.where(orig_other, orig_cond, using_cow=using_cow)
                    return self._maybe_downcast(
                        nbs, downcast=_downcast, using_cow=using_cow, caller="where"
                    )

                elif isinstance(self, NDArrayBackedExtensionBlock):
                    
                    
                    blk = self.coerce_to_target_dtype(orig_other)
                    nbs = blk.where(orig_other, orig_cond, using_cow=using_cow)
                    return self._maybe_downcast(
                        nbs, downcast=_downcast, using_cow=using_cow, caller="where"
                    )

                else:
                    raise

            else:
                
                is_array = isinstance(orig_other, (np.ndarray, ExtensionArray))

                res_blocks = []
                nbs = self._split()
                for i, nb in enumerate(nbs):
                    n = orig_other
                    if is_array:
                        
                        n = orig_other[:, i : i + 1]

                    submask = orig_cond[:, i : i + 1]
                    rbs = nb.where(n, submask, using_cow=using_cow)
                    res_blocks.extend(rbs)
                return res_blocks

        nb = self.make_block_same_class(res_values)
        return [nb]

    @final
    def putmask(
        self, mask, new, using_cow: bool = False, already_warned=None
    ) -> list[Block]:
        
        mask = extract_bool_array(mask)
        if new is lib.no_default:
            new = self.fill_value

        orig_new = new
        orig_mask = mask
        new = self._maybe_squeeze_arg(new)
        mask = self._maybe_squeeze_arg(mask)

        if not mask.any():
            if using_cow:
                return [self.copy(deep=False)]
            return [self]

        if (
            warn_copy_on_write()
            and already_warned is not None
            and not already_warned.warned_already
        ):
            if self.refs.has_reference():
                warnings.warn(
                    COW_WARNING_GENERAL_MSG,
                    FutureWarning,
                    stacklevel=find_stack_level(),
                )
                already_warned.warned_already = True

        self = self._maybe_copy(using_cow, inplace=True)
        values = self.values
        if values.ndim == 2:
            values = values.T

        try:
            
            values._putmask(mask, new)
        except (TypeError, ValueError):
            if self.ndim == 1 or self.shape[0] == 1:
                if isinstance(self.dtype, IntervalDtype):
                    
                    
                    blk = self.coerce_to_target_dtype(orig_new, warn_on_upcast=True)
                    return blk.putmask(orig_mask, orig_new)

                elif isinstance(self, NDArrayBackedExtensionBlock):
                    
                    
                    blk = self.coerce_to_target_dtype(orig_new, warn_on_upcast=True)
                    return blk.putmask(orig_mask, orig_new)

                else:
                    raise

            else:
                
                is_array = isinstance(orig_new, (np.ndarray, ExtensionArray))

                res_blocks = []
                nbs = self._split()
                for i, nb in enumerate(nbs):
                    n = orig_new
                    if is_array:
                        
                        n = orig_new[:, i : i + 1]

                    submask = orig_mask[:, i : i + 1]
                    rbs = nb.putmask(submask, n)
                    res_blocks.extend(rbs)
                return res_blocks

        return [self]

    @final
    def delete(self, loc) -> list[Block]:
        
        if self.ndim == 1:
            values = self.values.delete(loc)
            mgr_locs = self._mgr_locs.delete(loc)
            return [type(self)(values, placement=mgr_locs, ndim=self.ndim)]
        elif self.values.ndim == 1:
            
            return []
        return super().delete(loc)

    @final
    @cache_readonly
    def array_values(self) -> ExtensionArray:
        return self.values

    @final
    def get_values(self, dtype: DtypeObj | None = None) -> np.ndarray:
        
        values: ArrayLike = self.values
        if dtype == _dtype_obj:
            values = values.astype(object)
        
        return np.asarray(values).reshape(self.shape)

    @final
    def pad_or_backfill(
        self,
        *,
        method: FillnaOptions,
        axis: AxisInt = 0,
        inplace: bool = False,
        limit: int | None = None,
        limit_area: Literal["inside", "outside"] | None = None,
        downcast: Literal["infer"] | None = None,
        using_cow: bool = False,
        already_warned=None,
    ) -> list[Block]:
        values = self.values

        kwargs: dict[str, Any] = {"method": method, "limit": limit}
        if "limit_area" in inspect.signature(values._pad_or_backfill).parameters:
            kwargs["limit_area"] = limit_area
        elif limit_area is not None:
            raise NotImplementedError(
                f"{type(values).__name__} does not implement limit_area "
                "(added in pandas 2.2). 3rd-party ExtnsionArray authors "
                "need to add this argument to _pad_or_backfill."
            )

        if values.ndim == 2 and axis == 1:
            
            new_values = values.T._pad_or_backfill(**kwargs).T
        else:
            new_values = values._pad_or_backfill(**kwargs)
        return [self.make_block_same_class(new_values)]


class ExtensionBlock(EABackedBlock):
    

    values: ExtensionArray

    def fillna(
        self,
        value,
        limit: int | None = None,
        inplace: bool = False,
        downcast=None,
        using_cow: bool = False,
        already_warned=None,
    ) -> list[Block]:
        if isinstance(self.dtype, (IntervalDtype, StringDtype)):
            
            return super().fillna(
                value=value,
                limit=limit,
                inplace=inplace,
                downcast=downcast,
                using_cow=using_cow,
                already_warned=already_warned,
            )
        if using_cow and self._can_hold_na and not self.values._hasna:
            refs = self.refs
            new_values = self.values
        else:
            copy, refs = self._get_refs_and_copy(using_cow, inplace)

            try:
                new_values = self.values.fillna(
                    value=value, method=None, limit=limit, copy=copy
                )
            except TypeError:
                
                refs = None
                new_values = self.values.fillna(value=value, method=None, limit=limit)
                
                
                warnings.warn(
                    
                    "ExtensionArray.fillna added a 'copy' keyword in pandas "
                    "2.1.0. In a future version, ExtensionArray subclasses will "
                    "need to implement this keyword or an exception will be "
                    "raised. In the interim, the keyword is ignored by "
                    f"{type(self.values).__name__}.",
                    DeprecationWarning,
                    stacklevel=find_stack_level(),
                )
            else:
                if (
                    not copy
                    and warn_copy_on_write()
                    and already_warned is not None
                    and not already_warned.warned_already
                ):
                    if self.refs.has_reference():
                        warnings.warn(
                            COW_WARNING_GENERAL_MSG,
                            FutureWarning,
                            stacklevel=find_stack_level(),
                        )
                        already_warned.warned_already = True

        nb = self.make_block_same_class(new_values, refs=refs)
        return nb._maybe_downcast([nb], downcast, using_cow=using_cow, caller="fillna")

    @cache_readonly
    def shape(self) -> Shape:
        
        if self.ndim == 1:
            return (len(self.values),)
        return len(self._mgr_locs), len(self.values)

    def iget(self, i: int | tuple[int, int] | tuple[slice, int]):
        
        
        
        
        

        

        if isinstance(i, tuple):
            
            col, loc = i
            if not com.is_null_slice(col) and col != 0:
                raise IndexError(f"{self} only contains one item")
            if isinstance(col, slice):
                
                
                if loc < 0:
                    loc += len(self.values)
                
                
                return self.values[loc : loc + 1]
            return self.values[loc]
        else:
            if i != 0:
                raise IndexError(f"{self} only contains one item")
            return self.values

    def set_inplace(self, locs, values: ArrayLike, copy: bool = False) -> None:
        
        
        if copy:
            self.values = self.values.copy()
        self.values[:] = values

    def _maybe_squeeze_arg(self, arg):
        
        
        if (
            isinstance(arg, (np.ndarray, ExtensionArray))
            and arg.ndim == self.values.ndim + 1
        ):
            
            assert arg.shape[1] == 1
            
            
            arg = arg[:, 0]  
        elif isinstance(arg, ABCDataFrame):
            
            
            assert arg.shape[1] == 1
            arg = arg._ixs(0, axis=1)._values

        return arg

    def _unwrap_setitem_indexer(self, indexer):
        
        

        if isinstance(indexer, tuple) and len(indexer) == 2:
            
            
            
            
            if all(isinstance(x, np.ndarray) and x.ndim == 2 for x in indexer):
                
                first, second = indexer
                if not (
                    second.size == 1 and (second == 0).all() and first.shape[1] == 1
                ):
                    raise NotImplementedError(
                        "This should not be reached. Please report a bug at "
                        "github.com/pandas-dev/pandas/"
                    )
                indexer = first[:, 0]

            elif lib.is_integer(indexer[1]) and indexer[1] == 0:
                
                indexer = indexer[0]

            elif com.is_null_slice(indexer[1]):
                indexer = indexer[0]

            elif is_list_like(indexer[1]) and indexer[1][0] == 0:
                indexer = indexer[0]

            else:
                raise NotImplementedError(
                    "This should not be reached. Please report a bug at "
                    "github.com/pandas-dev/pandas/"
                )
        return indexer

    @property
    def is_view(self) -> bool:
        
        return False

    
    @cache_readonly
    def is_numeric(self) -> bool:  
        return self.values.dtype._is_numeric

    def _slice(
        self, slicer: slice | npt.NDArray[np.bool_] | npt.NDArray[np.intp]
    ) -> ExtensionArray:
        
        
        

        
        if self.ndim == 2:
            
            

            if not isinstance(slicer, slice):
                raise AssertionError(
                    "invalid slicing for a 1-ndim ExtensionArray", slicer
                )
            
            
            
            
            new_locs = range(1)[slicer]
            if not len(new_locs):
                raise AssertionError(
                    "invalid slicing for a 1-ndim ExtensionArray", slicer
                )
            slicer = slice(None)

        return self.values[slicer]

    @final
    def slice_block_rows(self, slicer: slice) -> Self:
        
        
        
        new_values = self.values[slicer]
        return type(self)(new_values, self._mgr_locs, ndim=self.ndim, refs=self.refs)

    def _unstack(
        self,
        unstacker,
        fill_value,
        new_placement: npt.NDArray[np.intp],
        needs_masking: npt.NDArray[np.bool_],
    ):
        
        
        
        
        
        

        
        new_values, mask = unstacker.arange_result

        
        
        
        
        new_values = new_values.T[mask]
        new_placement = new_placement[mask]

        
        
        
        
        blocks = [
            
            type(self)(
                self.values.take(
                    indices, allow_fill=needs_masking[i], fill_value=fill_value
                ),
                BlockPlacement(place),
                ndim=2,
            )
            for i, (indices, place) in enumerate(zip(new_values, new_placement))
        ]
        return blocks, mask


class NumpyBlock(Block):
    values: np.ndarray
    __slots__ = ()

    @property
    def is_view(self) -> bool:
        
        return self.values.base is not None

    @property
    def array_values(self) -> ExtensionArray:
        return NumpyExtensionArray(self.values)

    def get_values(self, dtype: DtypeObj | None = None) -> np.ndarray:
        if dtype == _dtype_obj:
            return self.values.astype(_dtype_obj)
        return self.values

    @cache_readonly
    def is_numeric(self) -> bool:  
        dtype = self.values.dtype
        kind = dtype.kind

        return kind in "fciub"


class NumericBlock(NumpyBlock):
    
    
    __slots__ = ()


class ObjectBlock(NumpyBlock):
    
    
    __slots__ = ()


class NDArrayBackedExtensionBlock(EABackedBlock):
    

    values: NDArrayBackedExtensionArray

    @property
    def is_view(self) -> bool:
        
        
        return self.values._ndarray.base is not None


class DatetimeLikeBlock(NDArrayBackedExtensionBlock):
    

    __slots__ = ()
    is_numeric = False
    values: DatetimeArray | TimedeltaArray


class DatetimeTZBlock(DatetimeLikeBlock):
    

    values: DatetimeArray

    __slots__ = ()






def maybe_coerce_values(values: ArrayLike) -> ArrayLike:
    
    

    if isinstance(values, np.ndarray):
        values = ensure_wrapped_if_datetimelike(values)

        if issubclass(values.dtype.type, str):
            values = np.array(values, dtype=object)

    if isinstance(values, (DatetimeArray, TimedeltaArray)) and values.freq is not None:
        
        values = values._with_freq(None)

    return values


def get_block_type(dtype: DtypeObj) -> type[Block]:
    
    if isinstance(dtype, DatetimeTZDtype):
        return DatetimeTZBlock
    elif isinstance(dtype, PeriodDtype):
        return NDArrayBackedExtensionBlock
    elif isinstance(dtype, ExtensionDtype):
        
        return ExtensionBlock

    
    
    kind = dtype.kind
    if kind in "Mm":
        return DatetimeLikeBlock

    return NumpyBlock


def new_block_2d(
    values: ArrayLike, placement: BlockPlacement, refs: BlockValuesRefs | None = None
):
    
    
    
    
    klass = get_block_type(values.dtype)

    values = maybe_coerce_values(values)
    return klass(values, ndim=2, placement=placement, refs=refs)


def new_block(
    values,
    placement: BlockPlacement,
    *,
    ndim: int,
    refs: BlockValuesRefs | None = None,
) -> Block:
    
    
    
    
    klass = get_block_type(values.dtype)
    return klass(values, ndim=ndim, placement=placement, refs=refs)


def check_ndim(values, placement: BlockPlacement, ndim: int) -> None:
    

    if values.ndim > ndim:
        
        raise ValueError(
            "Wrong number of dimensions. "
            f"values.ndim > ndim [{values.ndim} > {ndim}]"
        )

    if not is_1d_only_ea_dtype(values.dtype):
        
        if values.ndim != ndim:
            raise ValueError(
                "Wrong number of dimensions. "
                f"values.ndim != ndim [{values.ndim} != {ndim}]"
            )
        if len(placement) != len(values):
            raise ValueError(
                f"Wrong number of items passed {len(values)}, "
                f"placement implies {len(placement)}"
            )
    elif ndim == 2 and len(placement) != 1:
        
        raise ValueError("need to split")


def extract_pandas_array(
    values: ArrayLike, dtype: DtypeObj | None, ndim: int
) -> tuple[ArrayLike, DtypeObj | None]:
    
    
    if isinstance(values, ABCNumpyExtensionArray):
        values = values.to_numpy()
        if ndim and ndim > 1:
            
            values = np.atleast_2d(values)

    if isinstance(dtype, NumpyEADtype):
        dtype = dtype.numpy_dtype

    return values, dtype





def extend_blocks(result, blocks=None) -> list[Block]:
    
    if blocks is None:
        blocks = []
    if isinstance(result, list):
        for r in result:
            if isinstance(r, list):
                blocks.extend(r)
            else:
                blocks.append(r)
    else:
        assert isinstance(result, Block), type(result)
        blocks.append(result)
    return blocks


def ensure_block_shape(values: ArrayLike, ndim: int = 1) -> ArrayLike:
    

    if values.ndim < ndim:
        if not is_1d_only_ea_dtype(values.dtype):
            
            
            
            values = cast("np.ndarray | DatetimeArray | TimedeltaArray", values)
            values = values.reshape(1, -1)

    return values


def external_values(values: ArrayLike) -> ArrayLike:
    
    if isinstance(values, (PeriodArray, IntervalArray)):
        return values.astype(object)
    elif isinstance(values, (DatetimeArray, TimedeltaArray)):
        
        
        
        values = values._ndarray

    if isinstance(values, np.ndarray) and using_copy_on_write():
        values = values.view()
        values.flags.writeable = False

    

    return values
